var relearn_searchindex = [
  {
    "breadcrumb": "Academic anecdotes \u003e Old courses",
    "content": "Game Theory in Economics and Evolution (Fall 2016) Exploration of human and animal interactions: integrating evolutionary and economic perspectives to investigate individual and social behaviour.\nIntroduction We’re taking our first steps towards flipping the classroom! Here you can find video lectures and notes that replace in-class lectures.\n01 The Ultimatum Game 02 Extensive and normal form games 03 Dominance and Pareto optimality 04 Symmetric and zero-sum games 05 Sotto vs. Blotto and mixed Nash equilibria 06 Deriving mixed Nash equilibria 07 Deriving Expected Utility Theory 08 Evolutionary Game Theory 09 An asymmetric evolutionary game 10 Multiplayer games 11 Public goods with punishment 12 Repeated games Lecture notes Here’s the whole collection of lecture notes for the videos:\n01 The Ultimatum Game.pdf 02 Extensive and normal form games.pdf 03 Dominance and Pareto Optimality.pdf 04 Symmetric and zero-sum games.pdf 05 Sotto vs. Blotto and mixed Nash equilibria.pdf 06 Deriving mixed Nash equilibria.pdf 07 Deriving Expected Utility Theory.pdf 08 Evolutionary Game Theory.pdf 09 An asymmetric evolutionary game.pdf 10 Multiplayer games.pdf 11 Public goods with punishment.pdf 12 Repeated games.pdf",
    "description": "Game Theory in Economics and Evolution (Fall 2016))\nExploration of human and animal interactions: integrating evolutionary and economic perspectives to investigate individual and social behaviour.",
    "tags": [],
    "title": "UBC ISCI 344 (2016)",
    "uri": "/~rikblok/teaching/past/isci344/index.html"
  },
  {
    "breadcrumb": "Mathematical musings",
    "content": "Remember Euler’s number, $e=2.71828$… ? One of the Bernoulli boys showed that it’s the limit of $(1 + 1/n)^n$ as $n$ goes to infinity. But if $n$ goes to infinity then we should be able to add an arbitrary constant $c$ to the denominator without changing the result. So, more generally,\n$$e = \\lim_{n\\rightarrow \\infty} \\left(1+\\frac{1}{n+c}\\right)^n.$$The question that came to my mind then is, what is the “best” constant to choose? It turns out you can show it’s $c=-1/2$. In other words, the limit of $(1+1/(n-1/2))^n$ converges to $e$ faster than Bernoulli’s formula (or any other $c$). In fact, it’s 99% accurate for $n=3$ (versus $n=50$ for Bernoulli).\nDerivation Here’s how I figured it out. Let’s call the $n$-th number in the sequence $E_n$:\n$$E_n = \\left(1+\\frac{1}{n+c}\\right)^n.$$Ideally, we want $E_n=e$ for all $n$. But then $c$ is no longer a constant. In fact, we can isolate $c$ in the above equation (with $E_n=e$) to find out how $c$ would depend on $n$:\n$$c(n) = \\left( e^{1/n} - 1 \\right)^{-1} - n.$$Now we want to know if $c$ converges to a constant as $n\\rightarrow\\infty$. But that’s tricky. It becomes much simpler if we take $u=1/n$ and look at what happens as $u\\rightarrow 0$.\n$$c(u) = \\left( e^u - 1 \\right)^{-1} - \\frac{1}{u}.$$Then we can expand $c$ as a Taylor series around $u=0$ (effectively, a Taylor expansion around $n=\\infty$, which is pretty cool!) to get\n$$c(u) \\approx -\\frac{1}{2} + \\frac{u}{12} + \\cdots$$So the best choice as a constant for large $n$ is $c=-1/2$ which gives a sequence\n$$E_n^{(1)} = \\left(1+\\frac{1}{n - 1/2}\\right)^n = \\left(\\frac{2 n + 1}{2 n - 1}\\right)^n.$$Higher order terms Including higher order terms in the approximation allows to find sequences that converge even faster! For example, the next order approximation would be $c(n) = -1/2 + 1/(12 n)$, which would give a sequence\n$$E_n^{(2)} = \\left( \\frac{12 n^2 + 6 n + 1}{12 n^2 - 6 n + 1} \\right)^n.$$It’s not as pretty an expression but it converges very quickly! It’s already more than 99.8% accurate for $n=1$! (For $n=1$ the result simplifies to the fraction $E_1^{(2)}=19/7\\approx 2.714$.)\nSummary I found replacing $c=0$ in the sequence $\\left(1+\\frac{1}{n+c}\\right)^n$ with $c=-1/2$ makes it converge to Euler’s number much faster as $n\\rightarrow \\infty$. Does it matter? Probably not. But I sure had a fun afternoon! :-)\n— Rik Blok, 2014",
    "description": "I found a sequence that converges to Euler’s constant faster than Bernoulli’s formula.",
    "tags": [],
    "title": "Euler's constant: An improved sequence (2014)",
    "uri": "/~rikblok/math/eulers_constant/index.html"
  },
  {
    "breadcrumb": "Academic anecdotes \u003e Old courses",
    "content": "",
    "description": "Models in Science (Fall 2009)\nMeaning, nature, use, strengths and limitations of models as investigative tools in all scientific disciplines. Detailed investigation of selected model systems from different scientific disciplines.",
    "tags": [],
    "title": "UBC ISCI 422 (2009)",
    "uri": "/~rikblok/teaching/past/isci422/index.html"
  },
  {
    "breadcrumb": "Research ramblings \u003e Published",
    "content": "Multimodal pattern formation in phenotype distributions of sexual populations Doebeli, \rBlok, \rLeimar \u0026 Dieckmann\r(2007)\rDoebeli, \rM., \rBlok, \rH., \rLeimar, \rO. \u0026 Dieckmann, \rU.\r \r(2007).\r Multimodal pattern formation in phenotype distributions of sexual populations.\rProceedings of the Royal Society B: Biological Sciences, 274(1608). 347–357.\rhttps://doi.org/10.1098/rspb.2006.3725\rAbstract During bouts of evolutionary diversification, such as adaptive radiations, the emerging species cluster around different locations in phenotype space. How such multimodal patterns in phenotype space can emerge from a single ancestral species is a fundamental question in biology. Frequency-dependent competition is one potential mechanism for such pattern formation, as has previously been shown in models based on the theory of adaptive dynamics. Here, we demonstrate that also in models similar to those used in quantitative genetics, phenotype distributions can split into multiple modes under the force of frequency-dependent competition. In sexual populations, this requires assortative mating, and we show that the multimodal splitting of initially unimodal distributions occurs over a range of assortment parameters. In addition, assortative mating can be favoured evolutionarily even if it incurs costs, because it provides a means of alleviating the effects of frequency dependence. Our results reveal that models at both ends of the spectrum between essentially monomorphic (adaptive dynamics) and fully polymorphic (quantitative genetics) yield similar results. This underscores that frequency-dependent selection is a strong agent of pattern formation in phenotype distributions, potentially resulting in adaptive speciation.\nDownload",
    "description": "Multimodal pattern formation in phenotype distributions of sexual populations",
    "tags": [],
    "title": "Doebeli, Blok, Leimar \u0026 Dieckmann (2007)",
    "uri": "/~rikblok/research/published/doebeli07/index.html"
  },
  {
    "breadcrumb": "Research ramblings \u003e Published",
    "content": "A tale of two cycles - distinguishing quasi-cycles and limit cycles in finite predator-prey populations Pineda-Krch, \rBlok, \rDieckmann \u0026 Doebeli\r(2007)\rPineda-Krch, \rM., \rBlok, \rH., \rDieckmann, \rU. \u0026 Doebeli, \rM.\r \r(2007).\r A tale of two cycles - distinguishing quasi-cycles and limit cycles in finite predator-prey populations.\rOikos, 116(1). 53–64.\rhttps://doi.org/10.1111/j.2006.0030-1299.14940.x\rAbstract Periodic predator-prey dynamics in constant environments are usually taken as indicative of deterministic limit cycles. It is known, however, that demographic stochasticity in finite populations can also give rise to regular population cycles, even when the corresponding deterministic models predict a stable equilibrium. Specifically, such quasi-cycles are expected in stochastic versions of deterministic models exhibiting equilibrium dynamics with weakly damped oscillations. The existence of quasi-cycles substantially expands the scope for natural patterns of periodic population oscillations caused by ecological interactions, thereby complicating the conclusive interpretation of such patterns. Here we show how to distinguish between quasi-cycles and noisy limit cycles based on observing changing population sizes in predator-prey populations. We start by confirming that both types of cycle can occur in the individual-based version of a widely used class of deterministic predator-prey model. We then show that it is feasible and straightforward to accurately distinguish between the two types of cycle through the combined analysis of autocorrelations and marginal distributions of population sizes. Finally, by confronting these results with real ecological time series, we demonstrate that by using our methods even short and imperfect time series allow quasi-cycles and limit cycles to be distinguished reliably.\nDownload",
    "description": "A tale of two cycles - distinguishing quasi-cycles and limit cycles in finite predator-prey populations",
    "tags": [],
    "title": "Pineda-Krch, Blok, Dieckmann \u0026 Doebeli (2007)",
    "uri": "/~rikblok/research/published/pinedakrch07/index.html"
  },
  {
    "breadcrumb": "Research ramblings \u003e Published",
    "content": "Scale-free extinction dynamics in spatially structured host–parasitoid systems Killingback, \rBlok \u0026 Doebeli\r(2006)\rKillingback, \rT., \rBlok, \rH. \u0026 Doebeli, \rM.\r \r(2006).\r Scale-free extinction dynamics in spatially structured host–parasitoid systems.\rJournal of Theoretical Biology, 241(4). 745–750.\rhttps://doi.org/10.1016/j.jtbi.2006.01.010\rAbstract Much of the work on extinction events has focused on external perturbations of ecosystems, such as climatic change, or anthropogenic factors. Extinction, however, can also be driven by endogenous factors, such as the ecological interactions between species in an ecosystem. Here we show that endogenously driven extinction events can have a scale-free distribution in simple spatially structured host-parasitoid systems. Due to the properties of this distribution there may be many such simple ecosystems that, although not strictly permanent, persist for arbitrarily long periods of time. We identify a critical phase transition in the parameter space of the host-parasitoid systems, and explain how this is related to the scale-free nature of the extinction process. Based on these results, we conjecture that scale-free extinction processes and critical phase transitions of the type we have found may be a characteristic feature of many spatially structured, multi-species ecosystems in nature. The necessary ingredient appears to be competition between species where the locally inferior type disperses faster in space. If this condition is satisfied then the eventual outcome depends subtly on the strength of local superiority of one species versus the dispersal rate of the other.\nDownload",
    "description": "Scale-free extinction dynamics in spatially structured host–parasitoid systems",
    "tags": [],
    "title": "Killingback, Blok \u0026 Doebeli (2006)",
    "uri": "/~rikblok/research/published/killingback06/index.html"
  },
  {
    "breadcrumb": "Research ramblings \u003e Unpublished notes",
    "content": "Updating in simulations of parallel Poisson processes Blok\r(2004)\rBlok, \rH.(2004, 10/15). Retrieved from \rhttp://www.zoology.ubc.ca/~rikblok/wiki/doku.php?id=random_research:rik_s_notes:parallel_poisson:start\rVersion 1 — Rik Blok, 2004-10-15\nAbstract I explore how to efficiently implement Poisson processes in event-driven, multi-agent simulations. The most efficient strategy I am able to find uses a binary tree to implement the roulette wheel algorithm and results in \\(O(\\log_2 N)\\) time to find the next event out of \\(N\\) total processes. These notes arose from discussions with Mario Pineda, Alistair Blachford, and Michael Doebeli. Unpublished.\n1. Definition — Rik Blok, 2004-09-26\nA Poisson process is a sequence of random events where the probability of an event is constant per unit time. Usually it is described in terms of a sequence of multiple events but in this discussion I will focus on the occurrence of a single event in the sequence. Let \\(c(t)\\) be the cumulative probability that the event has occurred by time t (starting at \\(t = 0\\)). Then, by the definition of a Poisson process, the probability of the event occurring between \\(t\\) and \\(t + dt\\) is given by the p.d.f.\n\\[ p(t) dt = (1 − c)r dt \\]where \\(r\\) is the average rate of the event sequence. This gives the probability that the event has not occurred yet \\((1 − c)\\) and then occurs in the specified interval \\((r dt)\\).\nSince the p.d.f. is the derivative of the cumulative, \\(p(t) \\equiv dc/dt\\), we find that\n\\[ \\frac{dc}{1-c} = r\\, dt \\]so the cumulative distribution is given by\n\\[ c(t) = 1 - e^{-r t} \\]and the p.d.f. is\n\\[ p(t) = r e^{-r t}. \\]The above gives the distribution for a single event. Below, we expand this to consider a number of possible events, each given by a Poisson process with an unique rate \\(r_j\\) . The problem is: how do we simulate such a process efficiently?\n2. Roulette wheel algorithm — Rik Blok, 2004-10-01\nIn a discrete-event simulation it is possible to sample random deviates for all possible events and construct an event queue to determine the order or events but it is cumbersome. The roulette wheel algorithm is algorithmically simpler. Given rates \\(r_j, j=1\\ldots N\\), the probability of event i acting first is\n\\[ \\Pr(i\\text{ first}) = \\frac{r_i}{\\sum_j r_j}. \\] ​\rFigure 1\rFigure 1: To select an event via the Roulette Wheel algorithm pick a random number \\(u\\) between \\(0\\) and \\(\\sum_j r_j\\). Then it will land within the area delimited by \\(r_i\\) with probability \\(r_i/\\sum_j r_j\\).\nWe can derive this from the Poisson distribution: let \\(t_i\\) be a random variable representing the waiting time to the first occurrence of event \\(i\\). Then the probability that event \\(i\\) is first (marginalizing over \\(t_i\\)) is\n\\[ \\begin{array}{rcl} \\Pr(t_i \u003c \\{t_j\\}_{j\\neq i}) \u0026 = \u0026 \\int_0^\\infty dt_i p_i(t_i) \\prod_{j\\neq i} (1 - c_j(t_i)) \\\\ \u0026 = \u0026 dt_i r_i e^{-\\sum_j r_j t_i} \\\\ \u0026 = \u0026 \\frac{r_i}{\\sum_j r_j} \\end{array} \\]where \\(p_i\\) and \\(c_i\\) represent the distributions for event \\(i\\) with rate \\(r_i\\). As shown in Figure 1, to pick an event, just pick a uniform deviate \\(0 \\leq u \u003c \\sum_j r_j\\), and select the maximum \\(i\\) such that\n\\[ \\sum_{j\\leq i} r_j \\leq u. \\]This method is simple to implement but computationally expensive since it requires \\(O(N)\\) operations (due to the summation) to compute each \\(i\\).\n3. Rejection method — Rik Blok, 2004-10-01\nAn alternative to the roulette wheel is the rejection method. The idea is to pick a random event \\(i\\) and sample whether it passes a trial. We will begin by determining what the probability of a successful trial, \\(f\\), should be. We would like the trial to be generic so that it only depends on the event rate, \\(f(r_i)\\). Given \\(N\\) processes, the probability of a single failed trial is\n\\[ \\begin{array}{rcl} \\Pr(\\text{fail trial}) \u0026 = \u0026 \\text{for any } j: \\Pr(j)\\, \\Pr(\\text{fail given }j) \\\\ \u0026 = \u0026 \\sum_j \\frac{1}{N} (1 − f(r_j)) \\\\ \u0026 = \u0026 1 − \\bar{f} \\end{array} \\]where \\(\\bar{f} = \\sum_j f(r_j)/N\\).\nThe probability of \\(k\\) failed trials followed by a successful \\(i\\) event is\n\\[ \\Pr(k\\text{ fails then }i) = \\left[1 − \\bar{f}\\right]^k \\frac{1}{N} f(r_i). \\]So the probability of choosing \\(i\\) for any number \\(k\\) of failed trials is\n\\[ \\begin{array}{rcl} \\Pr(i\\text{ first}) \u0026 = \u0026 \\sum_{k \\geq 0} \\left[1 − \\bar{f}\\right]^k \\frac{1}{N} f(r_i) \\\\ \u0026 = \u0026 \\frac{f(r_i)}{N \\bar{f}}. \\end{array} \\]Notice that this satisfies the normalization condition: \\(\\sum_i \\Pr(i) = 1\\).\nWhat we’d like to find is a form for the trial probability \\(f\\) that produces the Poisson probability:\n\\[ \\Pr(i\\text{ first}) = \\frac{r_i}{\\sum_j r_j} = \\frac{f(r_i)}{\\sum_j f(r_j)}. \\]Since this must hold independently of the rates \\(r_j\\) we must have \\(f(r_j) \\propto r_j\\) which we can write as\n\\[ f(r) = \\frac{r}{\\hat{r}} \\]for some constant \\(\\hat{r}\\).\n3.1. Efficient computation ​\rFigure 2\rFigure 2: To select an event via the rejection method pick a random event \\(i\\) and a random deviate \\(0 \u003c u \u003c \\hat{r}\\). Accept if \\(u \u003c r_i\\) otherwise repeat.\nWe want to choose \\(\\hat{r}\\) in order to minimize the computational cost of the rejection method. Recall that \\(f\\) is to be interpreted as a probability so it must obey \\(f(r_j) \\leq 1\\) for all \\(r_j\\) which means that \\(\\hat{r} \\geq \\max(r_j)\\). Each time a trial is failed more work is required for a new trial so the number of trials should be minimized. The probability of a single failed trial is \\(1−\\bar{r}/\\hat{r}\\) (where \\(\\bar{r} = \\sum_j r_j/N\\)) so the prob. of \\(k\\) trials is\n\\[ \\begin{array}{rcl} \\Pr(k\\text{ trials}) \u0026 = \u0026 \\text{for any }i:\\Pr(k − 1\\text{ fails then success with }i) \\\\ \u0026 = \u0026 \\sum_i \\left( 1 − \\frac{\\bar{r}}{\\hat{r}}\\right)^{k−1} \\frac{1}{N} \\frac{r_i}{\\bar{r}} \\\\ \u0026 = \u0026 \\left( 1 − \\frac{\\bar{r}}{\\hat{r}}\\right)^{k−1} \\frac{\\bar{r}}{\\bar{r}} \\end{array} \\]and the expected number of trials is\n\\[ \\langle k \\rangle = \\sum_k k \\Pr(k\\text{ trials}) = \\frac{\\hat{r}}{\\bar{r}}. \\] (1) So we can minimize \\(\\langle k \\rangle\\) by reducing \\(\\hat{r}\\) as much as possible, ideally by choosing \\(\\hat{r} = \\max(r_j)\\). Then the actual number of trials \\(\\langle k \\rangle\\) depends on the distribution of rates. The best case is if \\(\\max(r_j) \\propto \\bar{r}\\) so that \\(\\langle k \\rangle = O(1)\\) is independent of \\(N\\).\nBut if the rates are dynamic, if they change as the simulation progresses, then there is an added cost of continually updating \\(\\hat{r}\\). The worst choice would be to check all \\(N\\) rates and reset \\(\\hat{r}\\) appropriately whenever any rate changed. That would increase the cost of the rejection method to \\(O(N)\\) operations, no better than the Roulette Wheel.\nAn alternative would be to keep the rates sorted so that \\(r_j \\geq r_{j+1}\\) for all \\(j\\). Then \\(\\hat{r} = r_1\\), always. The cost involved would be that of adding and removing items from a sorted list. (I believe C++’s STL offers a ‘’(multi)map’’ container which is implemented as a binary tree giving typically \\(O(\\log N)\\) cost. Hash tables may also be suitable.)\nThat was assuming \\(\\hat{r}/\\bar{r}\\) was independent of \\(N\\). More realistically, we might expect the highest rate in the set to scale as \\(\\hat{r} \\propto \\bar{r} \\log N\\) so the total computational expense of this approach would grow as \\(O([\\log N]^2)\\) which is still much better than the Roulette Wheel.\n4. Faster implementation by sampling two events? — Rik Blok, 2004-10-05\nI wonder if it is possible to find an even less costly method by sampling multiple event processes and comparing them? To explore this we will consider a variant of the rejection method where the trial probability of event \\(i\\) depends on a second sampled event \\(j \\neq i, f = f(r_i, r_j)\\). If \\(i\\) is rejected then two new events are drawn. Is there a trial function \\(f\\) that reproduces the Poisson process?\nIndependent of \\(j\\) the probability of \\(i\\) passing any single trial is\n\\[ \\Pr(i\\text{ this trial}) = \\frac{1}{N(N-1)} \\sum_{j\\neq i} f(r_i,r_j). \\]The probability of failing a trial, independent of the event \\(k\\) chosen is\n\\[ \\begin{array}{rcl} \\Pr(\\text{fail}) \u0026 = \u0026 \\sum_k \\Pr(\\text{choose }k) \\Pr(\\text{fail given }k) \\\\ \u0026 = \u0026 \\sum_{k,l\\neq k} \\frac{1}{N(N-1)} (1-f(r_k,r_l)) \\\\ \u0026 = \u0026 1 - \\bar{f} \\end{array} \\]where \\(\\bar{f} = \\sum_{k,l}f(r_k,r_l)/N(N-1)\\).\nLike the rejection method, the probability of \\(m\\) failed trials then a successful event \\(i\\) is\n\\[ \\Pr(m\\text{ fails then }i) = \\left[ 1-\\bar{f} \\right]^m \\frac{1}{N(N-1)} \\sum_{j\\neq i} f(r_i,r_j) \\]so the probability of event \\(i\\) occurring first is\n\\[\\begin{array}{rcl} \\Pr(i\\text{ first}) \u0026 = \u0026 \\sum_m \\left[ 1-\\bar{f} \\right]^m \\frac{1}{N(N-1)} \\sum_{j\\neq i} f(r_i,r_j) \\\\ \u0026 = \u0026 \\frac{1}{\\bar{f}} \\sum_j \\frac{f(r_i,r_j)}{N(N-1)}. \\end{array} \\]For this to produce Poisson updating we must have\n\\[ \\frac{r_i}{\\sum_k r_k} = \\frac{\\sum_j f(r_i,r_j)}{\\sum_{k,l} f(r_k,r_l)} \\]or \\(r_k \\propto \\sum_{l\\neq k} f(r_k,r_l)\\) which means that we can write\n\\[ f(r_k,r_l) = r_k g(r_l) \\]for some unknown function \\(g\\). Rather than working with \\(g\\) directly, it is more convenient to work with the partial sum \\(G_i=\\sum_{j\\neq i} g(r_j)\\) as we see here:\n\\[ \\frac{r_i}{\\sum_k r_k} = \\frac{r_i \\sum_{j\\neq i} g(r_j)}{\\sum_k r_k \\sum_{l\\neq k} g(r_l)} = \\frac{r_i G_i}{\\sum_k r_k G_k}. \\]Recall, we are trying to detemine the form of \\(G_i\\) that reproduces Poisson updating. For arbitrary rates \\(r_k\\) the above equation reduces to \\(\\sum_k G_k = N G_i\\) for all \\(i\\), which can only be satisfied if all \\(G_i\\) are equal. In other words, \\(g(r) = \\text{const.}\\) independent of \\(r\\) so the second sampling is irrelevant and we fall back to the original rejection method. It appears there is no way to improve on the rejection method by sampling multiple events.\n5. Rejection with adaptive correction — Rik Blok, 2004-10-12\nMario came up with the idea of using the rejection method but relaxing restriction so that \\(\\hat{r} \\geq \\max(r)\\) is not strictly maintained at exactly \\(\\max(r)\\). It is cheap to enforce [with each new rate \\(r_i\\) just set \\(\\hat{r} = \\max(\\hat{r},r_i)\\) which is \\(O(1)\\)] but has a hidden cost: wasted rejection trials if \\(\\hat{r}\\) is too large. Mario’s idea was to recalculate \\(\\hat{r}\\) if the failed trials \\(k\\) were ever found to exceed some arbitrary threshold \\(k_\\max\\).\nThat’s good but I think we can do even better. There should be a way to choose how many //wasted// trials are acceptable. Recall from Eq. 1 that \\(\\langle k\\rangle =\\hat{r}/\\bar{r}\\). Since we can keep track of \\(\\bar{r}\\) in constant \\(O(1)\\) time [if a rate changes from \\(r_\\text{old}\\) to \\(r_\\text{new}\\) then \\(\\bar{r} \\gets \\bar{r} + (r_\\text{new} - r_\\text{old})/N\\) (where `\\(\\gets\\)’ represents the assignment operator)] it is possible to compute the optimal expected number of trials per event whenever \\(\\max(r)\\) is known,\n\\[ k_\\text{opt} = \\frac{\\max(r)}{\\bar{r}}. \\] (2) Now we assume that \\(k_\\text{opt}\\) remains roughly constant even as the rates change. Basically we’re assuming that \\(\\max(r) \\propto \\bar{r}\\). So we only update \\(k_\\text{opt}\\) occasionally, whenever we are sure of \\(\\max(r)\\) (to be discussed).\nHaving a fairly accurate \\(k_\\text{opt}\\) lets us estimate how many trials are being wasted because our value of \\(\\hat{r}\\) is too high. It doesn’t tell us what \\(\\hat{r}\\) should be, just when we’re spending too much effort in rejection trials. The goal then, is to determine a criterion for when it is more efficient to correct \\(\\hat{r}\\) by reiterating the entire set of rates \\(r_i\\) instead of continuing to use our inefficient estimate.\nThe first thing we need to know is \\(\\omega\\), the relative cost of one rejection trial versus one iteration of the correction loop:\n\\[ \\omega = \\frac{\\text{cost(1 rejection trial)}}{\\text{cost(1 correction loop)}}. \\]This could be computed in advance and stored as a constant.\nThen we keep track of the number of trials \\(k_e\\) actually required for every event \\(e\\). After \\(E\\) total events since the last correction the relative waste \\(W\\) on failed trials is approximately\n\\[ W = \\sum_{e=1}^E (k_e - k_\\text{opt}) \\omega. \\]It would be reasonable to expect the waste over the //next// \\(E\\) events to be similar.\nIn contrast, the (relative) cost of correction is \\(N\\). That is also the total cost over the next \\(E\\) events if we assume the correction will eliminate the waste (optimistic). We want to minimize the computation over the next \\(E\\) events, so it is better to correct if the cost of not correcting is higher: \\(W \u003e N\\).\nNote that we can compute the waste since the last correction, \\(W\\) cumulatively in \\(O(1)\\) time after each event by keeping track of the trials \\(k\\) needed to find it:\n\\[ W \\gets W + (k - k_\\text{opt}) \\omega. \\]So after each event our adaptive correction criterion is: if \\(W\u003eN\\) then correct \\(\\hat{r}\\) and \\(k_\\text{opt}\\). Note we also correct whenever we encounter a new rate higher than \\(\\hat{r}\\) because it is essentially free. Whenever a correction occurs we reset the cumulative waste \\(W=0\\).\n5.1. Implementation and test A sample implementation of adaptive correction is shown in Listing 1. A simulation based on this code was compiled and run with a range of processes from \\(N=1\\) to \\(N=10^7\\). The process rates were initially sampled (and resampled after each event) from a log-normal distribution with some spread \\(\\sigma\\) (the standard deviation of the normal distribution). For small \\(\\sigma\\) the rates tend to be narrowly distributed, as \\(\\sigma\\) grows the highest rates can grow to be many orders of magnitude faster than the slowest. The results are shown in Figure 3. Note that for small and moderate spreads (\\(\\leq 2\\) orders of magnitude) the simulation speed is \\(O(1)\\), constant independent of the number of parallel processes, \\(N\\).\n​\rListing 1\rclass TParallelPoisson { /* Intended usage: // setup TParallelPoisson pp(10);\t// pass estimated cost unsigned long trials; double maxrate, sumrates; for (int i=0; i\u003cN; i++)\tpp.adjustRate(0,rate[i]); // main loop do { maxrate = pp.getMaxRate(); event = rejection_method(N, maxrate, \u0026trials); if (pp.correctionNeeded(trials)) { find_max_rate_and_sum_rates(\u0026maxrate,\u0026sumrates); pp.setMaxRate(maxrate,sumrates); } for (EACH_RATE_CHANGED_BY_EVENT) { pp.adjustRate(oldrate,newrate); } }while (!HELL_FROZEN_OVER); */ private: double waste; double sumrates; double avgrate; unsigned long numprocesses; double opttrials; double maxrate; double cost; void setMaxRateInt(double newmaxrate) { maxrate = newmaxrate; opttrials = maxrate / avgrate; waste = 0; } public: TParallelPoisson(double newcost) { // constructor reset(); } void reset() { waste=0; sumrates=0; avgrate=0; numprocesses=0; opttrials=0; maxrate=0; cost=newcost; } inline double getMaxRate() { return maxrate; } bool correctionNeeded(unsigned long trials) { // after rejection trials update waste cumulator // and report if correction necessary waste += cost * ((double)trials - opttrials); return (waste \u003e numprocesses); } void setMaxSumRate(double newmaxrate, double newsumrates) { // sets maxrate (and sumrates if passed) maxrate = newmaxrate; sumrates = newsumrates; avgrate = sumrates / numprocesses; opttrials = maxrate / avgrate; waste = 0; } bool adjustRate(double oldrate, double newrate) { // returns true if maxrate reset numprocesses += (newrate\u003e0) - (oldrate\u003e0); sumrates += newrate - oldrate; avgrate = sumrates / numprocesses; if (newrate \u003e= maxrate) setMaxRateInt(newrate); return (newrate \u003e= maxrate); } inline double getOptTrials(){ return opttrials; } inline bool poorPerformance() { return (opttrials*cost \u003e numprocesses); } };\rListing 1: C++ implementation of adaptive correction rejection method.\n​\rFigure 3\rFigure 3: Performance of adaptive correction rejection method as a function of the number of parallel processes, \\(N\\). For low to moderate \\(N\\) and spreads the running time is roughly constant. Rates are sampled from log-normal distribution [exponential of normally-distributed deviates with mean zero and variance \\(\\sigma^2\\)]. The spread is estimated to be the ratio of the 95th upper- versus lower-percentiles of the normal distributions, \\(e^{+2\\sigma}/e^{-2\\sigma}=e^{+4\\sigma}\\). \\(10^6\\) events were simulated and on each event the associated rate was resampled.\nUnfortunately, for large spreads the news is not as good: recall from Eq. 2 the expected number of trials grows as the ratio of the maximum rate over the average rate. If the rates are widely distributed then the highest may be orders of magnitude above average. In the tests this was simulated by setting \\(\\sigma\\) large and Figure 3 demonstrates that this had a severe impact on performance (top curve) for all \\(N\\). So the efficiency of adaptive correction depends critically on the distribution of rates; ideally, it would be better to have a method that didn’t depend on the distribution (which may not be known in advance).\n6. Roulette in a tree — Rik Blok, 2004-10-14\nI’ve thought of a faster way to implement the roulette wheel method. It relies on storing partial sums on a balanced binary tree structure and should run in \\(O(\\log_2 N)\\) time, independent of the distribution of rates. Unlike the adaptive correction rejection method the rates are now explicitly stored and manipulated as part of the data structure and each process must be labelled by an index \\(i=1,\\ldots, N\\) in order to access its corresponding rate.\nThe tree, shown in Figure 4, is important because it is guaranteed to be as well balanced as possible for any number of processes, \\(N\\). Further, it is easy to add or remove processes as necessary. (Removing is done by setting the appropriate rate to zero but leaving it in the tree.) Locating a node is also efficient, requiring \\(O(\\log_2 N)\\) operations.\n​\rFigure 4\rFigure 4: A binary tree with a one-to-one mapping onto positive integers. Each node has two children indicated by the branches 0 and 1. To locate the node representing an index we represent the index in binary. Starting at the root (which is always index 1) we follow the branches by reading the binary representation from right to left until we reach the final 1. For instance, the highlighted path to \\(i=14\\) (1110 in binary) is \\(0\\rightarrow 1 \\rightarrow 1\\).\n​\rFigure 5\rFigure 5: A single node in the binary tree used to optimize the roulette wheel algorithm. Each node \\(A\\) contains a rate \\(r_A\\), sum of rates \\(\\Sigma_A\\), and links to its parent \\(P\\) and children \\(C_0\\) and \\(C_1\\). \\(\\Sigma_A\\) is the sum of all the rates down the branch of \\(A\\), including \\(r_A\\) itself, \\(\\Sigma_A = r_A + \\Sigma_{C_0} + \\Sigma_{C_1}\\). Any non-existant nodes are assumed to have \\(r=\\Sigma=0\\).\nBut the real value of the binary tree is in how it “divides and conquers” the roulette wheel. We store in each node the rate of the associated process \\(r_A\\) and the sum of the rates in all nodes beneath it \\(\\Sigma_A\\) as shown in Figure 5. Recall, in the roulette wheel we draw a single random number \\(u\\) between zero and the sum of all rates and then iterate through each process to determine which one \\(u\\) “landed” on. The binary tree reduces that process because we can determine in one comparison whether \\(u\\) landed on any processes along a branch. If it did, then we proceed down that branch and compare again, recursively, to find the node that \\(u\\) selects.\nFor a given node \\(A\\) (with children \\(C_0\\) and \\(C_1\\) as shown in Figure 5) and random \\(u\\) in \\([0,\\Sigma_A)\\) there are three possibilities: if we line up the probabilities \\(r_A\\), \\(\\Sigma_{C_0}\\), and \\(\\Sigma_{C_1}\\) for the roulette wheel (see Figure 6) then \\(u\\) will land in the domain of \\(r_A\\) or \\(\\Sigma_{C_0}\\) or \\(\\Sigma_{C_1}\\). The algorithm to choose a random event follows:\nStart at root of tree, \\(A=\\text{root}\\). If \\(u \u003c r_A\\)\tthen choose \\(A\\). Otherwise, \\(u\\gets u - r_A\\) (so that \\(u \u003c \\Sigma_{C_0} + \\Sigma_{C_1}\\)). If \\(u \u003c \\Sigma_{C_0}\\) then set focal node \\(A=C_0\\) and repeat from Step 1. Otherwise, set \\(u\\gets u - \\Sigma_{C_0}\\) (so that \\(u \u003c \\Sigma_{C_1}\\)), set focal node \\(A=C_1\\), and repeat from Step 1. The full code is given in Listing 2.\n​\rFigure 6\rFigure 6: To select an event via the binary tree Roulette Wheel algorithm pick a random number \\(u\\) between 0 and \\(\\Sigma_A = r_A + \\Sigma_{C_0} + \\Sigma_{C_1}\\). The area it lands in indicates the course of action (choose \\(A\\) or branches \\(C_0\\) or \\(C_1\\), respectively).\n​\rListing 2: parallelpoisson.h\rclass TPPNode { // nodes for TParallelPoisson tree. Each node uses ~32 bytes. private: TPPNode *odd; TPPNode *even; public: TPPNode *parent; unsigned long index; // \u003e= 1 double rate; double sum; TPPNode(TPPNode *newparent = NULL, unsigned long path = 0x1) { // constructor parent = newparent; rate = sum = 0; odd = even= NULL; // reverse path to get index for (index = 1; path \u003e 1; path = (path \u003e\u003e 1)) index = (index \u003c\u003c 1) | (path \u0026 0x1); } ~TPPNode() { // destructor if (odd) delete odd; if (even) delete even; } TPPNode *getNode(unsigned long find, bool create, unsigned long path = 0x1) { // returns pointer to node with index==find // creates node(s) if create==true, // else returns NULL if not found if (find == 1) return this; path = path \u003c\u003c 1; // shift bits if (find \u0026 0x1) { path |= 0x1; // append 1 if (!odd) { if (!create) return NULL; odd = new TPPNode(this, path); } return odd-\u003egetNode(find\u003e\u003e1, create, path); } else { if (!even) { if (!create) return NULL; even = new TPPNode(this, path); } return even-\u003egetNode(find\u003e\u003e1, create, path); } } unsigned long choose(double roulette) { if (roulette \u003c rate) return index; roulette -= rate; // now roulette \u003c odd-\u003esum + even-\u003esum double oddsum = 0, evensum = 0; if (odd) oddsum = odd-\u003esum; if (even) evensum= even-\u003esum; if (roulette \u003c oddsum) return odd-\u003echoose(roulette); return even-\u003echoose(roulette - oddsum); } }; class TParallelPoisson { /* Intended usage: // setup TParallelPoisson pp; unsigned long event; double time = 0; for (int i=1; i\u003c=N; i++) pp.setRate(i,rate[i]); // note: must be base 1! // main loop do { event = pp.choose(uniform_deviate()); time += pp.eventTime(uniform_deviate()); do_stuff(event); for (EACH_RATE_CHANGED_BY_EVENT) { pp.setRate(i,rate[i]); } } while (!HELL_FROZEN_OVER); */ private: TPPNode *root; public: TParallelPoisson() { // constructor root = new TPPNode; } ~TParallelPoisson() { // destructor if (root) delete root; root = NULL; } void reset() { if (root) delete root; root = NULL; root = new TPPNode; } double eventTime(double u) { // returns time to first event. Assumes 0 \u003c= u \u003c 1. if (!root) return 0; if (!(root-\u003esum)) return 0; return -log(1.0-u)/(root-\u003esum); } double getRate(unsigned long i) { // gets rate of node i (zero if not found) TPPNode *node=root-\u003egetNode(i,false); // don't create node if (!node) return 0; return node-\u003erate; } double setRate(unsigned long i, double newrate) { // sets rate of node i, returns old rate TPPNode *node=root-\u003egetNode(i,true); // create node if needed double oldrate = node-\u003erate; double dr = newrate - oldrate; node-\u003erate = newrate; for (; node; node = node-\u003eparent) node-\u003esum += dr; return oldrate; } double modRate(unsigned long i, double deltarate) { // adjust rate of node i, returns new rate TPPNode *node=root-\u003egetNode(i,true); // create node if needed double newrate = node-\u003erate + deltarate; node-\u003erate = newrate; for (; node; node = node-\u003eparent) node-\u003esum += deltarate; return newrate; } unsigned long choose(double u) { // chooses which event happens next, assumes 0 \u003c= u \u003c 1 if (!root) return 0; // error value if (!(root-\u003esum)) return 0; // error value return root-\u003echoose(u * root-\u003esum); } };\rListing 2: C++ implementation of binary tree roulette wheel method.\n7. References Blok\r(2004)\rBlok, \rH.(2004, 10/15). Retrieved from \rhttp://www.zoology.ubc.ca/~rikblok/wiki/doku.php?id=random_research:rik_s_notes:parallel_poisson:start",
    "description": "Updating in simulations of parallel Poisson processes",
    "tags": [],
    "title": "Blok (2004) Parallel Poisson",
    "uri": "/~rikblok/research/notes/parallel_poisson/index.html"
  },
  {
    "breadcrumb": "Academic anecdotes \u003e Old courses",
    "content": "",
    "description": "Electricity, Light and Radiation (Summer 2003)\nIntroduction to optics, electricity and magnetism, electric circuits, radioactivity, including biological applications.",
    "tags": [],
    "title": "UBC PHYS 102 (2003)",
    "uri": "/~rikblok/teaching/past/phys102/index.html"
  },
  {
    "breadcrumb": "Research ramblings \u003e Presented",
    "content": "Guest lecture for U.B.C. Physics 510: Stochastic Processes in Physics Blok\r(2003)\rBlok, \rH.\r \r(2003).\r \rSelf-affine timeseries analysis.\rAbstract A brief introduction to Lévy flight and fractional Brownian motion from the experimentalist’s perspective. Simple tools to analyze these timeseries, the Zipf plot and dispersional analysis, are presented. As a demonstration, these tools are applied to financial and meteorological data to determine the Lévy and Hurst exponents.\nDownload",
    "description": "Guest lecture for U.B.C. Physics 510: Stochastic Processes in Physics",
    "tags": [],
    "title": "Blok (2003) Self-affine timeseries analysis",
    "uri": "/~rikblok/research/presented/blok03/index.html"
  },
  {
    "breadcrumb": "Research ramblings \u003e Presented",
    "content": "SOWD (Schluter, Otto, Whitton, Whitlock, Doebeli)) Lab Meeting Blok\r(2002)\rBlok, \rH.\r \r(2002).\r \rRock, paper and scissors in space: A demonstration of R2DToo.\rAbstract Presentation given at the Dec. 2, 2002 SOWD Lab Meeting. A demonstration of how the simulation tool R2DToo can be used to solve real problems.\nDownload",
    "description": "SOWD (Schluter, Otto, Whitton, Whitlock, Doebeli)) Lab Meeting",
    "tags": [],
    "title": "Blok (2002) Rock, paper and scissors in space",
    "uri": "/~rikblok/research/presented/blok02b/index.html"
  },
  {
    "breadcrumb": "Research ramblings \u003e Presented",
    "content": "PIMS-MITACS Math Finance Seminar Blok\r(2002)\rBlok, \rH.\r \r(2002).\r \rStatistical properties of financial timeseries.\rAbstract A brief introduction to Lévy flight and fractional Brownian motion from the experimentalist’s perspective. Simple tools to analyze these timeseries, the Zipf plot and dispersional analysis, are presented. As a demonstration, these tools are applied to intraday foreign exchange data to determine the Lévy and Hurst exponents.\nDownload",
    "description": "PIMS-MITACS Math Finance Seminar",
    "tags": [],
    "title": "Blok (2002) Statistical properties of financial timeseries",
    "uri": "/~rikblok/research/presented/blok02/index.html"
  },
  {
    "breadcrumb": "Mathematical musings",
    "content": "My wife and I live in a twenty eight unit condominium which shares the cost of natural gas. Each unit has its own gas fireplace which we find is sufficient to heat our unit all year long, without resorting to electric baseboard heaters. This makes for an interesting problem in game theory: at what price level can we expect the residents to switch from heating with gas to heating with electricity?\nThe problem is only interesting when the cost of heating with gas is on the same order as electric heat. If one source is much cheaper than the other then it is the rational choice. As I write this the cost of gas is roughly (if I did the math right!) 3/4 the cost of electricity (measured in dollars per unit of energy). This neglects some issues such as efficiency of turning the energy into heat, etc. but at least it gives us a ballpark figure. Clearly, the problem is relevant.\nI’m going to demonstrate two solutions to the problem. The first ignores game theory and gives a trivial, intuitive result. The second, using game theory, gives a more likely–and drastically worse–result.\nSolution 1: Self-consistency First, some definitions:\n$T$ total heating cost over some fixed period (eg. one year), $N$ number of units in condo (eg. $N=28$), $E$ total units of energy used to heat home, $f$ ratio of gas price rate to electricity rate (eg. $f=3/4$), $r_e$ cost per unit energy for electricity, $r_g$ cost per unit energy for gas ($r_g=f r_e$), and $g$ fraction of heat generated by gas, for a single resident (between zero and one). Ok, to state it mathematically, we want to find the fraction $g$ which minimizes the total cost $T$ each resident spends. For this first solution, we assume each resident is going to do the same thing because they all want to minimize $T$.\nSo each resident’s cost for electric heat is $(1-g) E r_e$ and the total cost of gas for the entire building is $N g E r_g$, which is split uniformly between the $N$ condos. So the total cost to each condo is\n$$ T = (1-g) E r_e + g E r_g = E r_e [1+(f-1)g]. $$So what would each resident choose for $g$ in order to minimize $T$? Simple: if $f\u003c1$ then choose $g=1$ and if $f\u003e1$ then choose $g=0$. This just means the rational way to heat your home is with whichever source is cheaper. That seems obvious doesn’t it?\nSolution 2: Game theoretic If you agree with the first solution this one might surprise you. Again, we need a few definitions. Instead of everybody applying the same behaviour $g$, lets consider what I should do as a resident versus what everybody else is doing:\n$g_\\text{me}$ the fraction $g$ for me, as a resident, or $g_\\text{other}$ the fraction $g$ averaged over all other residents. Now there are three costs: my electricity, $(1-g_\\text{me}) E r_e$, my gas, $g_\\text{me} E r_g$, and everybody else’s gas, $(N-1) g_\\text{other} E r_g$. As before, these last two terms are shared by all $N$ residents so my total cost is\n$$ \\begin{array}{rl} T \u0026 = (1-g_\\text{me}) E r_e + [g_\\text{me} E r_g + (N-1) g_\\text{other} E r_g]/N \\\\ \u0026 = E r_e [1+(N-1) g_\\text{other} f / N + (f/N - 1) g_\\text{me}]. \\end{array} $$Notice that I only have control over my own actions, $g_\\text{me}$. I can’t hope to influence other people’s behaviour so $g_\\text{other}$ is effectively constant, independent of what I do. So, to minimize T all I can do is try to minimize the very last term $(f/N - 1) g_\\text{me}$. This is achieved with $g_\\text{me}=1$ when $f\u003cN$ and $g_\\text{me}=0$ when $f\u003eN$.\nTragedy of the commons Compare these two solutions: the first says I should use gas only if it is cheaper than electricity, but the second says I should keep using it until it is $N$ times more expensive than electricity! ($N=28$ in my building.)\nIf that’s the optimal behaviour for me, then the same should hold for every resident in the building. So, when $1\u003cf\u003cN$ we are all going to be paying more for heating than we need to! Strange but true. This dilemma is known as the tragedy of the commons. It happens because nobody can improve their situation by changing their behaviour unless everyone else changes, too.\nFortunately, there are ways to get around this kind of dilemma. What you have to do is change the rules of the game. For example, if the price of gas got too high we could have an emergency strata meeting to vote on the option of shutting off the gas to the entire building. (Other, less totalitarian solutions are probably also available…)\n— Rik Blok, 2002",
    "description": "My wife and I live in a twenty eight unit condominium which shares the cost of natural gas.  At what price level can we expect the residents to switch from heating with gas to heating with electricity?",
    "tags": [],
    "title": "Shared Gas: A 'Tragedy' of the Commons (2002)",
    "uri": "/~rikblok/math/shared_gas/index.html"
  },
  {
    "breadcrumb": "Research ramblings \u003e Presented",
    "content": "Presentation for Doebeli lab meeting Blok\r(2001)\rBlok, \rH.\r \r(2001).\r \rCan memes drive genes?.\rAbstract Assuming culture is transmitted horizontally (via imitation) a model was constructed to determine the conditions under which culture can dominate genetic evolution (“get off the leash” according to Blackmore (\rCitation: 2000 Blackmore, \rS. \r(2000).\r \rThe meme machine.\r \rOxford University Press.\r)\r). Two requirements were found: (1) culture must compete with genes (required only for the effect to be empirically testable); and (2) Interactions between individuals must be confined to small groups or neighbourhoods. The model was tested via analysis and simulation.\nIn this talk I will present the model, analysis, and simulation results. Feedback is appreciated.\nDownload",
    "description": "Presentation for Doebeli lab meeting",
    "tags": [],
    "title": "Blok (2001) Can memes drive genes?",
    "uri": "/~rikblok/research/presented/blok01/index.html"
  },
  {
    "breadcrumb": "Research ramblings \u003e Presented",
    "content": "On the nature of the stock market: Simulations and experiments Blok\r(2000)\rBlok, \rH.\r \r(2000).\r \rOn the nature of the stock market: Simulations and experiments (Departmental defense).\rDownload",
    "description": "On the nature of the stock market: Simulations and experiments",
    "tags": [],
    "title": "Blok (2000) Final PhD oral defense",
    "uri": "/~rikblok/research/presented/blok00c/index.html"
  },
  {
    "breadcrumb": "Research ramblings \u003e Published",
    "content": "On the nature of the stock market: Simulations and experiments Blok\r(2000)\rBlok, \rH.\r \r(2000).\r \rOn the nature of the stock market: Simulations and experiments\r. \rUniversity of British Columbia\r Retrieved from \rhttp://hdl.handle.net/2429/11108\rAbstract Over the last few years there has been a surge of activity within the physics community in the emerging field of Econophysics - the study of economic systems from a physicist’s perspective. Physicists tend to take a different view than economists and other social scientists, being interested in such topics as phase transitions and fluctuations.\nIn this dissertation two simple models of stock exchange are developed and simulated numerically. The first is characterized by centralized trading with a market maker. Fluctuations are driven by a stochastic component in the agents’ forecasts. As the scale of the fluctuations is varied a critical phase transition is discovered. Unfortunately, this model is unable to generate realistic market dynamics.\nThe second model discards the requirement of centralized trading. In this case the stochastic driving force is Gaussian-distributed “news events” which are public knowledge. Under variation of the control parameter the model exhibits two phase transitions: both a first- and a second-order (critical).\nThe decentralized model is able to capture many of the interesting properties observed in empirical markets such as fat tails in the distribution of returns, a brief memory in the return series, and long-range correlations in volatility. Significantly, these properties only emerge when the parameters are tuned such that the model spans the critical point. This suggests that real markets may operate at or near a critical point, but is unable to explain why this should be. This remains an interesting open question worth further investigation.\nOne of the main points of the thesis is that these empirical phenomena are not present in the stochastic driving force, but emerge endogenously from interactions between agents. Further, they emerge despite the simplicity of the modeled agents; suggesting complex market dynamics do not arise from the complexity of individual investors but simply from interactions between (even simple) investors.\nAlthough the emphasis of this thesis is on the extent to which multi-agent models can produce complex dynamics, some attempt is also made to relate this work with empirical data. Firstly, the trading strategy applied by the agents in the second model is demonstrated to be adequate, if not optimal, and to have some surprising consequences.\nSecondly, the claim put forth by Sornette et al. (\rCitation: 1996 Sornette, \rD., \rJohansen, \rA. \u0026 Bouchaud, \rJ.\r \r(1996).\r Stock Market Crashes, Precursors and Replicas.\rJournal de Physique I, 6(1). 9.\rhttps://doi.org/10.1051/jp1:1996135\r)\rthat large financial crashes may be heralded by accelerating precursory oscillations is also tested. It is shown that there is weak evidence for the existence of log-periodic precursors but the signal is probably too indistinct to allow for reliable predictions.\nDownload Individual sections\nFront matter Chapter 1: Introduction Chapter 2: Centralized Stock Exchange Model Chapter 3: Decentralized Stock Exchange Model Chapter 4: Analysis and results: Phase space Chapter 5: Analysis and results: Empirical results Chapter 6: Experiments with a hypothetical portfolio Chapter 7: Concluding remarks Bibliography Appendix A: Discounted least-squares curve fitting Appendix B: Sampling discrete processes Appendix C: Long-range memory: The Hurst exponent",
    "description": "On the nature of the stock market: Simulations and experiments",
    "tags": [],
    "title": "Blok (2000)",
    "uri": "/~rikblok/research/published/blok00b/index.html"
  },
  {
    "breadcrumb": "Academic anecdotes \u003e Old courses",
    "content": "",
    "description": "Elements of Physics (Winter 2000)\nThermometry, thermal properties of matter, heat, oscillations, waves, sound, wave optics; geometrical optics, elementary electricity and magnetism, simple DC and AC circuits.",
    "tags": [],
    "title": "UBC PHYS 153 (2000)",
    "uri": "/~rikblok/teaching/past/phys153/index.html"
  },
  {
    "breadcrumb": "Research ramblings \u003e Published",
    "content": "Synchronous versus asynchronous updating in the “game of Life” Blok \u0026 Bergersen\r(1999)\rBlok, \rH. \u0026 Bergersen, \rB.\r \r(1999).\r Synchronous versus asynchronous updating in the “game of Life”.\rPhysical Review E, 59(4). 3876–3879.\rhttps://doi.org/10.1103/PhysRevE.59.3876\rAbstract The rules for the “game of Life” are modified to allow for only a random fraction of sites to be updated in each time step. Under variation of this fraction from the parallel updating limit down to the Poisson limit, a critical phase transition is observed that explains why the game of Life appears to obey self-organized criticality. The critical exponents are calculated and the static exponents appear to belong to the directed percolation universality class in 2+1 dimensions. The dynamic exponents, however, are nonuniversal, as seen in other systems with multiple absorbing states.\nDownload",
    "description": "Synchronous versus asynchronous updating in the “game of Life”",
    "tags": [],
    "title": "Blok \u0026 Bergersen (1999)",
    "uri": "/~rikblok/research/published/blok99/index.html"
  },
  {
    "breadcrumb": "Research ramblings \u003e Presented",
    "content": "Presentation for UBC PHYS 510 Blok\r(1998)\rBlok, \rH.\r \r(1998).\r \rModelling Intentionality: The Gambler.\rDownload",
    "description": "Presentation for UBC PHYS 510",
    "tags": [],
    "title": "Blok (1998) Modelling intentionality: The gambler",
    "uri": "/~rikblok/research/presented/blok98/index.html"
  },
  {
    "breadcrumb": "Research ramblings \u003e Presented",
    "content": "Presentation for Peter Wall Inst. Adv. Science, Crisis Points Group, UBC Blok\r(1998)\rBlok, \rH.\r \r(1998).\r \rExtra! Extra! Critical Update on Life.\rDownload",
    "description": "Presentation for Peter Wall Inst. Adv. Science, Crisis Points Group, UBC",
    "tags": [],
    "title": "Blok (1998) Extra! Extra! Critical update on 'Life'",
    "uri": "/~rikblok/research/presented/blok98b/index.html"
  },
  {
    "breadcrumb": "Research ramblings \u003e Unpublished notes",
    "content": "Discounted Least Squares Curve Fitting Blok\r(1997)\rBlok, \rH.(1997, 7/20). Retrieved from \rhttp://www.zoology.ubc.ca/~rikblok/wiki/doku.php?id=random_research:rik_s_notes:discounted_least_squares:start\rVersion 1 — Rik Blok, 1997-07-20\n1. Introduction I recently wrote some code to make simple forecasts in a time series (a steadily accumulating set of \\((x,y)\\) data points). For its simplicity, I chose a least-squares fit to a straight line. The underlying behaviour of the system was continuously changing so it was unreasonable to expect the same parameters to be valid for all the data. As new data came in, I expected old data to become irrelevant, and I handled this by only fitting over the last \\(N\\) data points. Unfortunately, it became evident that this arbitrary parameter \\(N\\) I had chosen was very important to the fit, often producing pathological results: as \\(N\\) new data points were accumulated after an outlier (a strongly atypical \\(y\\)-value), it would suddenly be dropped from consideration and the forecast would undergo a discontinuous “jump”. I began to wonder if there was a way of steadily discounting the relevance of past data in a smoother and more natural way…\n(Note: much of the text written here is a blatant copy from Press et al. (\rCitation: 1992 Press, \rW., \rTeukolsky, \rS., \rVetterling, \rW. \u0026 Flannery, \rB. \r(1992).\r \rNumerical Recipes in C: The Art of Scientific Computing (Second).\r \rCambridge University Press. Retrieved from \rhttp://www.nr.com/\r)\r. They said it so well, I could not word it any better myself. In Chapter 16 they derive the least-squares technique I described above.)\n2. Solution We use the index \\(i\\) to label our data points where \\(i=0\\) indicates the most recently acquired data and \\(i=1,2,3,\\ldots\\) indicate successively older data. Each data point consists of a triplet \\((x,y,\\sigma)\\) where \\(x\\) is the independent variable (eg. time), \\(y\\) is the dependent variable, and \\(\\sigma\\) is the associated measurement error in \\(y\\).\nAs new data arrives \\((x_0,y_0,\\sigma_0)\\) we shift the indices of prior data to make room, and scale up the errors by some factor \\(\\gamma\\in (0,1)\\):\n\\[ (x_{i+1},y_{i+1},\\sigma_{i+1})\\leftarrow (x_i, y_i,\\sigma_i/\\gamma). \\]If we define \\(\\sigma_i^*\\) as the original value of \\(\\sigma_0\\) then after applying \\(i\\) of the above operations\n\\[ \\sigma_i = \\sigma_i^*/\\gamma^i \\] (2.1) so, since \\(\\gamma\u003c1\\), the historical deviations grow exponentially as new information is acquired.\nWe wish to fit data to a model which is a linear combination of any \\(M\\) specified functions of \\(x\\). For example, the functions could be \\(1,x,x^2,\\ldots,x^{M-1}\\), in which case their general linear combination,\n\\[ y(x) = a_1 + a_2 x + \\cdots + a_M x^{M-1} \\]is a polynomial of degree \\(M-1\\). The general form of this kind of model is\n\\[ y(x) = \\sum_{j=1}^M a_j X_j(x) \\] (2.2) where \\(X_1(x),\\ldots,X_M(x)\\) are arbitrary fixed functions of \\(x\\), called the basis functions. Note that the functions \\(X_j(x)\\) can be wildly nonlinear functions of \\(x\\). In this discussion “linear” refers only to the model’s dependence on its parameters \\(a_j\\).\nFor these linear models we define a merit function\n\\[ \\chi^2 = \\sum_{i=0}^N \\left[ \\frac{y_i - \\sum_j a_j X_j(x_i)}{\\sigma_i} \\right]^2. \\] (2.3) We will pick as best parameters those that minimize \\(\\chi^2\\). There are several different techniques for finding this minimum. We will focus on one: the singular value decomposition of the normal equations. To introduce it we need some notation.\nLet \\({\\bf A}\\) be a matrix whose \\(N\\times M\\) components are constructed from the \\(M\\) basis functions evaluated at the \\(N\\) abscissas \\(x_i\\), and from the \\(N\\) measurement errors \\(\\sigma_i\\), by the prescription\n\\[ A_{ij} = \\frac{X_j(x_i)}{\\sigma_i}. \\] (2.4) The matrix \\({\\bf A}\\) is called the design matrix of the fitting problem. Notice that in general \\(\\bf A\\) has more rows than columns, \\(N\\geq M\\), since there must be more data points than model parameters to be solved for.\nAlso define a vector \\(\\bf b\\) of length \\(N\\) by\n\\[ b_i = \\frac{y_i}{\\sigma_i} \\]and denote the \\(M\\) vector whose components are the parameters to be fitted, \\(a_1,\\ldots,a_M\\), by \\(\\bf a\\).\nIf we take the derivative of Eq. (2.3) with respect to all \\(M\\) parameters \\(a_j\\), we obtain \\(M\\) equations that must hold at the chi-square minimum,\n\\[ 0 = \\frac{1}{\\sigma_i^2} \\left[ y_i - \\sum_j a_j X_j(x_i) \\right] X_k(x_i)\\;\\; k=1,\\ldots,M. \\] (2.5) Interchanging the order of summations, we can write Eq. (2.5) as the matrix equation\n\\[ \\sum_j \\alpha_{kj} a_j = \\beta_k \\] (2.6) where\n\\[ \\alpha_{kj} = \\sum_i \\frac{X_j(x_i) X_k(x_i)}{\\sigma_i^2} \\text{ or equivalently } [\\alpha] = {\\bf A}^T\\cdot {\\bf A} \\] (2.7) an \\(M\\times M\\) matrix, and\n\\[ \\beta_k = \\sum_i \\frac{y_i X_k(x_i)}{\\sigma_i^2} \\text{ or equivalently } [\\beta] = {\\bf A}^T\\cdot {\\bf b} \\] (2.8) a vector of length \\(M\\).\nEq. (2.5) or (2.6) are called the normal equations of the least-squares problem. They can be solved for the vector parameters \\(\\bf a\\) by singular value decomposition (SVD). SVD solves fixes many difficulties in the normal equations, including susceptibility to round-off errors. SVD can be significantly slower than other methods; however, its great advantage, that it (theoretically) cannot fail, more than makes up for the speed disadvantage. A good review of SVD techniques can be found in Press et al. (\rCitation: 1992 Press, \rW., \rTeukolsky, \rS., \rVetterling, \rW. \u0026 Flannery, \rB. \r(1992).\r \rNumerical Recipes in C: The Art of Scientific Computing (Second).\r \rCambridge University Press. Retrieved from \rhttp://www.nr.com/\r)\rSection 2.6. In matrix form, the normal equations can be written as\n\\[ [\\alpha]\\cdot {\\bf a}=[\\beta]. \\] (2.9) 3. Covariance matrix Let us define\n\\[ [C] = [\\alpha]^{-1}. \\] (3.1) Then\n\\[ {\\bf a}=[C]\\cdot [\\beta] \\text{ or } a_j = \\sum_k C_{jk} \\beta_k \\]which allows us to determine \\(\\bf a\\)’s dependence on the \\(y_i\\) values. From Eq. (2.7) we see that \\([C]\\) is independent of \\(y_i\\) so\n\\[ a_j = \\sum_j C_{jk} \\sum_i A_{ik} \\frac{y_i}{\\sigma_i} \\] (3.2) and\n\\[ \\frac{\\partial a_j}{\\partial y_i} = \\sum_k C_{jk} \\frac{A_{ik}}{\\sigma_i}. \\]The covariance between two parameters \\(a_j\\) and \\(a_k\\) is defined as\n\\[ \\begin{array}{rcl} \\text{Covar}[a_j,a_k] \u0026 \\equiv \u0026 \\sum_i \\sigma_i^2 \\frac{\\partial a_j}{\\partial y_i} \\frac{\\partial a_k}{\\partial y_i} \\\\ \u0026 = \u0026 \\sum_i \\sigma_i^2 \\sum_{lm} C_{jl} \\frac{A_{il}}{\\sigma_i} \\frac{A_{im}}{\\sigma_i} \\\\ \u0026 = \u0026 \\sum_{lm} C_{jl} C_{km} \\alpha_{ml} \\end{array} \\] (3.3) but since \\([C]=[\\alpha]^{-1}\\) so\n\\[ \\sum_m C_{km} \\alpha_{ml} = \\delta_{kl} \\text{ or } [C][\\alpha]={\\bf 1} \\]where \\(\\delta_{kl}\\) is the Kronecker delta function. Hence Eq. (3.3) reduces to\n\\[ \\text{Covar}[a_j,a_k] = C_{jk} \\] (3.4) and we find that \\([C]\\) is the covariance matrix. The variance of a single parameter \\(a_j\\) is simply defined as\n\\[ \\text{Var}[a_j]=\\text{Covar}[a_j,a_j]=C_{jj}. \\] (3.5) 4. Storage and updating So far we have made no mention of \\(N\\), the number of data points to be fit. As we will see an advantage of the discounted least squares method is that \\(N\\) becomes irrelevant. As data points are accumulated the oldest data becomes decreasingly relevant and eventually contribute negligibly to the fitting procedure. Hence we can theoretically apply this data to an infinite data set. But can this be practically implemented? The answer is…Yes!\nNotice that as we acquire new data \\((x_0,y_0,\\sigma_0)\\) according to Eq. (2.7) and (2.8) the matrix \\([\\alpha]\\) and vector \\([\\beta]\\) update as\n\\[ \\alpha_{kj} \\leftarrow A_{0j} A_{0k} + \\gamma^2 \\alpha_{kj} = \\frac{X_j(x_0) X_k(x_0)}{\\sigma_0^2} + \\gamma^2 \\alpha_{kj} \\] (4.1) and\n\\[ \\beta_j \\leftarrow A_{0j} b_0 + \\gamma^2 \\beta_j = \\frac{X_j(x_0) y_0}{\\sigma_0^2} + \\gamma^2 \\beta_j \\] (4.2) so it becomes clear that we need not even store the history of data points, but should rather store just \\([\\alpha]\\) and \\([\\beta]\\) and update them as new data is accumulated.\nA useful measure we have neglected to calculate so far is \\(\\chi^2\\),the chi-square statistic itself. In matrix notation Eq. (2.3) can be written\n\\[ \\begin{array}{rcl} \\chi^2 \u0026 = \u0026 ({\\bf a}^T \\cdot {\\bf A}^T - {\\bf b}^T) \\cdot ({\\bf A} \\cdot {\\bf a}-{\\bf b}) \\\\ \u0026 = \u0026 {\\bf a}^T \\cdot {\\bf A}^T \\cdot {\\bf A} \\cdot {\\bf a} - {\\bf b}^T \\cdot {\\bf A} \\cdot {\\bf a} - {\\bf a}^T \\cdot {\\bf A}^T \\cdot {\\bf b} + {\\bf b}^T \\cdot {\\bf b} \\\\ \u0026 = \u0026 {\\bf a}^T \\cdot ([\\alpha] \\cdot {\\bf a} - [\\beta]) - [\\beta]^T \\cdot {\\bf a} + {\\bf b}^T \\cdot {\\bf b} \\\\ \u0026 = \u0026 {\\bf b}^T \\cdot {\\bf b} - [\\beta]^T \\cdot {\\bf a} \\end{array} \\]which appears to still depend on the data history in the first term. Let us define this term as a new variable \\(\\delta\\),\n\\[ \\delta \\equiv {\\bf b}^T \\cdot {\\bf b} = \\sum_i b_i^2. \\]Then, similarly to Eq. (4.1) and (4.2) \\(\\delta\\) can be updated as more information is accumulated\n\\[ \\delta \\leftarrow b_0^2 + \\gamma^2 \\delta = \\frac{y_0^2}{\\sigma_0^2} + \\gamma^2 \\delta. \\] (4.3) ​\rFigure 4.1\rFigure 4.1: Discounted least-squares fitting has a computational storage advantage over traditional least-squares when \\(N\u003eM^2+M+4\\) where \\(N\\) is the number of data points and \\(M\\) is the number of parameters to be fitted.\nSo, to store all relevant history information we need only remember \\([\\alpha]\\), \\([\\beta]\\), and \\(\\delta\\) as well as the latest data triplet \\((x_0,y_0,\\sigma_0)\\) for a total of \\(M^2+M+4\\) numbers, regardless of how many data points have been acquired. Figure 4.1 shows that for many practical problems discounted least-squares fitting requires less storage than other methods. Although it has not been tested, we expect a similar condition to hold for processing time because the number of calculations depend only on \\(M\\) instead of \\(M\\) and \\(N\\) as in traditional least-squares methods.\nAs the reader can justify, all of these values should be initialized (prior to any data) with null values: \\([\\alpha]={\\bf 0}\\), \\([\\beta]={\\bf 0}\\), and \\(\\delta=0\\).\n5. Memory, effective number of data points For traditional least-squares fitting it is well known that if the measurement errors of \\(y_i\\) are distributed normally then the method is a maximum likelihood estimation and the expectation value (average) of Eq. (2.3) evaluates to\n\\[ \\left\\langle \\chi^2 \\right\\rangle = N-M. \\]This arises because \\((y_i - y(x_i))/\\sigma_i\\) is distributed normally with mean 0 and variance 1, so the sum of \\(N\\) variances should equate to \\(N\\). The subtraction of \\(M\\) is necessary because \\(M\\) parameters can be adjusted to actually reduce the variances further. For instance, with \\(N=M=1\\) we can adjust the single parameter such that the curve passes precisely through the point \\((x_0,y_0)\\), with zero variance. Similarly, for our method\n\\[ \\begin{array}{rcl} \\left\\langle \\chi^2 \\right\\rangle \u0026 = \u0026 \\sum_{i=0}^\\infty \\gamma^{2 i} \\left\\langle \\left[ \\frac{y_i-y(x_i)}{\\sigma_i^*}\\right]^2 \\right\\rangle - M \\\\ \u0026 = \u0026 \\sum_{i=0}^\\infty \\gamma^{2 i} - M \\\\ \u0026 = \u0026 \\frac{1}{1-\\gamma^2} - M \\end{array} \\] (5.1) which strongly suggests an effective number of data points\n\\[ N_{eff} \\equiv \\frac{1}{1-\\gamma^2}. \\] (5.2) 5.1. Memory We now undertake a thought experiment to understand how \\(N_{eff}\\) comes into play. Consider a single parameter fit \\(X(x_i)=1\\) or \\(y(x_i)=a\\) to a long history of values \\(y_i=1\\) (regardless of \\(x_i\\)). Updating according to Eq. (4.1), (4.2), and (4.3) gives\n\\[ \\begin{array}{rcr} \\alpha \u0026 \\leftarrow \u0026 1 + \\gamma^2 \\alpha \\\\ \\beta \u0026 \\leftarrow \u0026 y + \\gamma^2 \\beta \\\\ \\delta \u0026 \\leftarrow \u0026 y^2 + \\gamma^2 \\delta \\end{array} \\]so after a long history of \\(y=1\\),\n\\[ \\begin{array}{rl} \\alpha \u0026 = 1 + \\gamma^2 \\left( 1 + \\gamma^2(\\cdots)\\right) = 1 + \\gamma^2 + \\gamma^4 + \\cdots \\\\ \u0026 = \\frac{1}{1-\\gamma^2} = \\beta = \\delta \\end{array} \\]which has a solution, in one dimension, of\n\\[ a = \\frac{\\beta}{\\alpha} \\]or \\(y(x)=a=1\\).\nNow consider a sudden shift in the data stream to \\(y_i=0\\) (like a step function). How will this change our curve fit? The value of \\(\\alpha\\) remains unchanged but \\(\\beta\\) and \\(a\\) change as follows:\n\\(y\\) \\(\\beta\\) \\(a\\) \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) \\(1\\) \\(\\alpha\\) \\(1\\) \\(0\\) \\(\\gamma^2 \\alpha\\) \\(\\gamma^2\\) \\(0\\) \\(\\gamma^4 \\alpha\\) \\(\\gamma^4\\) \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) Notice that \\(a\\) decays exponentially to the new equilibrium \\(a=0\\). The time constant \\(\\tau\\) for the system (time for \\(a\\) to decay to \\(1/e\\)) is\n\\[ \\begin{array}{l} \\left( \\gamma^2 \\right)^\\tau = e^{-1} \\\\ \\Rightarrow \\tau = \\frac{-1}{2 \\ln \\gamma} \\end{array} \\]which is, as Figure 5.1 shows, almost identical to \\(N_{eff}\\) for all \\(\\gamma\\).\n​\rFigure 5.1\rFigure 5.1: The difference between \\(N_{eff}\\) and \\(\\tau\\) is strictly less than one. The main difference between the two is that \\(\\sigma_{N_{eff}} \\rightarrow \\infty \\) as \\(N_{eff}\\rightarrow 1\\) (as it should) while \\(\\sigma_\\tau = \\sqrt{e} \\sigma_\\tau^*\\) for all \\(\\tau\\). They converge as \\(N_{eff}\\rightarrow \\infty\\).\nThus, \\(N_{eff}\\) is indeed a practical measure of the effective number of data points in a fit. The fit is dominated by the most recent data \\(i\\leq N_{eff}\\), and \\(N_{eff}\\) acts as the memory of the fitting procedure.\n6. Unknown measurement errors On occasion measurement uncertainties are unknown and least-squares fitting can be used to recover an estimate of these uncertainties. Be forewarned that this technique assumes normally distributed y data with identical variances. If this is not the case, the results become meaningless. It also precludes the use of a “goodness-of-fit” estimator (such as the incomplete gamma function, see Press et al. (\rCitation: 1992 Press, \rW., \rTeukolsky, \rS., \rVetterling, \rW. \u0026 Flannery, \rB. \r(1992).\r \rNumerical Recipes in C: The Art of Scientific Computing (Second).\r \rCambridge University Press. Retrieved from \rhttp://www.nr.com/\r)\rSection 6.2) because it assumes a good fit.\nWe begin by assuming \\(\\sigma_i^*=1\\) for all data points and proceeding with our calculations of \\(\\bf a\\) and \\(\\chi^2\\). If all (unknown) variances are equal \\(\\sigma^*=\\sigma_i^*\\) then Eq. (5.1) actually becomes\n\\[ \\left\\langle \\chi^2 \\right\\rangle = (N_{eff} - M) \\sigma^{*2} \\]so the actual data variance should be\n\\[ \\sigma^{*2} = \\frac{\\chi^2}{N_{eff}-M}. \\] (6.1) We can update our parameter error estimates by recognizing that, from Eq. (3.2) and Eq. (2.4), the covariance matrix is proportional to the variance in the data, so\n\\[ C_{jk} \\leftarrow \\frac{\\chi^2}{N_{eff}-M} C_{jk}. \\] (6.2) 7. Forecasting Forecasting via curve fitting is a dangerous proposition because it requires extrapolating into a region beyond the scope of the data, where different rules may apply, and hence, different parameter values. Nevertheless, it often used simply for its convenience. We assume the latest parameter estimations apply at the forecasted point \\(x\\) and simply use Eq. (2.2) to predict \\(y(x)\\).\nThe uncertainty in the prediction can be estimated from the covariance matrix. The definition of variance for any distribution is the expectation value of the squared difference from the mean:\n\\[ \\text{Var}[z] \\equiv \\left\\langle \\left( z - \\langle z \\rangle \\right)^2 \\right\\rangle \\]and the covariance between two variables is defined as\n\\[ \\text{Covar}[z_1,z_2] \\equiv \\left\\langle \\left( z_1 - \\langle z_1 \\rangle \\right) \\left( z_2 - \\langle z_2 \\rangle \\right) \\right\\rangle \\]so Eq. (2.2) has a variance\n\\[ \\begin{array}{rcl} \\text{Var}[y(x)] \u0026 = \u0026 \\text{Var}\\left[ \\sum_j a_j X_j(x) \\right] \\\\ \u0026 = \u0026 \\left\\langle \\left( \\sum_j a_j X_j(x) - \\sum_j \\langle a_j \\rangle X_j(x) \\right) ^2 \\right\\rangle \\\\ \u0026 = \u0026 \\sum_{jk} X_j(x) \\left\\langle \\left( a_j - \\langle a_j \\rangle \\right) \\left( a_k - \\langle a_k \\rangle \\right) \\right\\rangle X_k(x) \\\\ \u0026 = \u0026 \\sum_{jk} X_j(x) \\text{Covar}[a_j,a_k] X_k(x) \\\\ \u0026 = \u0026 X_j(x) C_{jk} X_k(x) \\end{array} \\]where \\([C]\\) is the covariance matrix discussed in Section 3 with possible updating, in the absence of measurement errors, according to Eq. (6.2).\nThe above gives the uncertainty in \\(y(x)\\), but in our derivation we have assumed the observed \\(y\\)-values were distributed normally around the curve where \\(y(x)\\) represents the mean of the distribution. Similarly for our prediction, \\(y(x)\\) is the prediction of the mean with its own uncertainty—-on top of which there is the measurement uncertainty of data around the mean. If the expected measurement uncertainty is given by \\(\\sigma'\\) then the predicted observation \\(y' \\sim N(y(x),\\sigma')\\) or, with the substitution\n\\[ z' = y' - y(x) \\]we assume \\(z' \\sim N(0,\\sigma')\\) regardless of the prediction \\(y(x)\\). In other words, \\(z'\\) and \\(y(x)\\) are mutually independent.\n\\[ \\begin{array}{rcl} \\text{Var}[y'] \u0026 = \u0026 \\text{Var}[y(x) + z'] \\\\ \u0026 = \u0026 \\left\\langle \\left( y(x) - \\langle y(x) \\rangle + z' - \\langle z' \\rangle \\right)^2 \\right\\rangle \\\\ \u0026 = \u0026 \\left\\langle \\left( y(x) - \\langle y(x) \\rangle \\right)^2 + \\left( z' - \\langle z' \\rangle \\right)^2 + 2 \\left( y(x) - \\langle y(x) \\rangle \\right) \\left( z' - \\langle z' \\rangle \\right) \\right\\rangle \\\\ \u0026 = \u0026 \\left\\langle \\left( y(x) - \\langle y(x) \\rangle \\right)^2 \\right\\rangle + \\left\\langle \\left( z' - \\langle z' \\rangle \\right)^2 \\right\\rangle + 2 \\left\\langle \\left( y(x) - \\langle y(x) \\rangle \\right) \\left( z' - \\langle z' \\rangle \\right) \\right\\rangle \\\\ \u0026 = \u0026 \\text{Var}[y(x)] + \\text{Var}[z']. \\end{array} \\]The last step of dropping the covariance term is allowed because when two distributions are independent\n\\[ \\left\\langle \\left( z_1 - \\langle z_1 \\rangle \\right) \\left( z_2 - \\langle z_2 \\rangle \\right) \\right\\rangle = \\left\\langle z_1 - \\langle z_1 \\rangle \\right\\rangle \\left\\langle z_2 - \\langle z_2 \\rangle \\right\\rangle = 0 \\]so our final results for the forecast \\(y'\\) at \\(x\\) are\n\\[ \\begin{array}{rcl} \\langle y' \\rangle \u0026 = \u0026 y(x) = \\sum_j a_j X_j(x) \\\\ \\text{Var}[y'] \u0026 = \u0026 \\sum_{jk} X_j(x) C_{jk} X_k(x) + \\sigma'^2. \\end{array} \\] (7.1) If \\(\\sigma'\\) is unknown it should be set to the same scale as historical measurement errors. If they are unknown, \\(\\sigma'\\) should be estimated from Eq. (6.1).\n8. Implementation A sample implementation of the above method, using a polynomial fitting function is included in the DOS program dpolyfit.exe((Download {{:random_research:rik_s_notes:discounted_least_squares:dls.zip|dls.zip}} source code and executable, released to the public domain)). It is designed to make continuously updated parameter fits from data in the input stream, and output these parameters, or forecasts derived therefrom, to the output stream. It takes as a command-line parameter an initialization file containing preset parameters for the input format, fitting procedure, and output display. Common usages of this program are:\n​\rListing 8.1\rdpolyfit.exe inifile.ini \u003cin.dat \u003eout.dat dpolyfit.exe inifile.ini \u003cin.dat \u003e\u003eout.dat\rListing 8.1: Sample command-line parameters for program, where inifile.ini, in.dat, and out.dat are replaced with desired configuration, input and output files, respectively. The second version appends output to out.dat rather than overwriting it.\nThe behaviour of the program is controlled by the initialization file which contains the following options:\n​\rListing 8.2\r[Input] Errors=No\t; input s values? [Fit] Memory=14\t; effective # data points, Neff in Eq. 5.2 Parameters=7\t; # of parameters a to fit, M in Eq. 2.2 [Output] Input=Yes\t; print input (x,y,s) triplet to output? Parameters=No\t; print parameters a and errors to output? Forecast=Yes\t; print forecasted y to output? Forecast Distance=0\t; forecast y at x=x0+\"Forecast Distance\" [Abort]\t; end program when all of the following are true: x=0 y=0 sig=0\t; only compare s if \"[Input] Errors=Yes\"\rListing 8.2: Sample initialization file inifile.ini.\nIf “[Input] Errors=Yes” then the program expects three numbers per data point \\((x_0,y_0,\\sigma_0)\\), each separated by white spaces (eg. “1.0 1.2 0.4”). Otherwise, only two are expected \\((x_0,y_0)\\).\nThe option “[Fit] Memory=...” contains \\(N_{eff}\\) as in Eq. (5.2). Generally, this must be strictly \\(\u003e0\\), but if a negative number is entered it is interpreted as \\(N_{eff}=\\infty\\), producing a traditional fit over all data points with no rescaling of the measurement errors.\nIf “[Output] Input=Yes” then the input values \\((x_0,y_0,\\sigma_0)\\) are reproduced as the first three columns of the output file. Even if \\(\\sigma_0\\) is unspecified, a best estimate is output, based on Eq. (6.1).\nIf “[Output] Parameters=Yes” then the next \\(2 M\\) columns of output are the parameters \\(\\bf a\\) and their respective uncertainties, eg. “\\(a_1 \\delta a_1 \\ldots a_M \\delta a_M\\)”.\nIf “[Output] Forecast=Yes” then the program generates another two columns of output. It calculates the forecast of \\(y\\) at \\(x=x_0+\\)\"[Output] Forecast Distance\" from Eq. (7.1) and prints out the forecasted \\(y\\) and its uncertainty.\nThe program ends when the input \\((x_0,y_0,\\sigma_0)\\) or \\((x_0,y_0)\\) matches the values in “[Abort] x=... y=... sig=...” or “[Abort] x=... y=...”, respectively.\nThe design of this program might cause some confusion: even though the input data file is a complete set of data, the program only analyzes each data point successively, and all output is based on just this point and prior data. For example, forecasts are based only on past data, so by the end of the output file, all data points are considered but in the beginning results are based only on a single data point. The technique derived herein is better suited to time series with slowly accumulating data, rather than a complete data set on startup.\n9. Summary As in traditional least-squares methods, by differentiating the \\(\\chi^2\\) merit function (Eq. (2.3)) of a linear model (Eq. (2.2)) we were able find a set of linear equations (Eq. (2.9)) which allowed us to solve for the optimal parameters which minimize \\(\\chi^2\\). By scaling up the error tolerance of old data as new data is acquired (Eq. (2.1)) we were able to compact the information such that only an \\(M \\times M\\) matrix \\([\\alpha]\\) (Eq. (4.1)), an \\(M\\times 1\\) vector \\([\\beta]\\) (Eq. (4.2)), and a scalar \\(\\delta\\) (Eq. (4.3)) need be stored to retain the full history of accumulated data. We found that the inverse of \\([\\alpha]\\) (Eq. (3.1)) held the covariance matrix of the fitted parameters (Eq. (3.4) and (3.5)). We were able to compute a memory for this technique (Eq. (5.2)) which is comparable to the number of data points used in traditional least-squares fitting. By assuming a good fit we were able to estimate the measurement uncertainties if they were unknown, and apply this to reconstruct reasonable deviations in the fitted parameters (Eq. (6.2)). Finally, by extrapolating with the latest parameter estimates (assuming they were valid in the forecasted domain), we were able to make forecasts and estimate their uncertainties (Eq. (7.1)).\nAs my list of references will attest, I have done virtually no research to see whether the discounted least-squares method has already been discovered (as is undoubtedly the case) and what name it goes by. In deriving this, I did not care if I “reinvented the wheel” because my goal was to introduce myself to some of the statistical techniques, particularly those used in the derivation of uncertainties.\n10. References Blok\r(1997)\rBlok, \rH.(1997, 7/20). Retrieved from \rhttp://www.zoology.ubc.ca/~rikblok/wiki/doku.php?id=random_research:rik_s_notes:discounted_least_squares:start\rPress, \rTeukolsky, \rVetterling \u0026 Flannery\r(1992)\rPress, \rW., \rTeukolsky, \rS., \rVetterling, \rW. \u0026 Flannery, \rB. \r(1992).\r \rNumerical Recipes in C: The Art of Scientific Computing (Second).\r \rCambridge University Press. Retrieved from \rhttp://www.nr.com/",
    "description": "Discounted Least Squares Curve Fitting",
    "tags": [],
    "title": "Blok (1997) Discounted Least Squares",
    "uri": "/~rikblok/research/notes/discounted_least_squares/index.html"
  },
  {
    "breadcrumb": "Research ramblings \u003e Published",
    "content": "Effect of boundary conditions on scaling in the “game of Life” Blok \u0026 Bergersen\r(1997)\rBlok, \rH. \u0026 Bergersen, \rB.\r \r(1997).\r Effect of boundary conditions on scaling in the “game of Life”.\rPhysical Review E, 55(5). 6249–6252.\rhttps://doi.org/10.1103/PhysRevE.55.6249\rAbstract The debate as to whether the “game of Life” is self-organized critical remains unresolved. We present evidence that boundary conditions play an important role in the scaling behaviour, resulting in apparently contradictory results. We develop an analytic form for the scaling function and demonstrate that periodic boundaries force saturation, while open boundaries exhibit no such transitions on similar scales. We also consider the removal of boundaries altogether.\nDownload",
    "description": "Effect of boundary conditions on scaling in the “game of Life”",
    "tags": [],
    "title": "Blok \u0026 Bergersen (1997)",
    "uri": "/~rikblok/research/published/blok97/index.html"
  },
  {
    "breadcrumb": "Mathematical musings",
    "content": "Pythagorean theorem\rIn a right triangle the square of the hypotenuse is equal to the sum of the squares of the sides containing the right angle.\nI’ve been puzzling over a proof for this for years, and it finally dawned on me. (Eureka!) It’s all in how you draw it…\nProof #1 Given the triangle formed by $a$, $b$ (choosing $b\\geq a$) and $c$, we can construct a square with total area $c^2$. As shown, we can fit four triangles, each with area $a b/2$, into the large square, leaving an inner square with area $(b-a)^2$. Thus, the total area of the large square is\n$$ \\begin{array}{rl} c^2 \u0026 = 4 (a b/2) + (b-a)^2 \\\\ \u0026 = 2 a b + a^2 + b^2 - 2 a b \\\\ \u0026 = a^2 + b^2 . \\end{array} $$Hence, the Pythagorean theorem.\nProof #2 I found another proof, which Jim Loy told me is due to Legendre. It relies on recognizing that you can subdivide a triangle forming two sub-triangles similar to each other and the original. (I won’t prove this.) Then, from the figure above, and from the properties of similar triangles\n$$ \\frac{a}{e} = \\frac{c}{a} \\text{ thus } a^2 = c e $$and\n$$ \\frac{b}{f} = \\frac{c}{b} \\text{ thus } b^2 = c f. $$Adding the two results together gives\n$$ \\begin{array}{rl} a^2 + b^2 \u0026 = c e + c f \\\\ \u0026 = c (e+f) \\\\ \u0026 = c^2 . \\end{array} $$Hence, the Pythagorean theorem.\n— Rik Blok, 1997",
    "description": "I’ve been puzzling over a proof for this for years, and it finally dawned on me. (Eureka!) It’s all in how you draw it…",
    "tags": [],
    "title": "Proof of the Pythagoran theorem (1997)",
    "uri": "/~rikblok/math/pythagoras/index.html"
  },
  {
    "breadcrumb": "Research ramblings",
    "content": "My peer-reviewed and published articles.\nDoebeli, Blok, Leimar \u0026 Dieckmann (2007)Multimodal pattern formation in phenotype distributions of sexual populations\nPineda-Krch, Blok, Dieckmann \u0026 Doebeli (2007)A tale of two cycles - distinguishing quasi-cycles and limit cycles in finite predator-prey populations\nKillingback, Blok \u0026 Doebeli (2006)Scale-free extinction dynamics in spatially structured host–parasitoid systems\nBlok (2000)On the nature of the stock market: Simulations and experiments\nBlok \u0026 Bergersen (1999)Synchronous versus asynchronous updating in the “game of Life”\nBlok \u0026 Bergersen (1997)Effect of boundary conditions on scaling in the “game of Life”",
    "description": "My peer-reviewed and published articles",
    "tags": [],
    "title": "Published",
    "uri": "/~rikblok/research/published/index.html"
  },
  {
    "breadcrumb": "",
    "content": "Contact me below if you’d like to talk to me outside of class. Also, here’s some course material for current and past courses I have been involved in.\nContact RikWant to book an appointment or reach me? Check out my office hours and contact information here.\nWorkloadView my historical workload, automatically generated from the emails waiting in my inbox.\nRecent coursesHere are some recent courses I’ve taught.\nUBC CPSC 110Computation, Programs, and Programming\nFundamental program and computation structures. Introductory programming skills. Computation as a tool for information processing, simulation and modelling, and interacting with the world.\nUBC CPSC 107Systematic Program Design\nFundamental computation and program structures. Continuing systematic program design from CPSC 103.\nUBC ISCI 320Research Development Project\nRetreat to develop skills in writing scientific research proposals. Emphasis on formulating and testing hypotheses to explain observations.\nOld coursesHere are some courses I’ve taught in the past.\nUBC ISCI 344 (2016)Game Theory in Economics and Evolution (Fall 2016))\nExploration of human and animal interactions: integrating evolutionary and economic perspectives to investigate individual and social behaviour.\nUBC ISCI 422 (2009)Models in Science (Fall 2009)\nMeaning, nature, use, strengths and limitations of models as investigative tools in all scientific disciplines. Detailed investigation of selected model systems from different scientific disciplines.\nUBC PHYS 102 (2003)Electricity, Light and Radiation (Summer 2003)\nIntroduction to optics, electricity and magnetism, electric circuits, radioactivity, including biological applications.\nUBC PHYS 153 (2000)Elements of Physics (Winter 2000)\nThermometry, thermal properties of matter, heat, oscillations, waves, sound, wave optics; geometrical optics, elementary electricity and magnetism, simple DC and AC circuits.",
    "description": "My contact information and material from some of my courses.  Look here if you want to book an appointment.",
    "tags": [],
    "title": "Academic anecdotes",
    "uri": "/~rikblok/teaching/index.html"
  },
  {
    "breadcrumb": "Academic anecdotes",
    "content": "Want to book an appointment or reach me? Check out my office hours and contact information here.\nOffice hours Choose an available time slot to book an online Zoom appointment:\nE-mail rik.blok@ubc.ca Go ahead, fire off an email if you have a question or want to meet outside of my regular office hours (above). It may take me a while to get back to you, depending on my workload.\nPhone 604-736-6343 Feel free to phone me at home anytime. Leave a message if I’m not around.\nSnail mail Rik Blok, Sessional Lecturer Computer Science, UBC 201 - 2366 Main Mall Vancouver, BC, Canada V6T 1Z4 I don’t check my mailbox regularly so please let me know if you’ve mailed me something.",
    "description": "Want to book an appointment or reach me?  Check out my office hours and contact information here.",
    "tags": [],
    "title": "Contact Rik",
    "uri": "/~rikblok/teaching/contact/index.html"
  },
  {
    "breadcrumb": "Research ramblings",
    "content": "Work I’ve presented for feedback at seminars, lab meetings, and guest lectures.\nBlok (2003) Self-affine timeseries analysisGuest lecture for U.B.C. Physics 510: Stochastic Processes in Physics\nBlok (2002) Rock, paper and scissors in spaceSOWD (Schluter, Otto, Whitton, Whitlock, Doebeli)) Lab Meeting\nBlok (2002) Statistical properties of financial timeseriesPIMS-MITACS Math Finance Seminar\nBlok (2001) Can memes drive genes?Presentation for Doebeli lab meeting\nBlok (2000) Final PhD oral defenseOn the nature of the stock market: Simulations and experiments\nBlok (1998) Modelling intentionality: The gamblerPresentation for UBC PHYS 510\nBlok (1998) Extra! Extra! Critical update on 'Life'Presentation for Peter Wall Inst. Adv. Science, Crisis Points Group, UBC",
    "description": "Work I’ve presented for feedback at seminars, lab meetings, and guest lectures",
    "tags": [],
    "title": "Presented",
    "uri": "/~rikblok/research/presented/index.html"
  },
  {
    "breadcrumb": "",
    "content": "I spend a lot of time around computers, both at work and play. Yes, I’m a card-carrying geek 😉 Here’s what I’ve picked up over the years.",
    "description": "I spend a lot of time around computers, both at work and play. Yes, I’m a card-carrying geek 😉  Here’s what I’ve picked up over the years.",
    "tags": [],
    "title": "Computational capers",
    "uri": "/~rikblok/compute/index.html"
  },
  {
    "breadcrumb": "Academic anecdotes",
    "content": "You reached out to me and now you’re wondering, “That ahle! Why hasn’t Rik got back to me?” If I’m busy I just may not have had a chance yet. So check out my current workload for yourself. Automatically generated from the number of emails waiting in my inbox.\n​\r1 week\r2 months\r1 year\r10 years\rall time\rChart shows daily maximum workload.\nChart shows daily maximum workload.\nChart shows weekly maximum workload.\nChart shows 3-month maximum workload.\nChart shows 3-month maximum workload.\nUnder light workloads expect a response within a few days. I should be able to get back to you within a week under moderate workloads. But when my workload is heavy it could take a few weeks. Also check my schedule: I may be in a meeting or out of town.",
    "description": "View my historical workload, automatically generated from the emails waiting in my inbox.",
    "tags": [],
    "title": "Workload",
    "uri": "/~rikblok/teaching/workload/index.html"
  },
  {
    "breadcrumb": "Research ramblings",
    "content": "Here are some research-oriented technical notes I’ve written. They’re not peer-reviewed or published.\nBlok (2004) Parallel PoissonUpdating in simulations of parallel Poisson processes\nBlok (1997) Discounted Least SquaresDiscounted Least Squares Curve Fitting",
    "description": "Here are some research-oriented technical notes I’ve written. They’re not peer-reviewed or published.",
    "tags": [],
    "title": "Unpublished notes",
    "uri": "/~rikblok/research/notes/index.html"
  },
  {
    "breadcrumb": "",
    "content": "Some interesting (to me!) mathematical puzzles and problems I’ve come across.\nEuler's constant (2014)I found a sequence that converges to Euler’s constant faster than Bernoulli’s formula.\nShared gas (2002)My wife and I live in a twenty eight unit condominium which shares the cost of natural gas. At what price level can we expect the residents to switch from heating with gas to heating with electricity?\nThe Pythagorean theorem (1997)I’ve been puzzling over a proof for this for years, and it finally dawned on me. (Eureka!) It’s all in how you draw it…",
    "description": "Some interesting (to me!) mathematical puzzles and problems I’ve come across.",
    "tags": [],
    "title": "Mathematical musings",
    "uri": "/~rikblok/math/index.html"
  },
  {
    "breadcrumb": "Academic anecdotes",
    "content": "Here are some recent courses I’ve taught.\nUBC CPSC 110Computation, Programs, and Programming\nFundamental program and computation structures. Introductory programming skills. Computation as a tool for information processing, simulation and modelling, and interacting with the world.\nUBC CPSC 107Systematic Program Design\nFundamental computation and program structures. Continuing systematic program design from CPSC 103.\nUBC ISCI 320Research Development Project\nRetreat to develop skills in writing scientific research proposals. Emphasis on formulating and testing hypotheses to explain observations.",
    "description": "Here are some recent courses I’ve taught.",
    "tags": [],
    "title": "Recent courses",
    "uri": "/~rikblok/teaching/current/index.html"
  },
  {
    "breadcrumb": "",
    "content": "I’m a theoretical statistical physicist by training and a complexologist by nature. The common thread throughout my research is the search for common features of complex, irreducible systems.\nTraditionally, science approaches a problem by breaking it into parts and solving each part separately. In some cases, even when the individual pieces are well understood, the interactions between them will lead to surprising outcomes. Many important and diverse systems exhibit this irreducibility: earthquakes, ecosystems, stock markets, weather, computer networks, the immune system, the brain, forest fires, et cetera. Traditional scientific methods are ill-equipped to cope with these complex systems so my approach is to use novel tools such as nonequilibrium statistical physics theory and computer simulations to further our understanding.\nSee also my Google Scholar profile or my Zotero library.\nPublishedMy peer-reviewed and published articles\nDoebeli, Blok, Leimar \u0026 Dieckmann (2007)Multimodal pattern formation in phenotype distributions of sexual populations\nPineda-Krch, Blok, Dieckmann \u0026 Doebeli (2007)A tale of two cycles - distinguishing quasi-cycles and limit cycles in finite predator-prey populations\nKillingback, Blok \u0026 Doebeli (2006)Scale-free extinction dynamics in spatially structured host–parasitoid systems\nBlok (2000)On the nature of the stock market: Simulations and experiments\nBlok \u0026 Bergersen (1999)Synchronous versus asynchronous updating in the “game of Life”\nBlok \u0026 Bergersen (1997)Effect of boundary conditions on scaling in the “game of Life”\nPresentedWork I’ve presented for feedback at seminars, lab meetings, and guest lectures\nBlok (2003) Self-affine timeseries analysisGuest lecture for U.B.C. Physics 510: Stochastic Processes in Physics\nBlok (2002) Rock, paper and scissors in spaceSOWD (Schluter, Otto, Whitton, Whitlock, Doebeli)) Lab Meeting\nBlok (2002) Statistical properties of financial timeseriesPIMS-MITACS Math Finance Seminar\nBlok (2001) Can memes drive genes?Presentation for Doebeli lab meeting\nBlok (2000) Final PhD oral defenseOn the nature of the stock market: Simulations and experiments\nBlok (1998) Modelling intentionality: The gamblerPresentation for UBC PHYS 510\nBlok (1998) Extra! Extra! Critical update on 'Life'Presentation for Peter Wall Inst. Adv. Science, Crisis Points Group, UBC\nUnpublished notesHere are some research-oriented technical notes I’ve written. They’re not peer-reviewed or published.\nBlok (2004) Parallel PoissonUpdating in simulations of parallel Poisson processes\nBlok (1997) Discounted Least SquaresDiscounted Least Squares Curve Fitting",
    "description": "I’m a theoretical statistical physicist by training and a complexologist by nature. The common thread throughout my research is the search for common features of complex, irreducible systems.",
    "tags": [],
    "title": "Research ramblings",
    "uri": "/~rikblok/research/index.html"
  },
  {
    "breadcrumb": "Academic anecdotes",
    "content": "Here are some courses I’ve taught in the past. These pages are not maintained and may contain broken links.\nUBC ISCI 344 (2016)Game Theory in Economics and Evolution (Fall 2016))\nExploration of human and animal interactions: integrating evolutionary and economic perspectives to investigate individual and social behaviour.\nUBC ISCI 422 (2009)Models in Science (Fall 2009)\nMeaning, nature, use, strengths and limitations of models as investigative tools in all scientific disciplines. Detailed investigation of selected model systems from different scientific disciplines.\nUBC PHYS 102 (2003)Electricity, Light and Radiation (Summer 2003)\nIntroduction to optics, electricity and magnetism, electric circuits, radioactivity, including biological applications.\nUBC PHYS 153 (2000)Elements of Physics (Winter 2000)\nThermometry, thermal properties of matter, heat, oscillations, waves, sound, wave optics; geometrical optics, elementary electricity and magnetism, simple DC and AC circuits.",
    "description": "Here are some courses I’ve taught in the past.",
    "tags": [],
    "title": "Old courses",
    "uri": "/~rikblok/teaching/past/index.html"
  },
  {
    "breadcrumb": "",
    "content": "Science is both my work and my play. That doesn’t mean I’m particularly bright or hard-working, just that I’m curious. Because that’s the main ingredient for doing good science. (A healthy dose of skepticism helps, too.)",
    "description": "Science is both my work and my play. That doesn’t mean I’m particularly bright or hard-working, just that I’m curious. Because that’s the main ingredient for doing good science. (A healthy dose of skepticism helps, too.)",
    "tags": [],
    "title": "Scientific scribblings",
    "uri": "/~rikblok/science/index.html"
  },
  {
    "breadcrumb": "Academic anecdotes \u003e Recent courses",
    "content": "",
    "description": "Computation, Programs, and Programming\nFundamental program and computation structures. Introductory programming skills. Computation as a tool for information processing, simulation and modelling, and interacting with the world.",
    "tags": [],
    "title": "UBC CPSC 110",
    "uri": "/~rikblok/teaching/current/cpsc110/index.html"
  },
  {
    "breadcrumb": "Academic anecdotes \u003e Recent courses",
    "content": "",
    "description": "Systematic Program Design\nFundamental computation and program structures. Continuing systematic program design from CPSC 103.",
    "tags": [],
    "title": "UBC CPSC 107",
    "uri": "/~rikblok/teaching/current/cpsc107/index.html"
  },
  {
    "breadcrumb": "Academic anecdotes \u003e Recent courses",
    "content": "",
    "description": "Research Development Project\nRetreat to develop skills in writing scientific research proposals. Emphasis on formulating and testing hypotheses to explain observations.",
    "tags": [],
    "title": "UBC ISCI 320",
    "uri": "/~rikblok/teaching/current/isci320/index.html"
  },
  {
    "breadcrumb": "",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Categories",
    "uri": "/~rikblok/categories/index.html"
  },
  {
    "breadcrumb": "",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tags",
    "uri": "/~rikblok/tags/index.html"
  }
]
