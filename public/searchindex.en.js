var relearn_searchindex = [
  {
    "breadcrumb": "Scientific scribblings",
    "content": "All models are wrong, but some are useful. ‚Äî George E. P. Box\nI‚Äôm interested in the patterns that can emerge when many (often simple) elements interact. It is often required to build models of these kinds of systems to study their behaviour. The goal in constructing such models is not to get them ‚Äúright‚Äù (after all, all models are wrong) but rather to capture the important features and discard the unimportant ones. That‚Äôs what makes a model useful.\nHere you can find some models and, in some cases, emergent phenomena.\nEscape from Goblin-town! (2025)This simulation is inspired by the Goblin-town chase scene in the film The Hobbit: An Unexpected Journey (2012).\nConway's Game of Life (2020)This NetLogo model implements Conway‚Äôs Game of Life, a cellular automaton John Horton Conway designed to be difficult to anticipate the dynamics of starting patterns. This implementation incorporates some ideas I focused on in my research: finite-size effects and asynchronous updating.\nAxelrod's tournament (2018)In the early 1980s Robert Axelrod invited colleagues to submit strategies to a series of round-robin tournaments to see which strategies would do well playing an iterated Prisoner‚Äôs Dilemma. This NetLogo model allows you to try Axelrod‚Äôs tournaments yourself by creating some strategies and testing them in an iterated Prisoner‚Äôs Dilemma.\nAquaworld Radiation Balance (2018)This simple radiation balance model shows the greenhouse effect that an atmosphere can have in warming a planet. By trapping some of the radiation emitted by the planet the atmosphere can cause the surface to become warmer than it otherwise would be.\nA Trojan horse approach to medical intervention strategies (2017)I recently read an interesting review paper that explores the possibility of fighting a bacterial infection with Darwinian medicine through the introduction of a ‚Äúcheater‚Äù strain of bacteria into a wild population. I extended the analytic model in the paper to an agent-based model with explicit spatial structure.\nFlame (2017)I got thinking about how fires work today. Why do flames curl into whorls and some tongues lick up so high? I built this model to see how hard it was to reproduce the phenomenon. This is the result. I don‚Äôt think it captures much of the underlying mechanism but it looks pretty hot üôÇ\nMandelbrot Set (2017)Explore the Mandelbrot set and some related fractals.",
    "description": "I‚Äôm interested in the patterns that can emerge when many (often simple) elements interact.  It is often required to build models of these kinds of systems to study their behaviour.",
    "tags": [],
    "title": "Models",
    "uri": "/~rikblok/science/models/index.html"
  },
  {
    "breadcrumb": "Scientific scribblings¬†\u003e¬†Models",
    "content": "A NetLogo (\rCitation: Wilensky, 1999 Wilensky, \rU.(1999). Retrieved from \rhttp://ccl.northwestern.edu/netlogo/\r)\rmodel by Rik Blok.\nThis simulation is inspired by the Goblin-town chase scene in the film The Hobbit: An Unexpected Journey (2012).\nStill goblins go faster than dwarves, and these goblins knew the way better (they had made the paths themselves), and were madly angry; so that do what they could the dwarves heard the cries and howls getting closer and closer. Soon they could hear even the flap of the goblin feet, many many feet which seemed only just round the last corner. The blink of red torches could be seen behind them in the tunnel they were following; and they were getting deadly tired. ‚Äî J.R.R. Tolkien, ‚ÄúThe Hobbit‚Äù\nThe NetLogo model above simulates a set of platforms and bridges, shown from above. Dwarves (brown) are trying to get from the top-left corner, past the goblins (green), to the escape in the bottom-right corner. The goblins are trying to capture the dwarves before they escape. To see how it works, press setup and, after waiting a few seconds for the scene to be prepared, press go.\nYou‚Äôll see that the dwarves and goblins are both pretty silly ‚Äì they just stumble around randomly. If a dwarf should happen to find the escape, it‚Äôs just dumb luck.\nCan you do better? You can edit the code in this simulation to try help the dwarves (or goblins). Click NetLogo Code at the bottom of the simulation and take a look at these procedures:\nto turn-dwarf ;;;;;; YOUR CODE GOES HERE! wiggle 30 end ;--------------------------------------------------------- to turn-goblin ;;;;;; YOUR CODE GOES HERE! wiggle 90 end\rThe command wiggle is a procedure I wrote. But it‚Äôs not very useful ‚Äì it just makes the individual randomly turn left or right a bit. Have a look at the face-‚Ä¶ procedures in the NetLogo Code above. Maybe some of those would be better? Go ahead and replace the command wiggle in the turn-dwarf or turn-goblin procedure, then click Recompile Code to try it out. Did your changes work the way you expected? (If not, see if you can figure out why not and try again üôÇ)\nExamples Listing 1 shows some example turn-dwarf and turn-goblin procedures. Notice that some face-... procedures only turn the individual if they‚Äôre close enough to ‚Äúhear‚Äù the target. So these procedures can be called after other procedures to ‚Äúoverride‚Äù the individual‚Äôs behaviour. For example, Listing 1 shows that dwarves will try to move towards the exit except if they hear goblins nearby; then they will try to avoid the goblins.\n‚Äã\rturn-dwarf\rturn-goblin\r;--------------------------------------------------------- to turn-dwarf ;;;;;; YOUR CODE GOES HERE! face-towards-escape ; first face exit face-away-from-goblin-sounds ; but if hear goblins, turn away end ;---------------------------------------------------------\rListing 1: Example turn-dwarf and turn-goblin procedures demonstrating how to use the face-... procedures.\n;--------------------------------------------------------- to turn-goblin ;;;;;; YOUR CODE GOES HERE! wiggle 90 ; first turn up to 90 degrees left/right randomly face-towards-dwarf-sounds ; but if hear dwarves, turn towards end ;---------------------------------------------------------\rListing 1: Example turn-dwarf and turn-goblin procedures demonstrating how to use the face-... procedures.\nReferences Wilensky\r(1999)\rWilensky, \rU.(1999). Retrieved from \rhttp://ccl.northwestern.edu/netlogo/",
    "description": "This simulation is inspired by the Goblin-town chase scene in the film The Hobbit: An Unexpected Journey (2012).",
    "tags": [],
    "title": "Escape from Goblin-town! (2025)",
    "uri": "/~rikblok/science/models/goblintown/index.html"
  },
  {
    "breadcrumb": "Scientific scribblings",
    "content": "The world‚Äôs spinning fast. Sometimes I forget about how much science and technology have progressed in my lifetime. Here are some advances to help remind me.\nSince I was born‚Ä¶\n1971 - The Stanford prison experiment was conducted. 1974 - Start of Dauphin Manitoba‚Äôs Mincome project (until 1979). 1974 - The world population reached 4 billion people. 1975 - The term fractal was coined. 1976 - General relativity was tested and confirmed to an accuracy of 0.0000007%. 1976 - A spacecraft successfully landed on Mars. 1976 - The first known Ebola outbreak occurred. 1979 - Smallpox was eradicated. 1980 - I saw my first bank machine. ~1980 - I first used a wireless remote control and a microwave oven. The dawn of the age of ‚Äúaction at a distance‚Äù? 1981 - I first played a video game console at a friend‚Äôs house. 1981 - First launch of a Space Shuttle. 1982 - I first heard of a new disease, AIDS. 1983 - I wrote my first computer program, in BASIC (on an Apple II Plus at my junior high school. 1983 - Polymerase chain reaction was invented. 1984 - Prions (infectious misfolded proteins) were confirmed. 1985 - The wreck of the Titanic was discovered. ~1985 - I first heard about the Antarctic ozone hole. 1986 - I bought my first computer, an Apple IIc (with a 1MHz CPU, a 320kB floppy disk, and a 9\" monochrome monitor). 1986 - The worst nuclear disaster in history occurred. 1987 - The world population reached 5 billion people. 1988 - The first confirmed exoplanet (extrasolar planet) was discovered. 1988 - I sent and received my first email. 1989 - The Berlin Wall came down. ~1990 - I saw a cell phone in person. 1992 - The Atlantic northwest cod fishery collapsed. 1993 - I browsed the world wide web for the first time. 1994 - Fermat‚Äôs Last Theorem was proved. 1996 - Dolly the sheep was cloned. 1996 - I got Internet service at home. (Dial-up service @ 56kbps until 1999, then cable broadband.) 1996 - A feathered dinosaur was discovered. 1997 - Global average temperature reached 0.50¬∞C above the 20th century average. 1997 - A computer beat a chess grandmaster in a match. 1997 - I started my own website. (It received 100 visits in the first 3 months; about 1,000 in the first year; and about 10,000 in the first two years.) 1998 - It was observed that the expansion of the universe is accelerating. 1999 - The world population reached 6 billion people. 2001 - Wikipedia was launched. 2003 - The human genome was mapped. 2003 - I bought my first cell phone. (Held out as long as I could üòÑ) 2003 - My first wireless access to the internet. 2005 - Same-sex marriage legalized in Canada. 2009 - Bitcoin, the first digital cryptocurrency, is released. 2010 - I started buying digital music when some digital stores started selling unencumbered MP3 songs. Previously, music was encumbered by Digital Rights Management in Canada. 2010 - The first privately funded company to successfully launch to orbit and recover a spacecraft. 2011 - I cancelled my cable TV service ‚Äì strictly Internet since. 2011 - The world population reached 7 billion people. 2012 - The existence of the Higgs boson was confirmed. 2012 - A man-made object reached interstellar space. 2012 - I digitized my entire research library (about 30,000 pages of books and papers) ‚Äì strictly electronic from then on. Also switched pleasure-reading from paper to e-books. (By 2012 we had accumulated about 1,000 paper books.) 2013 - I switched from incandescent to LED light bulbs at home. 2015 - I first heard about CRISPR, the most powerful gene editing tool to-date. 2015 - An Ebola virus epidemic in West Africa killed over 11,000 people ‚Äì more than all previous Ebola outbreaks combined. Also, the first vaccine for Ebola was developed. 2015 - The first time somebody close to me bought an electric car. 2016 - Global average temperature reached 1.00¬∞C above the 20th century average. 2020 - The COVID-19 pandemic killed an estimated 7 million people worldwide and led to lockdowns, work-from-home, and face masking. 2020 - I started video calling regularly with family and friends. 2022 - I first started having useful chats with an artificial intelligence. At the time it had 175 billion parameters, about 0.1% of the synapses in the human brain. 2022 - The world population reached 8 billion people (more than doubled since I was born). I wish I could remember‚Ä¶ When did I first hear of global warming? When did I eat my first genetically modified food? When did I first see GPS in action? ‚Äî Rik Blok",
    "description": "The world‚Äôs spinning fast.  Sometimes I forget about how much science and technology have progressed in my lifetime.  Here are some advances to help remind me.",
    "tags": [],
    "title": "Since I was born (2022)",
    "uri": "/~rikblok/science/since_i_was_born/index.html"
  },
  {
    "breadcrumb": "Scientific scribblings¬†\u003e¬†Models",
    "content": "A NetLogo (\rCitation: Wilensky, 1999 Wilensky, \rU.(1999). Retrieved from \rhttp://ccl.northwestern.edu/netlogo/\r)\rmodel by Rik Blok.\nThis NetLogo model implements Conway‚Äôs Game of Life, a cellular automaton John Horton Conway designed to be difficult to anticipate the dynamics of starting patterns. This implementation incorporates some ideas I focused on in my research: finite-size effects (\rCitation: Blok \u0026 Bergersen, 1997 Blok, \rH. \u0026 Bergersen, \rB.\r \r(1997).\r Effect of boundary conditions on scaling in the ‚Äúgame of Life‚Äù.\rPhysical Review E, 55(5). 6249‚Äì6252.\rhttps://doi.org/10.1103/PhysRevE.55.6249\r)\rand asynchronous updating (\rCitation: Blok \u0026 Bergersen, 1999 Blok, \rH. \u0026 Bergersen, \rB.\r \r(1999).\r Synchronous versus asynchronous updating in the ‚Äúgame of Life‚Äù.\rPhysical Review E, 59(4). 3876‚Äì3879.\rhttps://doi.org/10.1103/PhysRevE.59.3876\r)\r.\nHow it works Each site on the square 2-dimensional lattice can be in one of two states (alive or dead). All sites are updated in parallel according to the following rules:\nLoneliness: An alive site with less than two of its 8 nearest neighbours also alive becomes dead; Overcrowding: An alive site with more than three alive neighbours becomes dead; and Birth: A dead site with exactly three alive neighbours becomes alive. Otherwise, sites remain in the same state.\nIn this implementation, alive sites are shown in bright yellow. Dead sites fade to black.\nHow to use it Choose world-size and initial-density of alive sites and press setup to create a random starting configuration. You may also press draw to draw your own starting configuration with the mouse.\nPress go to repeatedly apply the rules and watch the configuration evolve. Adjust the speed slider at the top as desired. You may also draw while the simulation is going.\nYou may adjust the synchronicity of the simulation ‚Äì the fraction of sites that are updated on each iteration. When synchronicity=100% we have Conway‚Äôs original Game of Life. As synchronicity is reduced some sites are skipped in each step, so the dynamics start to deviate from Conway‚Äôs. As synchronicity approaches 0% most sites are not updated in any one iteration, and the simulation approaches asynchrony ‚Äì almost the same as one site updating at a time. Notice how the patterns differ as synchronicity varies.\nTo perturb a configuration ‚Äì by toggling one site ‚Äì press bump. You may want to do this once the dynamics have settled to a stable (or simply repeating) pattern. Some bumps will have little effect but occasionally they will cascade through the whole space, changing the entire system. It is difficult to predict the size of the cascade.\nThings to notice Since there are a fixed, finite number N of sites there are only a finite number of possible configurations (2^N) and the configuration must necessarily repeat as it evolves. In principle the period between repeating configurations could be anything up to 2^N but in practice it is much shorter: typically 1 or 2. A notable exception can occur when synchronicity=100% and a glider is present ‚Äì rarely a glider may travel around the entire length of the space and return to its original position.\nThings to try Draw Try drawing your own starting configuration. Set the initial-density=0% and press setup to set all sites to dead. Press the draw button to activate drawing mode, then use the mouse to draw a shape, such as the R-pentomino.\nBoundary conditions This implementation defaults to periodic boundary conditions: the left side can be thought of as wrapping around to touch the right and the top touches the bottom. In the native version of NetLogo (not the applet) you can switch to cold boundaries where any sites outside of the visible area are assumed to be dead ‚Äì press Settings‚Ä¶ at the top-right of the interface and toggle the World wraps‚Ä¶ checkboxes. Notice that periodic boundaries reduce edge effects (\rCitation: Blok \u0026 Bergersen, 1997 Blok, \rH. \u0026 Bergersen, \rB.\r \r(1997).\r Effect of boundary conditions on scaling in the ‚Äúgame of Life‚Äù.\rPhysical Review E, 55(5). 6249‚Äì6252.\rhttps://doi.org/10.1103/PhysRevE.55.6249\r)\r.\nReferences Blok \u0026 Bergersen\r(1997)\rBlok, \rH. \u0026 Bergersen, \rB.\r \r(1997).\r Effect of boundary conditions on scaling in the ‚Äúgame of Life‚Äù.\rPhysical Review E, 55(5). 6249‚Äì6252.\rhttps://doi.org/10.1103/PhysRevE.55.6249\rBlok \u0026 Bergersen\r(1999)\rBlok, \rH. \u0026 Bergersen, \rB.\r \r(1999).\r Synchronous versus asynchronous updating in the ‚Äúgame of Life‚Äù.\rPhysical Review E, 59(4). 3876‚Äì3879.\rhttps://doi.org/10.1103/PhysRevE.59.3876\rWilensky\r(1999)\rWilensky, \rU.(1999). Retrieved from \rhttp://ccl.northwestern.edu/netlogo/",
    "description": "This NetLogo model implements Conway‚Äôs Game of Life, a cellular automaton John Horton Conway designed to be difficult to anticipate the dynamics of starting patterns.  This implementation incorporates some ideas I focused on in my research: finite-size effects and asynchronous updating.",
    "tags": [],
    "title": "Conway's Game of Life (2020)",
    "uri": "/~rikblok/science/models/game_of_life/index.html"
  },
  {
    "breadcrumb": "Scientific scribblings¬†\u003e¬†Models",
    "content": "A NetLogo (\rCitation: Wilensky, 1999 Wilensky, \rU.(1999). Retrieved from \rhttp://ccl.northwestern.edu/netlogo/\r)\rmodel by Rik Blok.\nIn the early 1980s Robert Axelrod invited colleagues to submit strategies to a series of round-robin tournaments (\rCitation: Axelrod \u0026 Hamilton, 1981 Axelrod, \rR. \u0026 Hamilton, \rW.\r \r(1981).\r The evolution of cooperation.\rScience, 211(4489). 1390‚Äì1396.\rhttps://doi.org/10.1126/science.7466396\r)\rto see which strategies would do well playing an iterated Prisoner‚Äôs Dilemma. This NetLogo model allows you to try Axelrod‚Äôs tournaments yourself by creating some strategies and testing them in an iterated Prisoner‚Äôs Dilemma.\nHow can cooperation arise and persist when there is a temptation to ‚Äúdefect‚Äù from cooperation for personal gain? Cooperation is a well-studied problem in economics, social sciences, and evolution.\nLet‚Äôs construct a simple scenario to highlight the problem. Consider an interaction between two individuals where each player can, at a cost $c\u003e0$ to themselves, confer a benefit $b\u003ec$ to the other player:\nIf I cooperate I pay a cost $c$ and If you cooperate I receive a benefit $b$. If you and I are playing this Prisoner‚Äôs Dilemma game what should we choose? Clearly it would be best for both of us if we could cooperate so we each earn a net amount of $b-c\u003e0$. But it would be even better for me if I didn‚Äôt pay the cost $c$. If we both try to gain the highest payoff by avoiding the cost then we will get nothing (because nobody generated the benefit). Cooperation is undermined because no matter what you choose, I always feel the temptation to defect and avoid paying the cost ‚Äì it is difficult for cooperation to arise and persist in this game.\nRepetition was proposed as a solution to this dilemma: perhaps if the players repeated the interaction many times, the prospect of reciprocal cooperation in the future would encourage players to cooperate now.\nIn each round a player can choose to cooperate or defect but their choice may depend on many details, such as what they and/or the other player did in the past. For example, I would like to receive the benefit $b$ from you in every round. If I received it in the prior round I might repeat the same choice (don‚Äôt make any changes if things are going well, or ‚Äúwin-stay‚Äù) but if I didn‚Äôt I might choose the other option (switch if things are going poorly, or ‚Äúlose-switch‚Äù). This well-known strategy is called Pavlov, or win-stay, lose-switch. If both players use the Pavlov strategy and cooperate in the first round, they will continue to cooperate for all rounds, doing much better than strategies that mutually fall for the temptation to defect. (But Pavlov is not guaranteed to perform well when playing against these strategies.)\nIn the early 1980s Robert Axelrod invited colleagues to submit strategies to a series of round-robin tournaments (\rCitation: Axelrod \u0026 Hamilton, 1981 Axelrod, \rR. \u0026 Hamilton, \rW.\r \r(1981).\r The evolution of cooperation.\rScience, 211(4489). 1390‚Äì1396.\rhttps://doi.org/10.1126/science.7466396\r)\rto see which strategies would do well playing an iterated Prisoner‚Äôs Dilemma. This NetLogo model allows you to try Axelrod‚Äôs tournaments yourself by creating some strategies and testing them in an iterated Prisoner‚Äôs Dilemma.\n1 How it works 1.1 go The [go] button starts a round-robin tournament where all strategies are paired with each other to play the Prisoner‚Äôs Dilemma for a specified number of rounds. The average score for each player is shown beside their name. At the end of the tournament all players‚Äô average scores are shown in the output window.\n1.2 Memory-one strategies In Axelrod‚Äôs tournament game theorists were invited to submit any strategies that could be encoded as computer programs. The programs had as input the entire history of the interaction so far and would respond with a choice to cooperate or defect in the next round (\rCitation: Axelrod, 1980 Axelrod, \rR.\r \r(1980).\r More Effective Choice in the Prisoner‚Äôs Dilemma.\rJournal of Conflict Resolution, 24(3). 379‚Äì403.\rhttps://doi.org/10.1177/002200278002400301\r)\r. That‚Äôs far beyond the scope of this simulation.\nInstead, each strategy consists of a set of five numbers, representing the probability of cooperating in the next round given what occured only in the previous round:\nC_on_1st = probability that I cooperate in the first round. C_after_CC = probability that I cooperate after we both cooperated in the previous round. C_after_CD = probability that I cooperate after I cooperated and you defected in the previous round. C_after_DC = probability that I cooperate after I defected and you cooperated in the previous round. C_after_DD = probability that I cooperate after we both defected in the previous round. Even though this severely limits the available strategies, it is still possible to create some well-known strategies:\nAllC = (100%, 100%, 100%, 100%, 100%). Always cooperates. AllD = ( 0%, 0%, 0%, 0%, 0%). Always defects. Tit-for-tat = (100%, 100%, 0%, 100%, 0%). Cooperates on first round. After that, repeats other player‚Äôs last choice. Pavlov = (100%, 100%, 0%, 0%, 100%). Cooperates on first round. After that, repeats last move if received b, otherwise switches. Grim = (100%, 100%, 0%, 0%, 0%). Cooperates on first round. After that, keeps cooperating until anybody defects. Then defects for rest of game. Click [presets] to explore other interesting strategies.\n1.3 evolve The [evolve] button allows the user to explore how the population of strategies evolves over many tournaments. Between each tournament a new generation of strategies is created by sampling the current generation. The probability of each strategy reproducing into the next generation is proportional to how much better its score is than the lowest-scoring player in the population. The lowest-scoring player therefore has zero probability of reproducing.\n2 How to use it 2.1 Adding players To run a tournament you first need to add some players (also called strategies). You can add your own by choosing slider values and (optionally) giving the strategy a name, then clicking the [add-players] button. (You can add duplicates of a strategy by adjusting the [how-many] slider before clicking [add-players].)\nAlternatively, you can click the [random-players] button to add one (or [how-many]) randomly-chosen strategies.\nYou can also click the [presets] button at the bottom to add a bunch of pre-defined strategies. Most of these were submitted by students in the UBC course ISCI 344 Game Theory.\n2.2 Running a tournament 2.2.1 go Once you‚Äôve got a pool of players you can run a round-robin tournament between them by clicking the [go] button. Choose the following parameters:\nnumber-of-rounds: The number of repetitions (rounds) of the game played between each pair of players. cost-to-self: The cost each player pays for choosing to cooperate. benefit-to-other: The benefit received if the other player chooses to cooperate. When the benefit is more than the cost there is an incentive to choose mutual cooperation, but a temptation to defect ‚Äì a Prisoner‚Äôs Dilemma. play-self: Toggle on to have each player also play against themselves in the tournament. They are actually playing against a mirror image ‚Äì their opponent makes exactly the same choices as they do (even duplicating any errors). errors: The chance of making an implementation error with any choice. With implementation errors players perceive the conditions (eg. what happened in the last round) correctly and determine their response correctly according to their strategy, but they accidentally select the option opposite to what they intended. Set this to zero for perfect fidelity (players always successfully make the choice they intended). errors also sets the mutation rate under [evolve] (see the next section). At the end of the tournament all the player scores and level of cooperation (fraction of times they cooperated) are shown.\n2.2.2 inspect-players You can view the score and other details of any of the players. Press the [inspect-players] button to enable this functionality. Then hover over any player to see their attributes including their name, strategy (five percentages), average frequency of cooperation, and average score so far.\nInspecting a player also populates the ‚ÄúPlayers:‚Äù view (name and strategy sliders) so you can easily remove this player or add more of the same. (Hint: You can stop [inspect-players] so that the current player remains in the view by clicking on the player.)\n2.2.3 evolve In addition to running the tournament once and seeing the scores, it is possible to run it repeatedly, and select for the highest scoring strategies. Each generation, the players are selected to form the next generation with likelihood proportional to their fitness where\nmy-fitness = my-average-score - lowest average-score\nso that the minimum probability of selection is never negative. The lowest scoring strategies will have zero fitness and be removed from the population.\nThe population size is conserved across generations. Since lower-fitness strategies are less likely to be copied into the next generation this evolutionary process selects for higher fitness strategies.\nAs strategies are copied into the next generation, replication errors (mutations) are possible. The [errors] slider gives the likelihood that a child will have a mutation from its parent. If a mutation occurs, one of the five probabilities is replaced with a random value.\n2.3 Removing players You can remove players at any time by entering their name in the [Name] box and clicking [remove-name]. Note that this removes all players with that name.\nYou can also remove the player with the lowest average score with the [remove-worst] button.\n3 Things to notice 3.1 Errors Notice that it is possible to introduce implementation errors into the game: a strategy may intend to cooperate or defect but erroneously choose the other option. The error rate (per choice) is given by the errors slider.\nThe errors slider also allows reproduction errors, or mutations. In this case the value gives the mutation rate per child. If a mutation occurs one of the five variables representing the strategy is replaced with a random value.\n3.2 Fixed number of rounds Axelrod set up his tournament so each game between two players had an uncertain duration (\rCitation: Axelrod, 1980 Axelrod, \rR.\r \r(1980).\r More Effective Choice in the Prisoner‚Äôs Dilemma.\rJournal of Conflict Resolution, 24(3). 379‚Äì403.\rhttps://doi.org/10.1177/002200278002400301\r)\r. That prevented strategies from being conditioned on how many rounds remained. (It‚Äôs always best to defect in the last round. But if I know that, I should also defect in the second-to-last round‚Ä¶) That‚Äôs not an issue in this simulation because memory-one strategies aren‚Äôt sophisticated enough to condition their response on the number of remaining rounds. So this tournament allows a certain, fixed number of rounds.\n3.3 Fitness landscape You may be surprised to see the average score (or fitness) drop as the population evolves. Evolution is often thought of as climbing a fitness landscape. That makes sense when the fitness is unchanging. But in this model the fitness of each strategy depends strictly on the other strategies in the population. As the population composition changes the fitness of the population may decline. Nevertheless, the most successful within that population will tend to reproduce more frequently. Counterintuitively, in this way it is possible for the system to evolve to low fitness. It is akin to climbing a hill that collapses as it is being climbed.\n4 Things to try What do you expect to happen if the error rate is set to 50%? (Hint: For each of the five memory-one conditions, what is the probability any player will choose erroneously?) Check if you‚Äôre right!\n5 References Axelrod \u0026 Hamilton\r(1981)\rAxelrod, \rR. \u0026 Hamilton, \rW.\r \r(1981).\r The evolution of cooperation.\rScience, 211(4489). 1390‚Äì1396.\rhttps://doi.org/10.1126/science.7466396\rAxelrod\r(1980)\rAxelrod, \rR.\r \r(1980).\r More Effective Choice in the Prisoner‚Äôs Dilemma.\rJournal of Conflict Resolution, 24(3). 379‚Äì403.\rhttps://doi.org/10.1177/002200278002400301\rWilensky\r(1999)\rWilensky, \rU.(1999). Retrieved from \rhttp://ccl.northwestern.edu/netlogo/",
    "description": "In the early 1980s Robert Axelrod invited colleagues to submit strategies to a series of round-robin tournaments to see which strategies would do well playing an iterated Prisoner‚Äôs Dilemma.  This NetLogo model allows you to try Axelrod‚Äôs tournaments yourself by creating some strategies and testing them in an iterated Prisoner‚Äôs Dilemma.",
    "tags": [],
    "title": "Axelrod's tournament (2018)",
    "uri": "/~rikblok/science/models/axelrods_tournament/index.html"
  },
  {
    "breadcrumb": "Scientific scribblings¬†\u003e¬†Models",
    "content": "An Insight Maker model by Rik Blok.\nThis simple radiation balance model shows the greenhouse effect that an atmosphere can have in warming a planet. By trapping some of the radiation emitted by the planet the atmosphere can cause the surface to become warmer than it otherwise would be.\n1 How it works Welcome to the Aquaworld radiation balance model. I want to show some of the factors that determine the temperature of a planet, including incoming/emitted radiation and the greenhouse effect. Let‚Äôs say the planet is like earth except it‚Äôs completely covered in water. (Earth‚Äôs surface is about 2/3rds water so it‚Äôs not a terrible assumption.)\nIncoming solar radiation reaches the planet.1 Most of the incoming radiation energy is absorbed by the planet‚Äôs surface but some is reflected back out into space. Let‚Äôs take the Surface Albedo (‚Äúreflectivity‚Äù) to be 0.3, the same as Earth.2 The retained solar energy causes the surface to warm. In this case, we just consider the top 100 meters of our aquaworld.3\nNotice the surface temperature (shown in degrees Celsius) quickly climbs from its starting value (of absolute zero, which isn‚Äôt very realistic anyway). If the surface continued to absorb incoming solar radiation and nothing else happened the planet‚Äôs temperature would keep increasing without bound.\nBut as the planet warms it starts to emit its own (infrared) radiation that slows the rate of warming.\nIf we wait longer we see that the planet reaches a steady-state temperature where the incoming and emitted radiation are balanced.\nWhat effect does the atmosphere have? The atmosphere is mostly transparent to solar radiation, since it is mostly in the visible wavelengths. But it absorbs some infrared radiation, such as the radiation from the surface. I call the fraction absorbed the ‚ÄúGreenhouse Effect‚Äù.\nAs we saw for the surface, as the atmosphere absorbs energy it warms up. The warming atmosphere emits its own radiation, like a black body. This time, the radiation is emitted both upwards ‚Äì escaping out into space ‚Äì and back down to the surface, warming it further. The greenhouse effect makes the atmosphere acts like a blanket, trapping some of the heat emitted by the surface and heating it up.\nNotice also that the atmosphere, like your blanket in a cold room, is colder than what‚Äôs underneath.\nNow it‚Äôs your turn. Can you adjust the strength of the greenhouse effect (the slider on the right) to make the surface temperature match Earth‚Äôs (+14C)?\nIf so, what is the resultant atmosphere temperature predicted by the model? How well does it compare with actual observations of temperatures near the top of the atmosphere?\nOther things to try: Change the model parameters (in Settings). Can you represent Mars, Venus, or other planets in the solar system? How? Or why not?\n1.1 Parameters This model is deliberately simple, with just a couple parameters that are designed to be varied:\nGreenhouse Effect\nThe fraction of surface radiation absorbed by the atmosphere‚Äã. The absorbed radiation heats up the atmosphere causing it to radiate out (back down to the planet and out into space). Surface radiation that isn‚Äôt absorbed continues out to space.\nSurface Albedo\nThe fraction of incoming solar radiation that is reflected back out to space. Radiation that isn‚Äôt reflected is absorbed by the surface.\n‚ÄúThe average albedo of Earth is about 0.3.‚Äù ‚Äì from Wikipedia\nBesides those variables, there are a few other constants to be found in the ‚ÄúSettings‚Äù, chosen to make Aquaworld similar to Earth:\nDistance from sun, $d$\n‚ÄúThe average distance between the Earth and the Sun is 149.60 million kilometers‚Äù ‚Äì Wikipedia\nMixing Height\n‚ÄúThe primary heat source for the ocean is solar radiation entering through the top surface. Almost all of the solar energy flux into the ocean is absorbed in the top 100 m.‚Äù ‚Äì (\rCitation: Hartmann, 1994 Hartmann, \rD. \r(1994).\r \rGlobal Physical Climatology.\r \rAcademic Press.\r)\r.\nRadius of planet, $r$\n‚ÄúA globally-average value [of Earth‚Äôs radius] is usually considered to be 6,371 kilometres‚Äù. ‚Äì from Wikipedia\nMass of atmosphere\n\"[Earth‚Äôs] atmosphere has a mass of about 5.15√ó1018 kg,\" ‚Äì from Wikipedia\nYou can change these parameters to, for example, compare Aquaworld to other planets.\n2 Theory The sun‚Äôs total radiation output is $I_0 = 3.86√ó10^{26}$ Watts. That radiation spreads out radially so the density falls off with distance from the sun as the surface area of a sphere. A planet at a distance $d$ from the sun will receive $I_0 / (4 \\pi d^2)$ radiation per unit area with the sun directly overhead.\nOnly the sunny side of the planet receives the insolation. We‚Äôll assume our planet is roughly spherical but it turns out not to matter for determining the amount of energy it receives ‚Äì the important factor is the size of the planet‚Äôs ‚Äúshadow‚Äù or cross section. If the planet has radius $r$ (so, cross-sectional ‚Äúshadow‚Äù area $\\pi r^2$) then the total incoming solar radiation is\n\\[ I(d,r) = I_0 \\frac{\\pi r^2}{4 \\pi d^2} = I_0 \\frac{r^2}{4 d^2}. \\]For example, Earth receives incoming solar radiation\n\\[ I_{\\text{Earth}} = I(149.60√ó10^6 \\text{ km}, 6371 \\text{ km}) = (3.86√ó10^{26} \\text{ W}) \\frac{(6371 \\text{ km})^2}{4 (149.60√ó10^6 \\text{ km})^2} = 1.75√ó10^{17} \\text{ W}. \\] This system dynamics model tracks energy stored in various stocks, and flows between them.\nFor most settings, the surface energy (a stock) equilibrates at some level, regardless of starting energy. To demonstrate that, we start with 0 Joules stored and see how radiation flow balances out after some time.\n2.1 Assumptions This model makes several important assumptions:\nEnergy generated in Aquaworld‚Äôs interior has a negligible influence on its energy budget. In Section 2.1, Hartmann (\rCitation: 1994 Hartmann, \rD. \r(1994).\r \rGlobal Physical Climatology.\r \rAcademic Press.\r)\rstates this is a valid assumption for Earth.\nThe atmosphere is treated as a single, well-mixed layer. More detailed models split the atmosphere into two or more layers. Here is an example with a 2-layer atmosphere.\nConvective heat transfer is ignored. Here is an example that incorporates convection of heat from the surface to the atmosphere.\n3 References Hartmann\r(1994)\rHartmann, \rD. \r(1994).\r \rGlobal Physical Climatology.\r \rAcademic Press.\r4 Footnotes At the mean distance of Earth from the sun the intensity is 1367 Watts per square meter (\rCitation: Hartmann, 1994 Hartmann, \rD. \r(1994).\r \rGlobal Physical Climatology.\r \rAcademic Press.\r)\r.¬†‚Ü©Ô∏é\nThe Surface Albedo is a parameter in this model. You might explore the effect of changing its value.¬†‚Ü©Ô∏é\nIt is known that on Earth the top 100 meters of the oceans mix much quicker than the layers below (\rCitation: Hartmann, 1994 Hartmann, \rD. \r(1994).\r \rGlobal Physical Climatology.\r \rAcademic Press.\r)\r. This Mixing Height is another parameter in this model. You can find it in the Settings.¬†‚Ü©Ô∏é",
    "description": "This simple radiation balance model shows the greenhouse effect that an atmosphere can have in warming a planet.  By trapping some of the radiation emitted by the planet the atmosphere can cause the surface to become warmer than it otherwise would be.",
    "tags": [],
    "title": "Aquaworld Radiation Balance (2018)",
    "uri": "/~rikblok/science/models/aquaworld/index.html"
  },
  {
    "breadcrumb": "Scientific scribblings¬†\u003e¬†Models",
    "content": "A NetLogo (\rCitation: Wilensky, 1999 Wilensky, \rU.(1999). Retrieved from \rhttp://ccl.northwestern.edu/netlogo/\r)\rmodel by Rik Blok.\nI recently read an interesting review paper (\rCitation: Brown, West\r\u0026 al., 2009 Brown, \rS., \rWest, \rS., \rDiggle, \rS. \u0026 Griffin, \rA.\r \r(2009).\r Social evolution in micro-organisms and a Trojan horse approach to medical intervention strategies.\rPhilosophical Transactions of the Royal Society B: Biological Sciences, 364(1533). 3157‚Äì3168.\rhttps://doi.org/10.1098/rstb.2009.0055\r)\rthat explores the possibility of fighting a bacterial infection with Darwinian medicine through the introduction of a ‚Äúcheater‚Äù strain of bacteria into a wild population. I extended the analytic model in the paper to an agent-based model with explicit spatial structure.\nThis agent-based model represents a bacterial infection as described in (\rCitation: Brown, West\r\u0026 al., 2009 Brown, \rS., \rWest, \rS., \rDiggle, \rS. \u0026 Griffin, \rA.\r \r(2009).\r Social evolution in micro-organisms and a Trojan horse approach to medical intervention strategies.\rPhilosophical Transactions of the Royal Society B: Biological Sciences, 364(1533). 3157‚Äì3168.\rhttps://doi.org/10.1098/rstb.2009.0055\r)\r. It is assumed the wild type ($W$) produces a public good ($F$) which benefits all. To combat the infection the population is innoculated with a ‚Äúcheater‚Äù strain ($C$). The cheater strain has one or more of the following traits:\nIt consumes but does not produce the public good ($F$), It produces a toxin ($T$) that harms all, It produces a bacteriocinogen ($B$) it is immune to but harms the wild type. 1 How it works The simulation approximates a Poisson process for each of the above events. The best known technique would be the Gillespie algorithm (\rCitation: Gibson \u0026 Bruck, 2000 Gibson, \rM. \u0026 Bruck, \rJ.\r \r(2000).\r Efficient Exact Stochastic Simulation of Chemical Systems with Many Species and Many Channels.\rJ. Phys. Chem. A, 104(9). 1876‚Äì1889.\rhttps://doi.org/10.1021/jp993732q\r)\rbut it isn‚Äôt well suited to NetLogo‚Äôs strengths. Instead, time proceeds in steps with multiple events occurring in each timestep.\nThe step size is adaptive, chosen to achieve a desired error tolerance, compared with the Gillespie algorithm. When the error tolerance is near zero the likelihood of each event is small and we may expect just a few events to occur per timestep. Then we‚Äôre accurately ‚Äì but inefficiently ‚Äì mimicking the Gillespie algorithm. As the tolerance increases we have more simultaneous events, lowering accuracy but increasing performance.\nTip\rFor a long run you may want to increase the speed slider (reduces frame rate) and/or increase err-tolerance (reduces accuracy). The default parameters often give interesting cyclical patterns1. Table 1 has parameter values that can be used to compare against (\rCitation: Brown, West\r\u0026 al., 2009 Brown, \rS., \rWest, \rS., \rDiggle, \rS. \u0026 Griffin, \rA.\r \r(2009).\r Social evolution in micro-organisms and a Trojan horse approach to medical intervention strategies.\rPhilosophical Transactions of the Royal Society B: Biological Sciences, 364(1533). 3157‚Äì3168.\rhttps://doi.org/10.1098/rstb.2009.0055\r)\r. 2 Theory This simulation incorporates three ideas from Section 2 of (\rCitation: Brown, West\r\u0026 al., 2009 Brown, \rS., \rWest, \rS., \rDiggle, \rS. \u0026 Griffin, \rA.\r \r(2009).\r Social evolution in micro-organisms and a Trojan horse approach to medical intervention strategies.\rPhilosophical Transactions of the Royal Society B: Biological Sciences, 364(1533). 3157‚Äì3168.\rhttps://doi.org/10.1098/rstb.2009.0055\r)\r:\n(a) A cheat that does not produce exoproducts (public goods), (b) Trojan horse cheats, and (d) Bacteriocinogen cheat invasion. Instead of approximating spatial structure with the relatedness factor $r$ in 2(c) ‚ÄúTrojan horse cheat in a spatially structured host‚Äù I just explicitly put the bacteria in space ‚Äì they diffuse in a two-dimensional continuum with periodic boundaries.\n3 Numeric model Combining (a), (b), and (d) gives the following dynamical equations for the rate of change of the wild ($W$) and cheat ($C$) strain densities:\n\\begin{equation} \\begin{array}{rcrccccl} \\frac{dW}{dt} \u0026 = \u0026 W ( \u0026 \\overbrace{1}^{\\text{growth}} \u0026 \\overbrace{- N}^{\\text{competition}} \u0026 \\overbrace{- x}^{\\text{costs}} \u0026 \\overbrace{+ b W / N}^{\\text{public good}} \u0026 \\overbrace{- a C / N}^{\\text{toxication}} \u0026 \\overbrace{- e C / N}^{\\text{bacteriocide}} ) \\cr \\frac{dC}{dt} \u0026 = \u0026 C ( \u0026 1 \u0026 - N \u0026 - q \u0026 + b W / N \u0026 - a C / N ) \\end{array} \\end{equation} (1) where\n$N = W + C$ is the total bacterial density, $x$ is the cost of producing the public good, $q$ is the direct growth cost of the cheat (if any), $b$ is the benefit of the public good, $a$ is the strength of the antibacterial toxin, and $e$ is the efficacy of the bacteriocinogen. These two equations combine Eqs. (2.1)-(2.5) from (\rCitation: Brown, West\r\u0026 al., 2009 Brown, \rS., \rWest, \rS., \rDiggle, \rS. \u0026 Griffin, \rA.\r \r(2009).\r Social evolution in micro-organisms and a Trojan horse approach to medical intervention strategies.\rPhilosophical Transactions of the Royal Society B: Biological Sciences, 364(1533). 3157‚Äì3168.\rhttps://doi.org/10.1098/rstb.2009.0055\r)\r‚Äì the effects can be explored separately in the simulation by moving sliders of other parameters to zero. The numeric dynamics are displayed as faint curves in the ‚Äúdynamics‚Äù and ‚Äúphase‚Äù graphs. They are included to validate and compare with the agent-based model.\n‚Äã\rTable 1\rFigure $W(0)$,\ninitial-W-density $C(0)$,\ninitial-C-density $x$,\nx-wild-cost $q$,\nq-cheater-cost $b$,\nb-shared-benefit $a$,\na-toxin-production $e$,\ne-bacteriocinogen well-mixed,\n$r=0$ 4(a) 1.1 0.001 0.1 0 0.2 0 0 Yes 4(b) 1.1 0.001 0.1 0 0.2 0 0 No 4(c) 1.1 0.001 0.1 0.01 0.2 0.5 0 Yes 4(d) 1.1 0.001 0.1 0.01 0.2 0.5 0 No 4(e) 1.1 0.001 0.1 0.01 0.2 -0.3 0 Yes 4(f) 1.1 0.001 0.1 0.01 0.2 -0.3 0 No 5(a) 1.1 0.001 0.1 0.15 0.2 0 0.5 Yes 5(b) 1.1 0.13 0.1 0.15 0.2 0 0.5 Yes 5(c) 1.1 0.001 0.1 0.05 0.2 0 0.5 Yes 5(d) 1.1 0.13 0.1 0.05 0.2 0 0.5 Yes Table 1: Parameter values used in the figures of Brown, West, et al. (2009), for comparison. The well-mixed cases usually agree with my model dynamics, except for stochastic noise due to demographics (eg. extinction of one type).\n4 Agent-based model The numeric model can be derived as a non-spatial limiting case of an agent-based model. In this model we explicitly represent each individual ‚Äúagent‚Äù in the system instead of treating them as identical and just tracking aggregate population densities. A convenient approach is to borrow reaction kinetics from physical chemistry to describe allowed interactions in our model.\nTo capture the numeric model we require five types/species2:\n$W$ is a wild-type bacterium, $C$ is a cheat bacterium, $F$ is a parcel of food, $T$ is a parcel of toxin, and $B$ is a parcel of bacteriocinogen. We simply allow these agents to interact stochastically at given rates according to the following reactions:\n\\begin{equation} \\begin{array}{rclrcll} N \u0026 \\xrightarrow{1} \u0026 2 N \u0026 \u0026 \u0026 \u0026 \\text{(growth)} \\cr W + N \u0026 \\xrightarrow{1} \u0026 N, \u0026 C + N \u0026 \\xrightarrow{1} \u0026 N \u0026 \\text{(competition)} \\cr W \u0026 \\xrightarrow{x} \u0026 \\emptyset, \u0026 C \u0026 \\xrightarrow{q} \u0026 \\emptyset \u0026 \\text{(costs)} \\cr W \u0026 \\xrightarrow{b} \u0026 W + F, \u0026 N + F \u0026 \\xrightarrow{\\beta} \u0026 2 N \u0026 \\text{(public good)} \\cr C \u0026 \\xrightarrow{a} \u0026 C + T, \u0026 N + T \u0026 \\xrightarrow{\\delta} \u0026 \\emptyset \u0026 \\text{(toxication)} \\cr C \u0026 \\xrightarrow{e} \u0026 C + B, \u0026 C + B \u0026 \\xrightarrow{\\gamma} \u0026 C \u0026 \\text{(bacteriocide)} \\cr \u0026 \u0026 \u0026 W + B \u0026 \\xrightarrow{\\gamma} \u0026 \\emptyset \\end{array} \\end{equation} (2) where $\\emptyset$ indicates an absence of products and $N$ is shorthand for either $W$ or $C$.\nA moment‚Äôs review should satisfy the reader that these reactions are reasonable prescriptions. For example, $W \\xrightarrow{b} W + F$ indicates that each wild-type bacterium produces a food parcel at an average rate of $b$ per unit time. A bacterium that encounters a food parcel consumes it at rate $\\beta$ and benefits by reproducing, $N + F \\xrightarrow{\\beta} 2 N$.\nIn the agent-based approach we model these processes explicitly and track all of the agents as they are produced, changed, or removed from the system. To connect with the numeric model we apply the law of mass action to compute the dynamics of a large, well-mixed population following the above reactions:\n\\begin{equation} \\begin{array}{rcrccccl} \\frac{dW}{dt} \u0026 = \u0026 W ( \u0026 \\overbrace{1}^{\\text{growth}} \u0026 \\overbrace{- N}^{\\text{competition}} \u0026 \\overbrace{- x}^{\\text{costs}} \u0026 \\overbrace{+ \\beta F}^{\\text{public good}} \u0026 \\overbrace{- \\delta T}^{\\text{toxication}} \u0026 \\overbrace{- \\gamma B}^{\\text{bacteriocide}} ) \\cr \\frac{dC}{dt} \u0026 = \u0026 C ( \u0026 1 \u0026 - N \u0026 - q \u0026 + \\beta F \u0026 - \\delta T ) \\cr \\frac{dF}{dt} \u0026 = \u0026 \u0026 \u0026 \u0026 \u0026 b W - \\beta F N \\cr \\frac{dT}{dt} \u0026 = \u0026 \u0026 \u0026 \u0026 \u0026 \u0026 a C - \\delta T N \\cr \\frac{dB}{dt} \u0026 = \u0026 \u0026 \u0026 \u0026 \u0026 \u0026 \u0026 e C - \\gamma B N. \\end{array} \\end{equation} (3) 5 Quasi-steady-state approximation Eq. (3) looks much more complicated than Eq. (1) we‚Äôre trying to relate it to. But we can reduce the system if we assume that the densities $F$, $T$, and $B$ are //fast// variables ‚Äì that they respond quickly to perturbations and quickly converge to equilibrium. If we assume that they converge so quickly that the slow variables ($W$ and $C$) don‚Äôt change appreciably while the fast ones equilibrate then we can approximate the fast variables as always being in equilibrium ‚Äì the [[wp\u003eMichaelis%E2%80%93Menten_kinetics#Quasi-steady-state_approximation | quasi-steady-state approximation]] (QSSA):\n\\[ \\begin{array}{rcl} F \u0026 = \u0026 b W / \\beta N \\cr C \u0026 = \u0026 a C / \\delta N \\cr B \u0026 = \u0026 e C / \\gamma N. \\end{array} \\]Then Eq. (3) reduces to exactly Eq. (1) and the agent-based model in Eq. (2) is an extension of (\rCitation: Brown, West\r\u0026 al., 2009 Brown, \rS., \rWest, \rS., \rDiggle, \rS. \u0026 Griffin, \rA.\r \r(2009).\r Social evolution in micro-organisms and a Trojan horse approach to medical intervention strategies.\rPhilosophical Transactions of the Royal Society B: Biological Sciences, 364(1533). 3157‚Äì3168.\rhttps://doi.org/10.1098/rstb.2009.0055\r)\rto finite populations. Unfortunately, finding the conditions to satisfy QSSA is not trivial (\rCitation: Segel \u0026 Slemrod, 1989 Segel, \rL. \u0026 Slemrod, \rM.\r \r(1989).\r The Quasi-Steady-State Assumption: A Case Study in Perturbation.\rSIAM Review, 31(3). 446.\rhttps://doi.org/10.1137/1031091\r)\r. Nevertheless, it should be satisfied if all of the rate constants $\\beta$, $\\delta$, and $\\gamma$ are large. In the simulation I set them all to the same large constant so we may expect differences between the agent-based and numeric models result from other causes, such as spatial structure.\n6 Spatial structure Brown et al. (\rCitation: 2009 Brown, \rS., \rWest, \rS., \rDiggle, \rS. \u0026 Griffin, \rA.\r \r(2009).\r Social evolution in micro-organisms and a Trojan horse approach to medical intervention strategies.\rPhilosophical Transactions of the Royal Society B: Biological Sciences, 364(1533). 3157‚Äì3168.\rhttps://doi.org/10.1098/rstb.2009.0055\r)\rcreate a structured population in Section 2(c) through preferential interactions of the bacteria with kin, mimicking spatial segregation. Implementing it as an agent-based model in NetLogo allows me to explicitly include space: agents move continuously in a two-dimensional plane with periodic boundary conditions. Reactions are localized to patches on a square grid. In the limit of large population size and infinitesimal patch size mass action swamps stochastic effects and the model should become equivalent to a reaction-diffusion system.\nI arbitrarily chose to allow only the bacteria (wild and cheater types) to move. Byproducts (food, toxin, \u0026 bacteriocinogen) are stationary after being created. Some other options would be to allow the byproducts to move (for example, as if they were diffusing via Brownian motion) or for both bacteria and byproducts to move (possibly at different rates).\nUnlike other events, which are treated as probabilistic stochastic processes, every moving agent moves in every time increment according to a random walk, with a jump size is governed by the diffusion constant. The effects of spatial structure can be minimized by mixing((Enable the well-mixed switch to rapidly stir the system.)). Only bacteria move so there may still be some spatial effects from the stationary byproducts but the dynamics should be more similar to the numeric (mean field) approximation.\n7 References Brown, \rWest, \rDiggle \u0026 Griffin\r(2009)\rBrown, \rS., \rWest, \rS., \rDiggle, \rS. \u0026 Griffin, \rA.\r \r(2009).\r Social evolution in micro-organisms and a Trojan horse approach to medical intervention strategies.\rPhilosophical Transactions of the Royal Society B: Biological Sciences, 364(1533). 3157‚Äì3168.\rhttps://doi.org/10.1098/rstb.2009.0055\rGibson \u0026 Bruck\r(2000)\rGibson, \rM. \u0026 Bruck, \rJ.\r \r(2000).\r Efficient Exact Stochastic Simulation of Chemical Systems with Many Species and Many Channels.\rJ. Phys. Chem. A, 104(9). 1876‚Äì1889.\rhttps://doi.org/10.1021/jp993732q\rSegel \u0026 Slemrod\r(1989)\rSegel, \rL. \u0026 Slemrod, \rM.\r \r(1989).\r The Quasi-Steady-State Assumption: A Case Study in Perturbation.\rSIAM Review, 31(3). 446.\rhttps://doi.org/10.1137/1031091\rWilensky\r(1999)\rWilensky, \rU.(1999). Retrieved from \rhttp://ccl.northwestern.edu/netlogo/\r8 Footnotes The simulation‚Äôs default parameters violate the Quasi-steady-state approximation so the equations in (\rCitation: Brown, West\r\u0026 al., 2009 Brown, \rS., \rWest, \rS., \rDiggle, \rS. \u0026 Griffin, \rA.\r \r(2009).\r Social evolution in micro-organisms and a Trojan horse approach to medical intervention strategies.\rPhilosophical Transactions of the Royal Society B: Biological Sciences, 364(1533). 3157‚Äì3168.\rhttps://doi.org/10.1098/rstb.2009.0055\r)\rare not applicable.¬†‚Ü©Ô∏é\nNote the overlapping notation: the symbols for individual agents are re-used to represent the densities of said types. Hopefully, the context (eg. density in a rate equation) is sufficient to prevent confusion.¬†‚Ü©Ô∏é",
    "description": "I recently read an interesting review paper that explores the possibility of fighting a bacterial infection with Darwinian medicine through the introduction of a ‚Äúcheater‚Äù strain of bacteria into a wild population.  I extended the analytic model in the paper to an agent-based model with explicit spatial structure.",
    "tags": [],
    "title": "A Trojan horse approach to medical intervention strategies (2017)",
    "uri": "/~rikblok/science/models/brown2009/index.html"
  },
  {
    "breadcrumb": "Scientific scribblings¬†\u003e¬†Models",
    "content": "A NetLogo (\rCitation: Wilensky, 1999 Wilensky, \rU.(1999). Retrieved from \rhttp://ccl.northwestern.edu/netlogo/\r)\rmodel by Rik Blok.\nI got thinking about how fires work today. Why do flames curl into whorls and some tongues lick up so high? I built this model to see how hard it was to reproduce the phenomenon. This is the result. I don‚Äôt think it captures much of the underlying mechanism but it looks pretty hot üôÇ\nThis is a simple particle-based simulation of flames. Individual ‚Äúparticles‚Äù of flame are produced at the bottom of the world and burn as they float up. It‚Äôs not meant to capture real fire dynamics but just simulate the look.\nReferences Wilensky\r(1999)\rWilensky, \rU.(1999). Retrieved from \rhttp://ccl.northwestern.edu/netlogo/",
    "description": "I got thinking about how fires work today. Why do flames curl into whorls and some tongues lick up so high? I built this model to see how hard it was to reproduce the phenomenon. This is the result. I don‚Äôt think it captures much of the underlying mechanism but it looks pretty hot üôÇ",
    "tags": [],
    "title": "Flame (2017)",
    "uri": "/~rikblok/science/models/flame/index.html"
  },
  {
    "breadcrumb": "Scientific scribblings¬†\u003e¬†Models",
    "content": "A NetLogo (\rCitation: Wilensky, 1999 Wilensky, \rU.(1999). Retrieved from \rhttp://ccl.northwestern.edu/netlogo/\r)\rmodel by Rik Blok.\nExplore the Mandelbrot Set and these related fractals:\nMultibrot set Mandelbar set Burning ship 1 Demonstration This movie was made by turning on the record-png switch and the zoom-every button, and setting the jump-size to 1%. The sequence of PNG images were stitched together and set to Rossini‚Äôs William Tell Overture Finale with Windows Live Movie Maker.\n2 Mappings Each fractal is defined by a function in the complex plane. Starting with an initial value z=0, each point c in the plane is repeatedly iterated through the map, z ‚Üí f(z,c). The mapping function is characterized by an exponent, d (d-multibrot-exp slider in the simulation), as follows:\nMandelbrot: f(z,c) = z2 + c (same as Multibrot with d=2) Multibrot: f(z,c) = zd + c Mandelbar: f(z,c) = Conj(z)d + c Burning ship: f(z,c) = (|Re(z)| + i |Im(z)|)d + c A point c is excluded from the set if the value z diverges after repeated iteration. In the simulation, excluded points are painted a color indicating how many iterations were required to decide they have diverged. Black points indicate undecided candidates that may belong to the set.\n3 Other implementations and examples This implementation of the Mandelbrot set is neither fast nor beautiful ‚Äì it‚Äôs just a proof of concept and a demonstration of how to code in NetLogo. If you‚Äôre interested in the Mandelbrot set or similar fractals, check out these excellent pages:\nGoogle‚Äôs Julia Map Last Lights On - video of Mandelbrot zoom to 10228 4 References Wilensky\r(1999)\rWilensky, \rU.(1999). Retrieved from \rhttp://ccl.northwestern.edu/netlogo/",
    "description": "Explore the Mandelbrot set and some related fractals.",
    "tags": [],
    "title": "Mandelbrot Set (2017)",
    "uri": "/~rikblok/science/models/mandelbrot_set/index.html"
  },
  {
    "breadcrumb": "Academic anecdotes¬†\u003e¬†Old courses",
    "content": "Game Theory in Economics and Evolution (Fall 2016) Exploration of human and animal interactions: integrating evolutionary and economic perspectives to investigate individual and social behaviour.\nIntroduction We‚Äôre taking our first steps towards flipping the classroom! Here you can find video lectures and notes that replace in-class lectures.\n01 The Ultimatum Game 02 Extensive and normal form games 03 Dominance and Pareto optimality 04 Symmetric and zero-sum games 05 Sotto vs. Blotto and mixed Nash equilibria 06 Deriving mixed Nash equilibria 07 Deriving Expected Utility Theory 08 Evolutionary Game Theory 09 An asymmetric evolutionary game 10 Multiplayer games 11 Public goods with punishment 12 Repeated games Lecture notes Here‚Äôs the whole collection of lecture notes for the videos:\n01 The Ultimatum Game.pdf 02 Extensive and normal form games.pdf 03 Dominance and Pareto Optimality.pdf 04 Symmetric and zero-sum games.pdf 05 Sotto vs. Blotto and mixed Nash equilibria.pdf 06 Deriving mixed Nash equilibria.pdf 07 Deriving Expected Utility Theory.pdf 08 Evolutionary Game Theory.pdf 09 An asymmetric evolutionary game.pdf 10 Multiplayer games.pdf 11 Public goods with punishment.pdf 12 Repeated games.pdf",
    "description": "Game Theory in Economics and Evolution (Fall 2016))\nExploration of human and animal interactions: integrating evolutionary and economic perspectives to investigate individual and social behaviour.",
    "tags": [],
    "title": "UBC ISCI 344 (2016)",
    "uri": "/~rikblok/teaching/past/isci344/index.html"
  },
  {
    "breadcrumb": "Mathematical musings",
    "content": "Remember Euler‚Äôs number, $e=2.71828$‚Ä¶ ? One of the Bernoulli boys showed that it‚Äôs the limit of $(1 + 1/n)^n$ as $n$ goes to infinity. But if $n$ goes to infinity then we should be able to add an arbitrary constant $c$ to the denominator without changing the result. So, more generally,\n$$e = \\lim_{n\\rightarrow \\infty} \\left(1+\\frac{1}{n+c}\\right)^n.$$The question that came to my mind then is, what is the ‚Äúbest‚Äù constant to choose? It turns out you can show it‚Äôs $c=-1/2$. In other words, the limit of $(1+1/(n-1/2))^n$ converges to $e$ faster than Bernoulli‚Äôs formula (or any other $c$). In fact, it‚Äôs 99% accurate for $n=3$ (versus $n=50$ for Bernoulli).\nDerivation Here‚Äôs how I figured it out. Let‚Äôs call the $n$-th number in the sequence $E_n$:\n$$E_n = \\left(1+\\frac{1}{n+c}\\right)^n.$$Ideally, we want $E_n=e$ for all $n$. But then $c$ is no longer a constant. In fact, we can isolate $c$ in the above equation (with $E_n=e$) to find out how $c$ would depend on $n$:\n$$c(n) = \\left( e^{1/n} - 1 \\right)^{-1} - n.$$Now we want to know if $c$ converges to a constant as $n\\rightarrow\\infty$. But that‚Äôs tricky. It becomes much simpler if we take $u=1/n$ and look at what happens as $u\\rightarrow 0$.\n$$c(u) = \\left( e^u - 1 \\right)^{-1} - \\frac{1}{u}.$$Then we can expand $c$ as a Taylor series around $u=0$ (effectively, a Taylor expansion around $n=\\infty$, which is pretty cool!) to get\n$$c(u) \\approx -\\frac{1}{2} + \\frac{u}{12} + \\cdots$$So the best choice as a constant for large $n$ is $c=-1/2$ which gives a sequence\n$$E_n^{(1)} = \\left(1+\\frac{1}{n - 1/2}\\right)^n = \\left(\\frac{2 n + 1}{2 n - 1}\\right)^n.$$Higher order terms Including higher order terms in the approximation allows to find sequences that converge even faster! For example, the next order approximation would be $c(n) = -1/2 + 1/(12 n)$, which would give a sequence\n$$E_n^{(2)} = \\left( \\frac{12 n^2 + 6 n + 1}{12 n^2 - 6 n + 1} \\right)^n.$$It‚Äôs not as pretty an expression but it converges very quickly! It‚Äôs already more than 99.8% accurate for $n=1$! (For $n=1$ the result simplifies to the fraction $E_1^{(2)}=19/7\\approx 2.714$.)\nSummary I found replacing $c=0$ in the sequence $\\left(1+\\frac{1}{n+c}\\right)^n$ with $c=-1/2$ makes it converge to Euler‚Äôs number much faster as $n\\rightarrow \\infty$. Does it matter? Probably not. But I sure had a fun afternoon! :-)\n‚Äî Rik Blok, 2014",
    "description": "I found a sequence that converges to Euler‚Äôs constant faster than Bernoulli‚Äôs formula.",
    "tags": [],
    "title": "Euler's constant: An improved sequence (2014)",
    "uri": "/~rikblok/math/eulers_constant/index.html"
  },
  {
    "breadcrumb": "Research ramblings¬†\u003e¬†Unpublished notes",
    "content": "Deriving the replicator equation from birth-death processes Blok\r(2013)\rBlok, \rH.(2013, 7/12). Retrieved from \rhttps://www.cs.ubc.ca/~rikblok/research/notes/replicator_kinetics/index.html\rVersion 1 ‚Äî Rik Blok, 2013-07-12\nAbstract I‚Äôve long felt that reaction kinetics, a formalism for describing agent-based models, would fit naturally with evolutionary game theory, but I‚Äôve had trouble seeing the connections. Here I explore several possible systems of reactions that yield evolutionary dynamics consistent with the replicator equation. They are also useful for studying finite, structured populations. Some of these approaches also exhibit plausible ecological dynamics in the absence of selection.\n1 Introduction Evolutionary game theory uses the replicator equation to formalize the dynamics of selected heritable traits in a population. It is frequently used to predict the evolutionarily stable state of an infinite, well-mixed population. Often it is interesting to study cases where the population is finite or not well-mixed, where the replicator equation isn‚Äôt suitable. Such a case is better suited to an agent-based model where each individual in a population is explicitly accounted.\nThere are a variety of approaches to agent-based modeling but I am keen on reaction kinetics because it is simple to understand, easy to apply, and behaves predictably in the limit of a large, well-mixed population. Also, the underlying mechanisms have clear interpretations if the reactions are elementary.\nIt would be useful to have a reaction-kinetic framework for game theory and the replicator equation. It could complement other agent-based formalisms for studying finite, structured populations. Below I will show a reaction kinetics approach to game theory that captures some important properties of the replicator equation.\nI have three goals:\nSelection should act in a replicator equation-like manner, with the same behaviour at least up to a time-rescaling, In the absence of selection, the density should obey the logistic equation, and The reactions should be simple, preferably elementary. In the following sections we will explore several ways to define birth-death reactions, analyzing them to see how well they meet the above goals.\nSelect births, ecological deaths Replacement Select deaths, ecological births Select births with a separate game Select births into available ‚Äúholes‚Äù I use the term ‚Äúselect‚Äù to indicate processes that select for traits (differential fitness) and ‚Äúecological‚Äù to mean processes that affect all individuals equally, independent of their type.\n2 Select births, ecological deaths Consider a population of heritable types where an individual of type \\(i\\), \\(X_i\\), acquires a payoff \\(P_{ij}\\) against \\(X_j\\) in pairwise interactions. Further assume that an individual‚Äôs birthrate is determined by its payoff. Conversely, the deathrate depends only on the total population density, $n$: \\begin{eqnarray} X_i + X_j \u0026 \\xrightarrow{P_{ij}} \u0026 2 X_i + X_j \u0026 \\text{(birth)} \\cr X_i \u0026 \\xrightarrow{\\delta(n)} \u0026 \\emptyset. \u0026 \\text{(death)} \\end{eqnarray} The birth process performs evolutionary selection, while the death process is purely ecological (because it drives population density but not frequency of types, on average). The deathrate could be any non-negative function (even $\\delta(n)=0$ leaving only the birth process and a geometrically increasing population).\n2.1 Rate equations These two processes can be applied to simulate a finite population, or analyzed in the limit of an infinite, well-mixed population. Then we find the dynamics are very similar to the replicator equation and reproduce some important properties thereof. The Law of mass action allows to compute the rate equation for the density \\(x_i=[X_i]\\) of type \\(i\\): \\begin{equation} \\frac{dx_i}{dt} = x_i \\left( \\sum_j P_{ij} x_j - \\delta(n) \\right) \\end{equation} where the total population density is \\(n\\equiv \\sum_k x_k\\) and follows \\begin{equation} \\frac{dn}{dt} = \\sum_k \\frac{dx_k}{dt} = \\sum_{jk} P_{kj} x_j x_k - n \\delta(n). \\end{equation}\n2.2 Fitness Let $y_i=x_i/n$ be the frequency of type $i$. We define its fitness\n\\begin{equation} f_i\\equiv \\sum_j P_{ij} y_j \\end{equation} (2.1) as its per-capita average birthrate and the mean fitness\n\\begin{equation} \\bar{f} \\equiv \\sum_k f_k y_k \\end{equation} (2.2) is the overall population per-capita average birthrate.\nThen the frequency of type $i$ obeys \\begin{eqnarray} \\frac{dy_i}{dt} \u0026 = \u0026 \\frac{1}{n} \\left[ \\frac{dx_i}{dt} - y_i \\frac{dn}{dt} \\right] \\cr \u0026 = \u0026 n \\left[ y_i \\left( \\sum_j P_{ij} y_j - \\frac{1}{n} \\delta(n) \\right) - y_i \\left( \\sum_{jk} P_{kj} y_j y_k - \\frac{1}{n} \\delta(n) \\right) \\right] \\cr \u0026 = \u0026 n y_i (f_i - \\bar{f}). \\end{eqnarray} (2.3) For comparison, the replicator equation is $dy_i/dt = y_i (f_i - \\bar{f})$, differing only by a factor $n$. So our ‚Äúreplicator kinetics‚Äù have exactly the same stability properties as the replicator equation, the only difference is that the rate of evolution varies with the population size. In particular, the evolutionarily stable state is the same in both frameworks.\n2.3 Ecology In terms of fitness $f$ the density rate equation becomes \\begin{equation} \\frac{dn}{dt} = n \\left(n \\bar{f} - \\delta(n) \\right) \\end{equation} where $\\bar{f}$ itself varies with the population structure.\nIn the special case where we neglect selection $P_{ij}\\equiv r=\\text{constant}$ for all $i,j$ so only ecology pertains, then $\\bar{f}=r$ and the ecological dynamics become \\begin{equation} \\frac{dn}{dt} = r n^2 \\left(1 - \\frac{n}{K} \\right) \\end{equation} where $K \\equiv r n^2 / \\delta(n)$. If $\\delta(n) \\propto n^2$ then $K$ is a constant carrying capacity. The dynamics are similar to logistic except the quadratic factor depresses the growth rate when the population is small, a weak Allee effect.\n2.4 Bounded population \\[ 3 X \\xrightarrow{\\text{constant}} 2 X \\] or equivalently $\\delta(n) \\propto n^2$, where $X$ represents an individual of any type.\n3 Replacement \\[ X_i + X_j + X_k \\xrightarrow{P_{ij}} 2 X_i + X_j \\; \\text{ (replacement)} \\]\\(X_k\\) is simply a bystander who may be replaced by a child of \\(X_i\\), depending on its payoff against \\(X_j\\). In this case the population size is fixed so we recover exactly the replicator equation, without a fluctuating rate depending on the population size as in Equation 2.3.\n4 Select deaths, ecological births We could also design a system with an ecological (non-selective) birth process and a selective death process (that depends on payoffs). Let $\\pi \\geq \\max_{i,j} P_{ij}$ be a constant. Then \\begin{eqnarray} X_i \u0026 \\xrightarrow{\\beta(n)} \u0026 2 X_i \u0026 \\text{(birth)} \\cr X_i + X_j \u0026 \\xrightarrow{\\pi - P_{ij}} \u0026 X_j \u0026 \\text{(death)} \\end{eqnarray} where $\\beta(n)$ is a birthrate that may depend on the population density but not its composition. For a stable, finite population it requires that $\\beta(n) \\prec n$ grows slower than $n$, such as spontaneous birth, $\\beta(n) =\\text{constant}$.\nIn this system, a higher payoff reduces the death rate, increasing the survival time.\n4.1 Ecology Let‚Äôs consider again the dynamics without selection: $P_{ij} = \\text{constant} \u003c \\pi$ for all $i,j$ so $\\bar{f} = \\text{constant}$. Then we can define $K=\\beta(n)/(\\pi-\\bar{f})$ and ‚Äî applying Equations 2.1, 2.2, and 2.3 to the rate equations ‚Äî we find \\begin{equation} \\frac{dn}{dt} = \\beta(n) n \\left(1 - \\frac{n}{K} \\right). \\end{equation} If we have a constant birthrate $\\beta(n)\\equiv r = \\text{constant}$ then we exactly recover the logistic equation.\n5 Select births with a separate game Is it possible to formulate a system with logistic ecological behaviour but with selection acting on births instead of deaths? It‚Äôs tricky because evolutionary game theory requires pairwise interactions but the birth process must be first-order (spontaneous). To achieve this we need to separate the ‚Äúgame‚Äù from the births: Let‚Äôs introduce pairwise interactions that determine the birthrates of individuals as follows: \\begin{eqnarray} Z_{ik} + Z_{jl} \u0026 \\xrightarrow{\\gamma} \u0026 Z_{ij} + Z_{jl} \u0026 \\text{(game)} \\cr Z_{ij} \u0026 \\xrightarrow{P_{ij}} \u0026 2 Z_{ij} \u0026 \\text{(birth)} \\cr Z_{ij} \u0026 \\xrightarrow{\\delta(n)} \u0026 \\emptyset. \u0026 \\text{(death)} \\end{eqnarray} We use $Z$ to denote these individuals because they carry two pieces of information: their own type and the type of their last co-player in the game. The density of type $i$ (regardless of last co-player) is now $x_i = \\sum_j z_{ij}$ and $n = \\sum_i x_i$.\nIn terms of the frequencies $w_{ij} \\equiv z_{ij}/n$ and $y_i \\equiv x_i/n = \\sum_j w_{ij}$, after some work (see Appendix) we find \\begin{equation} \\frac{dy_i}{dt} = \\sum_j P_{ij} w_{ij} - y_i \\sum_{kl} P_{kl} w_{kl}. \\end{equation}\nIf we define the fitness of type $i$ \\begin{equation} f_i\\equiv \\frac{1}{y_i} \\sum_j P_{ij} w_{ij} \\end{equation} (5.1) as its per-capita average birthrate and the mean fitness \\begin{equation} \\bar{f} \\equiv \\sum_i f_i y_i = \\sum_{ij} P_{ij} w_{ij} \\end{equation} then we find \\begin{eqnarray} \\frac{dy_i}{dt} \u0026 = \u0026 y_i ( f_i - \\bar{f}) \\cr \\frac{dn}{dt} \u0026 = \u0026 n (\\bar{f} - \\delta(n)). \\end{eqnarray} (5.2) 5.1 Ecology Without selection, so $P_{ij}\\equiv r=\\text{constant}$ for all $i,j$, we require $\\delta(n)=r n/K$ to get the logistic equation\n\\begin{equation} \\frac{dn}{dt} = r n \\left(1 - \\frac{n}{K} \\right). \\end{equation} (5.3) To achieve that each individual should compete with all others through a reaction like, \\begin{eqnarray} Z_{ik} + Z_{jl} \u0026 \\xrightarrow{\\delta} \u0026 Z_{jl}. \u0026 \\text{(competitive death)} \\end{eqnarray}\n6 Select births into available ‚Äúholes‚Äù The logistic equation derives from two simple reaction kinetic approaches: $N \\rightleftharpoons 2 N$ or with explicit ecological ‚Äúholes‚Äù, $H$: $N+H\\rightarrow 2 N, N\\rightarrow H$. Here the ‚Äúholes‚Äù serve to limit the population without explicit competition; a successful birth won‚Äôt occur without a hole for the offspring to occupy. Since the total population of holes and individuals is conserved, the population is controlled. The former approach is similar to Select births, ecological deaths, suggesting that we should also consider the latter.\n\\begin{eqnarray} X_i + X_j + H \u0026 \\xrightarrow{P_{ij}} \u0026 2 X_i + X_j \u0026 \\text{(birth)} \\cr X_i \u0026 \\xrightarrow{\\delta(n)} \u0026 H. \u0026 \\text{(death)} \\end{eqnarray}\nIf the total population, including ‚Äúholes‚Äù is conserved, $K\\equiv \\sum_l x_l + h$, then the rate equations for this reaction set can be written, substituting $h=K-\\sum_l x_l$, as: \\begin{equation} \\frac{dx_i}{dt} = x_i \\left( \\left(K - \\sum_l x_l\\right) \\sum_j P_{ij} x_j - \\delta(n) \\right) \\end{equation} where the total population density \\(n\\) follows \\begin{equation} \\frac{dn}{dt} = \\sum_k \\frac{dx_k}{dt} = \\left(K - \\sum_l x_l\\right) \\sum_{jk} P_{kj} x_j x_k - n \\delta(n). \\end{equation}\nThe rate equation for the frequency comes out more complicated than before but it‚Äôs still ‚Äúreplicator-like‚Äù in the sense that the equilibria and stabilities are the same as the replicator equation: \\begin{equation} \\frac{dy_i}{dt} = n y_i \\left(f_i - \\bar{f}\\right) \\left(K - n \\sum_l y_l\\right). \\end{equation}\n6.1 Discussion In this section we went back to select births and ecological deaths but separated the ‚Äúgame‚Äù (assignment of birthrates) from the birth process. With a slightly modified fitness function (Equation 5.1) we were able to achieve all of our goals: (1) replicator equation-like frequency dynamics (Equation 5.2), and (2) logistic ecological behaviour (Equation 5.3), with (3) only elementary reactions.\n7 Summary We have looked at four different systems of elementary reactions that produce replicator equation-like dynamics (having the same stability properties, only different in the rate of approach). Two of theses cases also have the pleasing property that they ‚Äúfall back‚Äù to logistic population dynamics in the absence of selection. A third is logistic with a weak Allee effect. The last, Replacement, is less realistic in that the population size is fixed.\nSystem Processes1 Replicator-like? Ecology2 Select births, ecological deaths \\begin{eqnarray*} X_i + X_j \u0026 \\xrightarrow{P_{ij}} \u0026 2 X_i + X_j \u0026 \\text{(birth)} \\cr X_i + 2 X \u0026 \\xrightarrow{\\delta} \u0026 2 X. \u0026 \\text{(death)} \\end{eqnarray*} Yes Logistic with weak Allee effect Replacement $$ X_i + X_j + X_k \\xrightarrow{P_{ij}} 2 X_i + X_j $$ Yes None (constant population size) Select deaths, ecological births \\begin{eqnarray*} X_i \u0026 \\xrightarrow{\\beta} \u0026 2 X_i \u0026 \\text{(birth)} \\cr X_i + X_j \u0026 \\xrightarrow{\\pi - P_{ij}} \u0026 X_j \u0026 \\text{(death)} \\end{eqnarray*} Yes Logistic Select births with a separate game \\begin{eqnarray*} Z_{ik} + Z_{jl} \u0026 \\xrightarrow{\\gamma} \u0026 Z_{ij} + Z_{jl} \u0026 \\text{(game)} \\cr Z_{ij} \u0026 \\xrightarrow{P_{ij}} \u0026 2 Z_{ij} \u0026 \\text{(birth)} \\cr Z_{ik} + Z_{jl} \u0026 \\xrightarrow{\\delta} \u0026 Z_{jl} \u0026 \\text{(death)} \\end{eqnarray*} Yes Logistic Here are some ideas for future consideration:\nCan this approach be extended to \\(N\\)-player games (eg. the public goods game)? Is there a general ‚Äúsolution‚Äù for a finite population, eg. Fokker-Planck? 8 Appendix 8.1 Derivation of rate equation for frequency of type in case of select births with a separate game In terms of the frequencies $w_{ij} \\equiv z_{ij}/n$ and $y_i \\equiv x_i/n = \\sum_j w_{ij}$ \\begin{eqnarray} \\frac{dz_{ij}}{dt} \u0026 = \u0026 \\gamma \\sum_{kl} ( z_{ik} z_{jl} - z_{ij} z_{kl} ) + P_{ij} z_{ij} - \\delta(n) z_{ij} \\cr \u0026 = \u0026 \\gamma ( x_i x_j - z_{ij} n ) + (P_{ij} - \\delta(n)) z_{ij}. \\end{eqnarray} (8.1) \\begin{eqnarray} \\frac{dw_{ij}}{dt} \u0026 = \u0026 \\frac{1}{n} \\left[ \\frac{dz_{ij}}{dt} - w_{ij} \\frac{dn}{dt} \\right] \\cr \\frac{dx_i}{dt} \u0026 = \u0026 \\sum_j \\frac{dz_{ij}}{dt} \\cr \u0026 = \u0026 \\gamma (x_i n - n x_i) + \\sum_j P_{ij} z_{ij} - \\delta(n) x_i \\cr \u0026 = \u0026 \\sum_j P_{ij} z_{ij} - \\delta(n) x_i. \\cr \\frac{dn}{dt} \u0026 = \u0026 \\sum_i \\frac{dx_i}{dt} \\cr \u0026 = \u0026 n \\left( \\sum_{ij} P_{ij} w_{ij} - \\delta(n) \\right). \\end{eqnarray} From Equation 8.1 \\begin{eqnarray} \\frac{dz_{ij}}{dt} \u0026 = \u0026 \\gamma n^2 ( y_i y_j - w_{ij} ) + n (P_{ij} - \\delta(n)) w_{ij} \\cr \\frac{dw_{ij}}{dt} \u0026 = \u0026 \\frac{1}{n} \\left[ \\frac{dz_{ij}}{dt} - w_{ij} \\frac{dn}{dt} \\right] \\cr \u0026 = \u0026 \\gamma n (y_i y_j - w_{ij}) + (P_{ij} - \\delta(n)) w_{ij} - w_{ij} \\sum_{kl} P_{kl} w_{kl} + \\delta(n) w_{ij} \\cr \\frac{dy_i}{dt} \u0026 = \u0026 \\sum_j P_{ij} w_{ij} - y_i \\sum_{kl} P_{kl} w_{kl}. \\end{eqnarray}\n9 References Blok\r(2013)\rBlok, \rH.(2013, 7/12). Retrieved from \rhttps://www.cs.ubc.ca/~rikblok/research/notes/replicator_kinetics/index.html\r10 Footnotes Reactions written in tems of preferred elementary reactions. All rates parameters are constant, independent of population density or structure.¬†‚Ü©Ô∏é\nIn the absence of selective pressure, $P_{ij}=\\text{constant}$.¬†‚Ü©Ô∏é",
    "description": "Here I explore several possible systems of reactions that yield evolutionary dynamics consistent with the replicator equation.  They are also useful for studying finite, structured populations.",
    "tags": [],
    "title": "Replicator Kinetics (2013)",
    "uri": "/~rikblok/research/notes/replicator_kinetics/index.html"
  },
  {
    "breadcrumb": "Computational capers",
    "content": "‚Äî Rik Blok, 2011-03-20 (with data thru 2021-01)\nNote\rI wrote the text on this page between 1993 and 2011, when computer components were changing rapidly. I continued collecting data and updating the statistics and figures thru 2021, when the trends were already showing a dramatic slowdown. Now, looking back on this page from 2025, it‚Äôs remarkable how different the current trends are.\n‚Äî Rik Blok, 2025-02-06\nYears ago I heard it said that computers were doubling in performance every year or two (a claim related‚Äìbut not identical‚Äìto Moore‚Äôs Law); that is, two years from now you could buy a computer twice as powerful/fast as today for the same price or less. I was curious to see if this was true so I started tracking the prices of individual components on a monthly basis. I am biased towards [[wp\u003eWintel]] PCs with a total price under $2000 Canadian, so I track components typical for such machines.\nMotherboards ‚Äã\rMotherboards\rFigure 1: Historical motherboard performance\nUnits: MHz/$, megaHertz per dollar (Cdn) Doubling time: 1564 ¬± 5180 months1 (flat) Motherboard performance, measured in MHz/$, is currently doubling every 1564 ¬± 5180 months1 (flat). Notice that I am measuring performance for the motherboard as a whole, not just the CPU. There have been fluctuations but the trend does look more or less exponential. A friend of mine (Andy Horton) pointed out there was a noticeable dip every year around December. This is most likely due to prices being jacked up for Christmas sales.\nProcessor speed depends on how many transistors can be fit on a chip, which has a theoretical maximum set by quantum mechanics. If the circuits get too close together the electrons will start ‚Äútunneling‚Äù through barriers and the chip won‚Äôt function properly. I‚Äôm not sure what the limit is, but as we approach it, expect the doubling time to stretch out‚Äìat least until manufacturers find a new way to get around (or take advantage of) this problem.\nOf course, every new generation of processor may perform better (or worse!) than the last, even at the same clock speed so I weighted the clock speed by an estimation of how fast each chip architecture is compared to a current chip:\n‚Äã\rSpeed factors\rArchitecture Speed Factor i8086 0.0025 i286 0.011 i386sx 0.016 i386dx 0.023 i486dx 0.047 i486dx2 0.039 i486dx4 0.031 Pentium 0.093 Pentium MMX 0.11 Pentium 2 0.12 Pentium 3 0.14 AMD Duron 0.14 AMD Athlon XP 0.13 Intel Core 2 Duo 0.51 ntel Core 2 Quad 0.72 Intel Core i5 0.90 Intel Core i7 1.00 Table 1: Estimated relative speed factors of past chip architectures (if running at the same clock speeds). Athlon speed is scaled by performance rating (eg. 1800+) not actual clock speed (eg. 1.53GHz).\nSo a 2.4GHz Core 2 Duo E6600 will perform about five times as fast as an Athlon XP 2000+.\nComparing different processors opens up a can of worms such as the impact of other components (eg. RAM, front-side bus, etc.) on performance. But, I don‚Äôt really care about all this‚Ä¶I just want to get an estimate of the typical speed of these machines so I just get my numbers by comparing application and game benchmarks for typically-configured machines.\nRAM ‚Äã\rRAM\rFigure 2: Historical RAM performance\nUnits: MiB/$, mebiBytes per dollar (Cdn) Doubling time: 53 ¬± 19 months1 RAM performance, measured in MiB/$, is currently doubling every 53 ¬± 19 months‚Ä¶but it‚Äôs a real wild ride! Notice that the graph is virtually flat until November 1995 and then explodes upwards. As I understand it this is due to a monopoly on SIMM modules which toppled around then. At the time (October 1995) the doubling time was a whopping 53 ¬± 9 months! After some fluctuations when the market opened up, it looks like RAM performance grew at a natural rate for a while.\nThere was an huge hiccup at the end of 2001 which was apparently due to price fixing.\nAgain, performance depends on how many transistors can be fit on a chip which has a theoretical maximum. Unlike motherboard performance, however, I don‚Äôt expect this to slow down the RAM performance doubling time because‚ÄìHey!‚Äìthe manufacturers can always just add more memory banks, right?\nStorage ‚Äã\rStorage\rFigure 3: Historical storage performance\nUnits: GB/$, gigabytes per dollar (Cdn) Doubling time: -85 ¬± 34 months1 (declining) Hard drive capacity, measured in GB/$, is currently doubling every -85 ¬± 34 months (declining). The graph was showing exponential growth until late 2011 when flooding in Thailand caused production shortages.\nBandwidth ‚Äã\rBandwidth\rFigure 4: Historical bandwidth performance\nUnits: kbps/$/month, kilobits per second per dollar (Cdn) per month Doubling time: 56 ¬± 14 months1 Bandwidth (the speed of an internet connection) is difficult to measure because it depends on your internet provider, and current conditions (eg. is there heavy usage?) so I don‚Äôt have as good of data. But the data I do have suggests the doubling time for bandwidth performance (versus monthly fees) is 56 ¬± 14 months. I calculate my bandwidth by doing speed tests weekly and then taking the median value from the last five weeks to reduce the noise.\nModems ‚Äã\rModems\rFigure 5: Historical modem performance\nUnits: kbps/$, kilobits per second per dollar (Cdn) Doubling time: 200 ¬± 77 months1 They‚Äôve stopped advertising dial-up modems in my local sources so I‚Äôm not tracking this technology anymore. But before they were obsoleted the estimated doubling time for modem performance was 200 ¬± 77 months. But you just have to look at the graph to realize exponential growth isn‚Äôt a good fit. Did modem performance plateau due to technical or economic factors, I wonder?\nNote that 56kbps modems never actually ran at that rate, it‚Äôs just a theoretical maximum (and a nice marketing ploy). The fastest my modem ever connected at (and maintained) was 46kbps so that‚Äôs the speed I used when calculating performance.\nThe Bottom Line The average doubling time for the motherboard, memory, and hard drive is currently 511 months. Sounds good, right? Well, the down side is that you‚Äôll have to keep laying out cash to keep your computer current. In that amount of time your brand-spanking new computer will only be half as ‚Äúgood‚Äù as the latest. (Actually I‚Äôm neglecting a lot of components like monitors and sound cards, but this should still be a good estimate.) This is the same as saying a computer loses 1.6% of its value each year. To maintain it you will have to regularly lay out some cash for upgrades.\nIf you‚Äôre laying out that kind of cash you might as well buy an entirely new system every 743 months! (That‚Äôs neglecting the money you‚Äôll get back for selling your old computer. If you factor it in then you should replace your system even more often‚Äìevery time the performance doubles, every 511 months!) Most people use a combination of the above strategies: they upgrade a bit to slow the decline of their system, and when it just gets too outdated they replace it.\nWhen buying a new system, be careful of unscrupulous vendors that may take advantage of this rapid drop in prices to make money. After the price is settled and the down payment made, some vendors may delay ordering the system for a week or two. In the meantime the value of your system drops marginally. Then the vendors buy at the lower price, but sell to you at the original higher price, and skim a profit off the top. For a \\$2000 machine, a two week delay will earn them roughly \\$1.96. Not much, but still something to watch out for.\nMath Stuff The component prices come from advertisements in local shops. I compiled the data and made estimates of what the actual doubling time, \\(\\tau\\), is, as follows. If there is a doubling trend over time, \\(t\\), then the performance (per dollar), \\(P(t)\\), should increase as\n\\[ P(t) = P(0) 2^{t/\\tau}. \\]Taking the logarithm of both sides gives\n\\[ \\log_2(P(t))=t/\\tau + \\log_2(P(0)) \\]which is just the straight line equation\n\\[ y(t)=mt+b \\]where \\(m=1/\\tau\\). So all we have to do is take the logarithm of the performance data and fit it to a straight line to get the parameters \\(m\\) and \\(b\\), which allow us to calculate \\(\\tau\\). The exact calculations for fitting to a straight line can be found in any statistics textbook or try Press et al. (\rCitation: 1992 Press, \rW., \rTeukolsky, \rS., \rVetterling, \rW. \u0026 Flannery, \rB. \r(1992).\r \rNumerical Recipes in C: The Art of Scientific Computing (Second).\r \rCambridge University Press. Retrieved from \rhttp://www.nr.com/\r)\r, Chapter 15.\nAlso given therein is a procedure to estimate the uncertainties in the parameters even without knowing the measurement errors. So it is possible to calculate the uncertainty in the slope \\(m\\) which is related to the uncertainty in the doubling time by\n\\[ \\frac{\\sigma_\\tau}{\\tau} = \\frac{\\sigma_m}{m}. \\]By using this method the ‚Äúgoodness of fit‚Äù is incorporated into the doubling time uncertainty: a large uncertainty means a poor fit.\nReferences Press, \rTeukolsky, \rVetterling \u0026 Flannery\r(1992)\rPress, \rW., \rTeukolsky, \rS., \rVetterling, \rW. \u0026 Flannery, \rB. \r(1992).\r \rNumerical Recipes in C: The Art of Scientific Computing (Second).\r \rCambridge University Press. Retrieved from \rhttp://www.nr.com/\rThe doubling time is calculated from the slope of the trend line fitted using a discounted least squares (DLS) technique with a memory of 18 months. DLS fitting smoothly discounts historical data with an exponential window to emphasize the most recent trend.¬†‚Ü©Ô∏é¬†‚Ü©Ô∏é¬†‚Ü©Ô∏é¬†‚Ü©Ô∏é¬†‚Ü©Ô∏é¬†‚Ü©Ô∏é",
    "description": "Years ago I heard it said that computers were doubling in performance every year or two; that is, two years from now you could buy a computer twice as powerful/fast as today for the same price or less. I was curious to see if this was true so I started tracking the prices of individual components on a monthly basis.",
    "tags": [],
    "title": "Trends in Computing (2011)",
    "uri": "/~rikblok/compute/trends/index.html"
  },
  {
    "breadcrumb": "Academic anecdotes¬†\u003e¬†Old courses",
    "content": "",
    "description": "Models in Science (Fall 2009)\nMeaning, nature, use, strengths and limitations of models as investigative tools in all scientific disciplines. Detailed investigation of selected model systems from different scientific disciplines.",
    "tags": [],
    "title": "UBC ISCI 422 (2009)",
    "uri": "/~rikblok/teaching/past/isci422/index.html"
  },
  {
    "breadcrumb": "Scientific scribblings",
    "content": "I‚Äôve recently been asked to describe my teaching philosophy. My initial response was dismissive: ‚ÄúWhat‚Äôs a teaching philosophy?‚Äù But after mulling it over for a few days I‚Äôve recognized that it‚Äôs important to be able to express your motivations and inspirations. How else can you be sure they make sense? So, here‚Äôs what drives me as a teacher.\nScience I teach Science. Not physics, not zoology, etc., but Science. The students who come into my classes are nearing completion of their Bachelor of Science degrees and they have very strong backgrounds in many different fields of science. And yet they‚Äôre usually missing something fundamental from their science education: what Science is. I don‚Äôt blame them‚Ä¶or their instructors. After all, it concerns issues that I didn‚Äôt think much about until after I got my Doctorate! When you‚Äôre busy learning scientific theories and methods it‚Äôs hard to step back and put it all in context. Undergraduate science students today are ‚Äúsubconsciously‚Äù taking in bits and pieces of what Science is and how it works but they‚Äôve never been pushed to formulate it in a cohesive, explicit manner.\nSo what is Science? I don‚Äôt want to define it here but let me just say it‚Äôs a special way of understanding the world around us and our place in it. But it‚Äôs not the only way. Isn‚Äôt most university education about furthering our understanding? Yet Science is only one faculty of many in a typical university. At UBC in 2006/07 the Faculty of Science represented only about one quarter of all undergraduate students. Clearly, there are many other ways to discover truths. Consider some of the departments and schools in the Faculty of Arts: Fine Arts, History, Philosophy, Sociology, Religion, etc. Each of these provides knowledge and understanding of important aspects of our experience.\nScience is no better or worse a tool to gain understanding than the others I have mentioned. But it is unique in how it works: scientists try to find explanations for nature‚Äôs inner workings and then devise clever observations to test whether their explanations hold up to scrutiny. In most other fields of study the ultimate litmus test is how palatable an idea is. If it explains something and is consistent with our prior experiences then we may well accept a new idea as true (or at least possible). Conversely, if it runs contrary to our experience then we may reject it (or consider discarding some of our previously-held beliefs). In the end, it‚Äôs a personal test‚Äìwe need to be personally convinced of new ideas in most fields.\nScientific ideas, though, ultimately face the harsh judgment of cold, hard, objective reality((Note that not all ideas/explanations can be scientific. For example, there may be no way to design an experiment that could potentially falsify an idea. This is a topic of discussion left for another day. And I won‚Äôt even get into the issue of whether an objective ‚ÄúReality‚Äù exists.)). It doesn‚Äôt matter how elegant or powerful a new scientific explanation for a phenomenon may be, if it fails to be supported by experiment we must discard it. This is reminiscent of H. L. Mencken‚Äôs wonderful barb: ‚Äúthere is always an easy solution to every problem ‚Äî neat, plausible and wrong.‚Äù I realize what I‚Äôm describing is an ideal‚Äîreal science is often much messier and often parts with favoured theories only grudgingly‚Äîbut it is an ideal we should strive for!\nCuriosity \u0026 skepticism In essence, Science is driven by two motivators: curiosity and skepticism. Curiosity makes us look at nature and ask, ‚ÄúThat‚Äôs interesting‚Äìwhy should it be so?‚Äù The question motivates us to come up with an explanation. At this point, we‚Äôve potentially increased our understanding, learned a new truth. But how do we know it‚Äôs true? In many fields of study we would present an argument and try to convince our peers of the idea‚Äôs truth. But in Science we must be skeptics: we have to test our theory against reality. That means coming up with a prediction and looking at empirical evidence to see if it supports or rejects the idea.\nTo be clear, skepticism is not cynicism. A cynic may say ‚ÄúWell, I don‚Äôt believe that!‚Äù But a skeptic would add ‚ÄúLet‚Äôs find out!‚Äù And therein lies the double-edged power of science: we try to make sense of our surroundings (curiosity) and then we test our ideas against available evidence (skepticism). Perhaps we should call scientists ‚Äúcurious skeptics‚Äù.\nAnd that‚Äôs what I want my students to become: curious skeptics. That doesn‚Äôt mean they should become career scientists (necessarily). Rather, I‚Äôd like to foster curiosity and skepticism in their natures so it stays with them for life, wherever they go and whatever they do. Some problems they encounter won‚Äôt be amenable to this approach but many will. And if they learn to reach first for their curiosity \u0026 skepticism when tackling a new problem, they‚Äôll quickly discover just how many questions can be approached scientifically!\nScience works because nature is personally accessible. Everybody can check the truth for themselves. It‚Äôs not always easy but in principle it can be done. In fact, testing theories in ‚Äúeveryday life‚Äù is often easier than it is in professional science. Maybe you‚Äôre thinking of buying a home. Will it increase in value? Here‚Äôs a theory: property values increase with population density because land is a finite resource. If that‚Äôs true then you should be able to find a correlation between population and home values. Those data aren‚Äôt too hard to find. Compare that with the effort that‚Äôs being put into trying to find the Higgs boson.\nBenefits Why do I want my students to become curious skeptics? First, I want them to realize their full potential. I get a lot of satisfaction personally from working not above nor below my abilities and I believe that the same will hold for my students. Applying curiosity and skepticism to their own persons will reveal their natural affinities and limitations. While it can be a bitter lesson at the moment, I believe candidly evaluating oneself helps avoid more severe distress in the long-term. (Not everybody can be an astronaut.) Second, I believe my students will have an advantage in life by becoming curious skeptics. These qualities are not widely taught but they are valuable. So those who have them will have skills in demand. A good boss will come to value the employee who challenges his/her assumptions. (A poor boss won‚Äôt‚Äîbut do you really want to work for that kind of person?)\nBut beyond that I think fostering curious skepticism is a good thing for our society. In the last several years we‚Äôve seen a number of alarming policy decisions that appear to have been personally or politically motivated, rather than being based on evidence. For example, last year Canada cut funding for the Kyoto protocol despite growing evidence that climate change is real and human-caused. The debate over teaching Intelligent Design in American science classrooms is still being fought (even though it is not a scientific theory). And closer to home, it appears the Insite supervised injection clinic is under constant threat of being shut down in spite of evidence that it helps addicts get off drugs. Even more overtly, recently Environment Canada scientists were instructed not to talk to the media directly. The motive here is unclear but the effect isn‚Äôt: scientific evidence being collected on behalf of Canadian taxpayers is now being withheld and filtered from those same taxpayers.\nI have concerns that this trend signals a shift in attitudes: policy makers would rather make decisions that are easy, cheap, or self-serving than look skeptically at the problem and try to find solid evidence. It is my hope that by encouraging curiosity and skepticism in students we can promote critical, evidence-based thinking in society and turn this trend around.\n‚Äî Rik Blok, 2008",
    "description": "Here‚Äôs what drives me as a teacher.",
    "tags": [],
    "title": "The curious skeptic (2008)",
    "uri": "/~rikblok/science/curious_skeptic/index.html"
  },
  {
    "breadcrumb": "Research ramblings¬†\u003e¬†Published",
    "content": "Multimodal pattern formation in phenotype distributions of sexual populations Doebeli, \rBlok, \rLeimar \u0026 Dieckmann\r(2007)\rDoebeli, \rM., \rBlok, \rH., \rLeimar, \rO. \u0026 Dieckmann, \rU.\r \r(2007).\r Multimodal pattern formation in phenotype distributions of sexual populations.\rProceedings of the Royal Society B: Biological Sciences, 274(1608). 347‚Äì357.\rhttps://doi.org/10.1098/rspb.2006.3725\rAbstract During bouts of evolutionary diversification, such as adaptive radiations, the emerging species cluster around different locations in phenotype space. How such multimodal patterns in phenotype space can emerge from a single ancestral species is a fundamental question in biology. Frequency-dependent competition is one potential mechanism for such pattern formation, as has previously been shown in models based on the theory of adaptive dynamics. Here, we demonstrate that also in models similar to those used in quantitative genetics, phenotype distributions can split into multiple modes under the force of frequency-dependent competition. In sexual populations, this requires assortative mating, and we show that the multimodal splitting of initially unimodal distributions occurs over a range of assortment parameters. In addition, assortative mating can be favoured evolutionarily even if it incurs costs, because it provides a means of alleviating the effects of frequency dependence. Our results reveal that models at both ends of the spectrum between essentially monomorphic (adaptive dynamics) and fully polymorphic (quantitative genetics) yield similar results. This underscores that frequency-dependent selection is a strong agent of pattern formation in phenotype distributions, potentially resulting in adaptive speciation.\nDownload",
    "description": "During bouts of evolutionary diversification the emerging species cluster around different locations in phenotype space. How such multimodal patterns in phenotype space can emerge from a single ancestral species is a fundamental question in biology. Here, we demonstrate that phenotype distributions can split into multiple modes under the force of frequency-dependent competition‚Ä¶",
    "tags": [],
    "title": "Multimodal pattern formation in phenotype distributions of sexual populations (2007)",
    "uri": "/~rikblok/research/published/doebeli07/index.html"
  },
  {
    "breadcrumb": "Research ramblings¬†\u003e¬†Published",
    "content": "A tale of two cycles - distinguishing quasi-cycles and limit cycles in finite predator-prey populations Pineda-Krch, \rBlok, \rDieckmann \u0026 Doebeli\r(2007)\rPineda-Krch, \rM., \rBlok, \rH., \rDieckmann, \rU. \u0026 Doebeli, \rM.\r \r(2007).\r A tale of two cycles - distinguishing quasi-cycles and limit cycles in finite predator-prey populations.\rOikos, 116(1). 53‚Äì64.\rhttps://doi.org/10.1111/j.2006.0030-1299.14940.x\rAbstract Periodic predator-prey dynamics in constant environments are usually taken as indicative of deterministic limit cycles. It is known, however, that demographic stochasticity in finite populations can also give rise to regular population cycles, even when the corresponding deterministic models predict a stable equilibrium. Specifically, such quasi-cycles are expected in stochastic versions of deterministic models exhibiting equilibrium dynamics with weakly damped oscillations. The existence of quasi-cycles substantially expands the scope for natural patterns of periodic population oscillations caused by ecological interactions, thereby complicating the conclusive interpretation of such patterns. Here we show how to distinguish between quasi-cycles and noisy limit cycles based on observing changing population sizes in predator-prey populations. We start by confirming that both types of cycle can occur in the individual-based version of a widely used class of deterministic predator-prey model. We then show that it is feasible and straightforward to accurately distinguish between the two types of cycle through the combined analysis of autocorrelations and marginal distributions of population sizes. Finally, by confronting these results with real ecological time series, we demonstrate that by using our methods even short and imperfect time series allow quasi-cycles and limit cycles to be distinguished reliably.\nDownload",
    "description": "Periodic predator-prey dynamics in constant environments are usually taken as indicative of deterministic limit cycles. It is known, however, that demographic stochasticity in finite populations can also give rise to regular population cycles. Here we show how to distinguish between quasi-cycles and noisy limit cycles based on observing changing population sizes in predator-prey populations. We demonstrate that by using our methods even short and imperfect time series allow quasi-cycles and limit cycles to be distinguished reliably‚Ä¶",
    "tags": [],
    "title": "A tale of two cycles - distinguishing quasi-cycles and limit cycles in finite predator-prey populations (2007)",
    "uri": "/~rikblok/research/published/pinedakrch07/index.html"
  },
  {
    "breadcrumb": "Research ramblings¬†\u003e¬†Published",
    "content": "Scale-free extinction dynamics in spatially structured host‚Äìparasitoid systems Killingback, \rBlok \u0026 Doebeli\r(2006)\rKillingback, \rT., \rBlok, \rH. \u0026 Doebeli, \rM.\r \r(2006).\r Scale-free extinction dynamics in spatially structured host‚Äìparasitoid systems.\rJournal of Theoretical Biology, 241(4). 745‚Äì750.\rhttps://doi.org/10.1016/j.jtbi.2006.01.010\rAbstract Much of the work on extinction events has focused on external perturbations of ecosystems, such as climatic change, or anthropogenic factors. Extinction, however, can also be driven by endogenous factors, such as the ecological interactions between species in an ecosystem. Here we show that endogenously driven extinction events can have a scale-free distribution in simple spatially structured host-parasitoid systems. Due to the properties of this distribution there may be many such simple ecosystems that, although not strictly permanent, persist for arbitrarily long periods of time. We identify a critical phase transition in the parameter space of the host-parasitoid systems, and explain how this is related to the scale-free nature of the extinction process. Based on these results, we conjecture that scale-free extinction processes and critical phase transitions of the type we have found may be a characteristic feature of many spatially structured, multi-species ecosystems in nature. The necessary ingredient appears to be competition between species where the locally inferior type disperses faster in space. If this condition is satisfied then the eventual outcome depends subtly on the strength of local superiority of one species versus the dispersal rate of the other.\nDownload",
    "description": "Much of the work on extinction events has focused on external perturbations of ecosystems, such as climatic change, or anthropogenic factors. Extinction, however, can also be driven by endogenous factors, such as the ecological interactions between species in an ecosystem. Here we show that endogenously driven extinction events can have a scale-free distribution in simple spatially structured host-parasitoid systems. Based on these results, we conjecture that scale-free extinction processes and critical phase transitions of the type we have found may be a characteristic feature of many spatially structured, multi-species ecosystems in nature‚Ä¶",
    "tags": [],
    "title": "Scale-free extinction dynamics in spatially structured host‚Äìparasitoid systems (2006)",
    "uri": "/~rikblok/research/published/killingback06/index.html"
  },
  {
    "breadcrumb": "Research ramblings¬†\u003e¬†Unpublished notes",
    "content": "Updating in simulations of parallel Poisson processes Blok\r(2004)\rBlok, \rH.(2004, 10/15). Retrieved from \rhttps://www.cs.ubc.ca/~rikblok/research/notes/parallel_poisson/index.html\rVersion 1 ‚Äî Rik Blok, 2004-10-15\nAbstract I explore how to efficiently implement Poisson processes in event-driven, multi-agent simulations. The most efficient strategy I am able to find uses a binary tree to implement the roulette wheel algorithm and results in \\(O(\\log_2 N)\\) time to find the next event out of \\(N\\) total processes. These notes arose from discussions with Mario Pineda, Alistair Blachford, and Michael Doebeli. Unpublished.\n1. Definition ‚Äî Rik Blok, 2004-09-26\nA Poisson process is a sequence of random events where the probability of an event is constant per unit time. Usually it is described in terms of a sequence of multiple events but in this discussion I will focus on the occurrence of a single event in the sequence. Let \\(c(t)\\) be the cumulative probability that the event has occurred by time t (starting at \\(t = 0\\)). Then, by the definition of a Poisson process, the probability of the event occurring between \\(t\\) and \\(t + dt\\) is given by the p.d.f.\n\\[ p(t) dt = (1 ‚àí c)r dt \\]where \\(r\\) is the average rate of the event sequence. This gives the probability that the event has not occurred yet \\((1 ‚àí c)\\) and then occurs in the specified interval \\((r dt)\\).\nSince the p.d.f. is the derivative of the cumulative, \\(p(t) \\equiv dc/dt\\), we find that\n\\[ \\frac{dc}{1-c} = r\\, dt \\]so the cumulative distribution is given by\n\\[ c(t) = 1 - e^{-r t} \\]and the p.d.f. is\n\\[ p(t) = r e^{-r t}. \\]The above gives the distribution for a single event. Below, we expand this to consider a number of possible events, each given by a Poisson process with an unique rate \\(r_j\\) . The problem is: how do we simulate such a process efficiently?\n2. Roulette wheel algorithm ‚Äî Rik Blok, 2004-10-01\nIn a discrete-event simulation it is possible to sample random deviates for all possible events and construct an event queue to determine the order or events but it is cumbersome. The roulette wheel algorithm is algorithmically simpler. Given rates \\(r_j, j=1\\ldots N\\), the probability of event i acting first is\n\\[ \\Pr(i\\text{ first}) = \\frac{r_i}{\\sum_j r_j}. \\] ‚Äã\rFigure 1\rFigure 1: To select an event via the Roulette Wheel algorithm pick a random number \\(u\\) between \\(0\\) and \\(\\sum_j r_j\\). Then it will land within the area delimited by \\(r_i\\) with probability \\(r_i/\\sum_j r_j\\).\nWe can derive this from the Poisson distribution: let \\(t_i\\) be a random variable representing the waiting time to the first occurrence of event \\(i\\). Then the probability that event \\(i\\) is first (marginalizing over \\(t_i\\)) is\n\\[ \\begin{array}{rcl} \\Pr(t_i \u003c \\{t_j\\}_{j\\neq i}) \u0026 = \u0026 \\int_0^\\infty dt_i p_i(t_i) \\prod_{j\\neq i} (1 - c_j(t_i)) \\\\ \u0026 = \u0026 dt_i r_i e^{-\\sum_j r_j t_i} \\\\ \u0026 = \u0026 \\frac{r_i}{\\sum_j r_j} \\end{array} \\]where \\(p_i\\) and \\(c_i\\) represent the distributions for event \\(i\\) with rate \\(r_i\\). As shown in Figure 1, to pick an event, just pick a uniform deviate \\(0 \\leq u \u003c \\sum_j r_j\\), and select the maximum \\(i\\) such that\n\\[ \\sum_{j\\leq i} r_j \\leq u. \\]This method is simple to implement but computationally expensive since it requires \\(O(N)\\) operations (due to the summation) to compute each \\(i\\).\n3. Rejection method ‚Äî Rik Blok, 2004-10-01\nAn alternative to the roulette wheel is the rejection method. The idea is to pick a random event \\(i\\) and sample whether it passes a trial. We will begin by determining what the probability of a successful trial, \\(f\\), should be. We would like the trial to be generic so that it only depends on the event rate, \\(f(r_i)\\). Given \\(N\\) processes, the probability of a single failed trial is\n\\[ \\begin{array}{rcl} \\Pr(\\text{fail trial}) \u0026 = \u0026 \\text{for any } j: \\Pr(j)\\, \\Pr(\\text{fail given }j) \\\\ \u0026 = \u0026 \\sum_j \\frac{1}{N} (1 ‚àí f(r_j)) \\\\ \u0026 = \u0026 1 ‚àí \\bar{f} \\end{array} \\]where \\(\\bar{f} = \\sum_j f(r_j)/N\\).\nThe probability of \\(k\\) failed trials followed by a successful \\(i\\) event is\n\\[ \\Pr(k\\text{ fails then }i) = \\left[1 ‚àí \\bar{f}\\right]^k \\frac{1}{N} f(r_i). \\]So the probability of choosing \\(i\\) for any number \\(k\\) of failed trials is\n\\[ \\begin{array}{rcl} \\Pr(i\\text{ first}) \u0026 = \u0026 \\sum_{k \\geq 0} \\left[1 ‚àí \\bar{f}\\right]^k \\frac{1}{N} f(r_i) \\\\ \u0026 = \u0026 \\frac{f(r_i)}{N \\bar{f}}. \\end{array} \\]Notice that this satisfies the normalization condition: \\(\\sum_i \\Pr(i) = 1\\).\nWhat we‚Äôd like to find is a form for the trial probability \\(f\\) that produces the Poisson probability:\n\\[ \\Pr(i\\text{ first}) = \\frac{r_i}{\\sum_j r_j} = \\frac{f(r_i)}{\\sum_j f(r_j)}. \\]Since this must hold independently of the rates \\(r_j\\) we must have \\(f(r_j) \\propto r_j\\) which we can write as\n\\[ f(r) = \\frac{r}{\\hat{r}} \\]for some constant \\(\\hat{r}\\).\n3.1. Efficient computation ‚Äã\rFigure 2\rFigure 2: To select an event via the rejection method pick a random event \\(i\\) and a random deviate \\(0 \u003c u \u003c \\hat{r}\\). Accept if \\(u \u003c r_i\\) otherwise repeat.\nWe want to choose \\(\\hat{r}\\) in order to minimize the computational cost of the rejection method. Recall that \\(f\\) is to be interpreted as a probability so it must obey \\(f(r_j) \\leq 1\\) for all \\(r_j\\) which means that \\(\\hat{r} \\geq \\max(r_j)\\). Each time a trial is failed more work is required for a new trial so the number of trials should be minimized. The probability of a single failed trial is \\(1‚àí\\bar{r}/\\hat{r}\\) (where \\(\\bar{r} = \\sum_j r_j/N\\)) so the prob. of \\(k\\) trials is\n\\[ \\begin{array}{rcl} \\Pr(k\\text{ trials}) \u0026 = \u0026 \\text{for any }i:\\Pr(k ‚àí 1\\text{ fails then success with }i) \\\\ \u0026 = \u0026 \\sum_i \\left( 1 ‚àí \\frac{\\bar{r}}{\\hat{r}}\\right)^{k‚àí1} \\frac{1}{N} \\frac{r_i}{\\bar{r}} \\\\ \u0026 = \u0026 \\left( 1 ‚àí \\frac{\\bar{r}}{\\hat{r}}\\right)^{k‚àí1} \\frac{\\bar{r}}{\\bar{r}} \\end{array} \\]and the expected number of trials is\n\\[ \\langle k \\rangle = \\sum_k k \\Pr(k\\text{ trials}) = \\frac{\\hat{r}}{\\bar{r}}. \\] (1) So we can minimize \\(\\langle k \\rangle\\) by reducing \\(\\hat{r}\\) as much as possible, ideally by choosing \\(\\hat{r} = \\max(r_j)\\). Then the actual number of trials \\(\\langle k \\rangle\\) depends on the distribution of rates. The best case is if \\(\\max(r_j) \\propto \\bar{r}\\) so that \\(\\langle k \\rangle = O(1)\\) is independent of \\(N\\).\nBut if the rates are dynamic, if they change as the simulation progresses, then there is an added cost of continually updating \\(\\hat{r}\\). The worst choice would be to check all \\(N\\) rates and reset \\(\\hat{r}\\) appropriately whenever any rate changed. That would increase the cost of the rejection method to \\(O(N)\\) operations, no better than the Roulette Wheel.\nAn alternative would be to keep the rates sorted so that \\(r_j \\geq r_{j+1}\\) for all \\(j\\). Then \\(\\hat{r} = r_1\\), always. The cost involved would be that of adding and removing items from a sorted list. (I believe C++‚Äôs STL offers a ‚Äò‚Äô(multi)map‚Äô‚Äô container which is implemented as a binary tree giving typically \\(O(\\log N)\\) cost. Hash tables may also be suitable.)\nThat was assuming \\(\\hat{r}/\\bar{r}\\) was independent of \\(N\\). More realistically, we might expect the highest rate in the set to scale as \\(\\hat{r} \\propto \\bar{r} \\log N\\) so the total computational expense of this approach would grow as \\(O([\\log N]^2)\\) which is still much better than the Roulette Wheel.\n4. Faster implementation by sampling two events? ‚Äî Rik Blok, 2004-10-05\nI wonder if it is possible to find an even less costly method by sampling multiple event processes and comparing them? To explore this we will consider a variant of the rejection method where the trial probability of event \\(i\\) depends on a second sampled event \\(j \\neq i, f = f(r_i, r_j)\\). If \\(i\\) is rejected then two new events are drawn. Is there a trial function \\(f\\) that reproduces the Poisson process?\nIndependent of \\(j\\) the probability of \\(i\\) passing any single trial is\n\\[ \\Pr(i\\text{ this trial}) = \\frac{1}{N(N-1)} \\sum_{j\\neq i} f(r_i,r_j). \\]The probability of failing a trial, independent of the event \\(k\\) chosen is\n\\[ \\begin{array}{rcl} \\Pr(\\text{fail}) \u0026 = \u0026 \\sum_k \\Pr(\\text{choose }k) \\Pr(\\text{fail given }k) \\\\ \u0026 = \u0026 \\sum_{k,l\\neq k} \\frac{1}{N(N-1)} (1-f(r_k,r_l)) \\\\ \u0026 = \u0026 1 - \\bar{f} \\end{array} \\]where \\(\\bar{f} = \\sum_{k,l}f(r_k,r_l)/N(N-1)\\).\nLike the rejection method, the probability of \\(m\\) failed trials then a successful event \\(i\\) is\n\\[ \\Pr(m\\text{ fails then }i) = \\left[ 1-\\bar{f} \\right]^m \\frac{1}{N(N-1)} \\sum_{j\\neq i} f(r_i,r_j) \\]so the probability of event \\(i\\) occurring first is\n\\[\\begin{array}{rcl} \\Pr(i\\text{ first}) \u0026 = \u0026 \\sum_m \\left[ 1-\\bar{f} \\right]^m \\frac{1}{N(N-1)} \\sum_{j\\neq i} f(r_i,r_j) \\\\ \u0026 = \u0026 \\frac{1}{\\bar{f}} \\sum_j \\frac{f(r_i,r_j)}{N(N-1)}. \\end{array} \\]For this to produce Poisson updating we must have\n\\[ \\frac{r_i}{\\sum_k r_k} = \\frac{\\sum_j f(r_i,r_j)}{\\sum_{k,l} f(r_k,r_l)} \\]or \\(r_k \\propto \\sum_{l\\neq k} f(r_k,r_l)\\) which means that we can write\n\\[ f(r_k,r_l) = r_k g(r_l) \\]for some unknown function \\(g\\). Rather than working with \\(g\\) directly, it is more convenient to work with the partial sum \\(G_i=\\sum_{j\\neq i} g(r_j)\\) as we see here:\n\\[ \\frac{r_i}{\\sum_k r_k} = \\frac{r_i \\sum_{j\\neq i} g(r_j)}{\\sum_k r_k \\sum_{l\\neq k} g(r_l)} = \\frac{r_i G_i}{\\sum_k r_k G_k}. \\]Recall, we are trying to detemine the form of \\(G_i\\) that reproduces Poisson updating. For arbitrary rates \\(r_k\\) the above equation reduces to \\(\\sum_k G_k = N G_i\\) for all \\(i\\), which can only be satisfied if all \\(G_i\\) are equal. In other words, \\(g(r) = \\text{const.}\\) independent of \\(r\\) so the second sampling is irrelevant and we fall back to the original rejection method. It appears there is no way to improve on the rejection method by sampling multiple events.\n5. Rejection with adaptive correction ‚Äî Rik Blok, 2004-10-12\nMario came up with the idea of using the rejection method but relaxing restriction so that \\(\\hat{r} \\geq \\max(r)\\) is not strictly maintained at exactly \\(\\max(r)\\). It is cheap to enforce [with each new rate \\(r_i\\) just set \\(\\hat{r} = \\max(\\hat{r},r_i)\\) which is \\(O(1)\\)] but has a hidden cost: wasted rejection trials if \\(\\hat{r}\\) is too large. Mario‚Äôs idea was to recalculate \\(\\hat{r}\\) if the failed trials \\(k\\) were ever found to exceed some arbitrary threshold \\(k_\\max\\).\nThat‚Äôs good but I think we can do even better. There should be a way to choose how many //wasted// trials are acceptable. Recall from Eq. 1 that \\(\\langle k\\rangle =\\hat{r}/\\bar{r}\\). Since we can keep track of \\(\\bar{r}\\) in constant \\(O(1)\\) time [if a rate changes from \\(r_\\text{old}\\) to \\(r_\\text{new}\\) then \\(\\bar{r} \\gets \\bar{r} + (r_\\text{new} - r_\\text{old})/N\\) (where `\\(\\gets\\)‚Äô represents the assignment operator)] it is possible to compute the optimal expected number of trials per event whenever \\(\\max(r)\\) is known,\n\\[ k_\\text{opt} = \\frac{\\max(r)}{\\bar{r}}. \\] (2) Now we assume that \\(k_\\text{opt}\\) remains roughly constant even as the rates change. Basically we‚Äôre assuming that \\(\\max(r) \\propto \\bar{r}\\). So we only update \\(k_\\text{opt}\\) occasionally, whenever we are sure of \\(\\max(r)\\) (to be discussed).\nHaving a fairly accurate \\(k_\\text{opt}\\) lets us estimate how many trials are being wasted because our value of \\(\\hat{r}\\) is too high. It doesn‚Äôt tell us what \\(\\hat{r}\\) should be, just when we‚Äôre spending too much effort in rejection trials. The goal then, is to determine a criterion for when it is more efficient to correct \\(\\hat{r}\\) by reiterating the entire set of rates \\(r_i\\) instead of continuing to use our inefficient estimate.\nThe first thing we need to know is \\(\\omega\\), the relative cost of one rejection trial versus one iteration of the correction loop:\n\\[ \\omega = \\frac{\\text{cost(1 rejection trial)}}{\\text{cost(1 correction loop)}}. \\]This could be computed in advance and stored as a constant.\nThen we keep track of the number of trials \\(k_e\\) actually required for every event \\(e\\). After \\(E\\) total events since the last correction the relative waste \\(W\\) on failed trials is approximately\n\\[ W = \\sum_{e=1}^E (k_e - k_\\text{opt}) \\omega. \\]It would be reasonable to expect the waste over the //next// \\(E\\) events to be similar.\nIn contrast, the (relative) cost of correction is \\(N\\). That is also the total cost over the next \\(E\\) events if we assume the correction will eliminate the waste (optimistic). We want to minimize the computation over the next \\(E\\) events, so it is better to correct if the cost of not correcting is higher: \\(W \u003e N\\).\nNote that we can compute the waste since the last correction, \\(W\\) cumulatively in \\(O(1)\\) time after each event by keeping track of the trials \\(k\\) needed to find it:\n\\[ W \\gets W + (k - k_\\text{opt}) \\omega. \\]So after each event our adaptive correction criterion is: if \\(W\u003eN\\) then correct \\(\\hat{r}\\) and \\(k_\\text{opt}\\). Note we also correct whenever we encounter a new rate higher than \\(\\hat{r}\\) because it is essentially free. Whenever a correction occurs we reset the cumulative waste \\(W=0\\).\n5.1. Implementation and test A sample implementation of adaptive correction is shown in Listing 1. A simulation based on this code was compiled and run with a range of processes from \\(N=1\\) to \\(N=10^7\\). The process rates were initially sampled (and resampled after each event) from a log-normal distribution with some spread \\(\\sigma\\) (the standard deviation of the normal distribution). For small \\(\\sigma\\) the rates tend to be narrowly distributed, as \\(\\sigma\\) grows the highest rates can grow to be many orders of magnitude faster than the slowest. The results are shown in Figure 3. Note that for small and moderate spreads (\\(\\leq 2\\) orders of magnitude) the simulation speed is \\(O(1)\\), constant independent of the number of parallel processes, \\(N\\).\n‚Äã\rListing 1\rclass TParallelPoisson { /* Intended usage: // setup TParallelPoisson pp(10);\t// pass estimated cost unsigned long trials; double maxrate, sumrates; for (int i=0; i\u003cN; i++)\tpp.adjustRate(0,rate[i]); // main loop do { maxrate = pp.getMaxRate(); event = rejection_method(N, maxrate, \u0026trials); if (pp.correctionNeeded(trials)) { find_max_rate_and_sum_rates(\u0026maxrate,\u0026sumrates); pp.setMaxRate(maxrate,sumrates); } for (EACH_RATE_CHANGED_BY_EVENT) { pp.adjustRate(oldrate,newrate); } }while (!HELL_FROZEN_OVER); */ private: double waste; double sumrates; double avgrate; unsigned long numprocesses; double opttrials; double maxrate; double cost; void setMaxRateInt(double newmaxrate) { maxrate = newmaxrate; opttrials = maxrate / avgrate; waste = 0; } public: TParallelPoisson(double newcost) { // constructor reset(); } void reset() { waste=0; sumrates=0; avgrate=0; numprocesses=0; opttrials=0; maxrate=0; cost=newcost; } inline double getMaxRate() { return maxrate; } bool correctionNeeded(unsigned long trials) { // after rejection trials update waste cumulator // and report if correction necessary waste += cost * ((double)trials - opttrials); return (waste \u003e numprocesses); } void setMaxSumRate(double newmaxrate, double newsumrates) { // sets maxrate (and sumrates if passed) maxrate = newmaxrate; sumrates = newsumrates; avgrate = sumrates / numprocesses; opttrials = maxrate / avgrate; waste = 0; } bool adjustRate(double oldrate, double newrate) { // returns true if maxrate reset numprocesses += (newrate\u003e0) - (oldrate\u003e0); sumrates += newrate - oldrate; avgrate = sumrates / numprocesses; if (newrate \u003e= maxrate) setMaxRateInt(newrate); return (newrate \u003e= maxrate); } inline double getOptTrials(){ return opttrials; } inline bool poorPerformance() { return (opttrials*cost \u003e numprocesses); } };\rListing 1: C++ implementation of adaptive correction rejection method.\n‚Äã\rFigure 3\rFigure 3: Performance of adaptive correction rejection method as a function of the number of parallel processes, \\(N\\). For low to moderate \\(N\\) and spreads the running time is roughly constant. Rates are sampled from log-normal distribution [exponential of normally-distributed deviates with mean zero and variance \\(\\sigma^2\\)]. The spread is estimated to be the ratio of the 95th upper- versus lower-percentiles of the normal distributions, \\(e^{+2\\sigma}/e^{-2\\sigma}=e^{+4\\sigma}\\). \\(10^6\\) events were simulated and on each event the associated rate was resampled.\nUnfortunately, for large spreads the news is not as good: recall from Eq. 2 the expected number of trials grows as the ratio of the maximum rate over the average rate. If the rates are widely distributed then the highest may be orders of magnitude above average. In the tests this was simulated by setting \\(\\sigma\\) large and Figure 3 demonstrates that this had a severe impact on performance (top curve) for all \\(N\\). So the efficiency of adaptive correction depends critically on the distribution of rates; ideally, it would be better to have a method that didn‚Äôt depend on the distribution (which may not be known in advance).\n6. Roulette in a tree ‚Äî Rik Blok, 2004-10-14\nI‚Äôve thought of a faster way to implement the roulette wheel method. It relies on storing partial sums on a balanced binary tree structure and should run in \\(O(\\log_2 N)\\) time, independent of the distribution of rates. Unlike the adaptive correction rejection method the rates are now explicitly stored and manipulated as part of the data structure and each process must be labelled by an index \\(i=1,\\ldots, N\\) in order to access its corresponding rate.\nThe tree, shown in Figure 4, is important because it is guaranteed to be as well balanced as possible for any number of processes, \\(N\\). Further, it is easy to add or remove processes as necessary. (Removing is done by setting the appropriate rate to zero but leaving it in the tree.) Locating a node is also efficient, requiring \\(O(\\log_2 N)\\) operations.\n‚Äã\rFigure 4\rFigure 4: A binary tree with a one-to-one mapping onto positive integers. Each node has two children indicated by the branches 0 and 1. To locate the node representing an index we represent the index in binary. Starting at the root (which is always index 1) we follow the branches by reading the binary representation from right to left until we reach the final 1. For instance, the highlighted path to \\(i=14\\) (1110 in binary) is \\(0\\rightarrow 1 \\rightarrow 1\\).\n‚Äã\rFigure 5\rFigure 5: A single node in the binary tree used to optimize the roulette wheel algorithm. Each node \\(A\\) contains a rate \\(r_A\\), sum of rates \\(\\Sigma_A\\), and links to its parent \\(P\\) and children \\(C_0\\) and \\(C_1\\). \\(\\Sigma_A\\) is the sum of all the rates down the branch of \\(A\\), including \\(r_A\\) itself, \\(\\Sigma_A = r_A + \\Sigma_{C_0} + \\Sigma_{C_1}\\). Any non-existant nodes are assumed to have \\(r=\\Sigma=0\\).\nBut the real value of the binary tree is in how it ‚Äúdivides and conquers‚Äù the roulette wheel. We store in each node the rate of the associated process \\(r_A\\) and the sum of the rates in all nodes beneath it \\(\\Sigma_A\\) as shown in Figure 5. Recall, in the roulette wheel we draw a single random number \\(u\\) between zero and the sum of all rates and then iterate through each process to determine which one \\(u\\) ‚Äúlanded‚Äù on. The binary tree reduces that process because we can determine in one comparison whether \\(u\\) landed on any processes along a branch. If it did, then we proceed down that branch and compare again, recursively, to find the node that \\(u\\) selects.\nFor a given node \\(A\\) (with children \\(C_0\\) and \\(C_1\\) as shown in Figure 5) and random \\(u\\) in \\([0,\\Sigma_A)\\) there are three possibilities: if we line up the probabilities \\(r_A\\), \\(\\Sigma_{C_0}\\), and \\(\\Sigma_{C_1}\\) for the roulette wheel (see Figure 6) then \\(u\\) will land in the domain of \\(r_A\\) or \\(\\Sigma_{C_0}\\) or \\(\\Sigma_{C_1}\\). The algorithm to choose a random event follows:\nStart at root of tree, \\(A=\\text{root}\\). If \\(u \u003c r_A\\)\tthen choose \\(A\\). Otherwise, \\(u\\gets u - r_A\\) (so that \\(u \u003c \\Sigma_{C_0} + \\Sigma_{C_1}\\)). If \\(u \u003c \\Sigma_{C_0}\\) then set focal node \\(A=C_0\\) and repeat from Step 1. Otherwise, set \\(u\\gets u - \\Sigma_{C_0}\\) (so that \\(u \u003c \\Sigma_{C_1}\\)), set focal node \\(A=C_1\\), and repeat from Step 1. The full code is given in Listing 2.\n‚Äã\rFigure 6\rFigure 6: To select an event via the binary tree Roulette Wheel algorithm pick a random number \\(u\\) between 0 and \\(\\Sigma_A = r_A + \\Sigma_{C_0} + \\Sigma_{C_1}\\). The area it lands in indicates the course of action (choose \\(A\\) or branches \\(C_0\\) or \\(C_1\\), respectively).\n‚Äã\rListing 2: parallelpoisson.h\rclass TPPNode { // nodes for TParallelPoisson tree. Each node uses ~32 bytes. private: TPPNode *odd; TPPNode *even; public: TPPNode *parent; unsigned long index; // \u003e= 1 double rate; double sum; TPPNode(TPPNode *newparent = NULL, unsigned long path = 0x1) { // constructor parent = newparent; rate = sum = 0; odd = even= NULL; // reverse path to get index for (index = 1; path \u003e 1; path = (path \u003e\u003e 1)) index = (index \u003c\u003c 1) | (path \u0026 0x1); } ~TPPNode() { // destructor if (odd) delete odd; if (even) delete even; } TPPNode *getNode(unsigned long find, bool create, unsigned long path = 0x1) { // returns pointer to node with index==find // creates node(s) if create==true, // else returns NULL if not found if (find == 1) return this; path = path \u003c\u003c 1; // shift bits if (find \u0026 0x1) { path |= 0x1; // append 1 if (!odd) { if (!create) return NULL; odd = new TPPNode(this, path); } return odd-\u003egetNode(find\u003e\u003e1, create, path); } else { if (!even) { if (!create) return NULL; even = new TPPNode(this, path); } return even-\u003egetNode(find\u003e\u003e1, create, path); } } unsigned long choose(double roulette) { if (roulette \u003c rate) return index; roulette -= rate; // now roulette \u003c odd-\u003esum + even-\u003esum double oddsum = 0, evensum = 0; if (odd) oddsum = odd-\u003esum; if (even) evensum= even-\u003esum; if (roulette \u003c oddsum) return odd-\u003echoose(roulette); return even-\u003echoose(roulette - oddsum); } }; class TParallelPoisson { /* Intended usage: // setup TParallelPoisson pp; unsigned long event; double time = 0; for (int i=1; i\u003c=N; i++) pp.setRate(i,rate[i]); // note: must be base 1! // main loop do { event = pp.choose(uniform_deviate()); time += pp.eventTime(uniform_deviate()); do_stuff(event); for (EACH_RATE_CHANGED_BY_EVENT) { pp.setRate(i,rate[i]); } } while (!HELL_FROZEN_OVER); */ private: TPPNode *root; public: TParallelPoisson() { // constructor root = new TPPNode; } ~TParallelPoisson() { // destructor if (root) delete root; root = NULL; } void reset() { if (root) delete root; root = NULL; root = new TPPNode; } double eventTime(double u) { // returns time to first event. Assumes 0 \u003c= u \u003c 1. if (!root) return 0; if (!(root-\u003esum)) return 0; return -log(1.0-u)/(root-\u003esum); } double getRate(unsigned long i) { // gets rate of node i (zero if not found) TPPNode *node=root-\u003egetNode(i,false); // don't create node if (!node) return 0; return node-\u003erate; } double setRate(unsigned long i, double newrate) { // sets rate of node i, returns old rate TPPNode *node=root-\u003egetNode(i,true); // create node if needed double oldrate = node-\u003erate; double dr = newrate - oldrate; node-\u003erate = newrate; for (; node; node = node-\u003eparent) node-\u003esum += dr; return oldrate; } double modRate(unsigned long i, double deltarate) { // adjust rate of node i, returns new rate TPPNode *node=root-\u003egetNode(i,true); // create node if needed double newrate = node-\u003erate + deltarate; node-\u003erate = newrate; for (; node; node = node-\u003eparent) node-\u003esum += deltarate; return newrate; } unsigned long choose(double u) { // chooses which event happens next, assumes 0 \u003c= u \u003c 1 if (!root) return 0; // error value if (!(root-\u003esum)) return 0; // error value return root-\u003echoose(u * root-\u003esum); } };\rListing 2: C++ implementation of binary tree roulette wheel method.\n7. References Blok\r(2004)\rBlok, \rH.(2004, 10/15). Retrieved from \rhttps://www.cs.ubc.ca/~rikblok/research/notes/parallel_poisson/index.html",
    "description": "I explore how to efficiently implement Poisson processes in event-driven, multi-agent simulations.",
    "tags": [],
    "title": "Parallel Poisson (2004)",
    "uri": "/~rikblok/research/notes/parallel_poisson/index.html"
  },
  {
    "breadcrumb": "Computational capers¬†\u003e¬†Orphanware",
    "content": "",
    "description": "Toolbar (alias Rik‚Äôs Toolbar) provides a way to add a customized floating toolbar to any application. When a button is pressed a pre-defined sequence of keystrokes is sent to the desired window.",
    "tags": [],
    "title": "Toolbar (1999 - 2003)",
    "uri": "/~rikblok/compute/orphanware/toolbar/index.html"
  },
  {
    "breadcrumb": "Academic anecdotes¬†\u003e¬†Old courses",
    "content": "",
    "description": "Electricity, Light and Radiation (Summer 2003)\nIntroduction to optics, electricity and magnetism, electric circuits, radioactivity, including biological applications.",
    "tags": [],
    "title": "UBC PHYS 102 (2003)",
    "uri": "/~rikblok/teaching/past/phys102/index.html"
  },
  {
    "breadcrumb": "Research ramblings¬†\u003e¬†Presented",
    "content": "Guest lecture for PHYS 510: Stochastic Processes in Physics, UBC Blok\r(2003)\rBlok, \rH.\r \r(2003).\r \rSelf-affine timeseries analysis.\r Retrieved from \rhttps://www.cs.ubc.ca/~rikblok/research/presented/blok03/index.html\rAbstract A brief introduction to L√©vy flight and fractional Brownian motion from the experimentalist‚Äôs perspective. Simple tools to analyze these timeseries, the Zipf plot and dispersional analysis, are presented. As a demonstration, these tools are applied to financial and meteorological data to determine the L√©vy and Hurst exponents.\nDownload",
    "description": "Guest lecture for PHYS 510: Stochastic Processes in Physics, UBC",
    "tags": [],
    "title": "Self-affine timeseries analysis (2003)",
    "uri": "/~rikblok/research/presented/blok03/index.html"
  },
  {
    "breadcrumb": "Computational capers¬†\u003e¬†Orphanware",
    "content": "",
    "description": "Rik‚Äôs 2D simulation Tool lets you build and run your own cellular automata or other spatial network simulations. R2DToo is designed for scientists, to help with constructing, running, and collecting data from simulations with features such as live time series plots of interesting statistics and automation to let the user run experiments repeatedly without requiring user interaction.",
    "tags": [],
    "title": "R2DToo (2001 - 2003)",
    "uri": "/~rikblok/compute/orphanware/r2dtoo/index.html"
  },
  {
    "breadcrumb": "Research ramblings¬†\u003e¬†Presented",
    "content": "SOWD (Schluter, Otto, Whitton, Whitlock, Doebeli)) Lab Meeting, UBC Blok\r(2002)\rBlok, \rH.\r \r(2002).\r \rRock, paper and scissors in space: A demonstration of R2DToo.\r Retrieved from \rhttps://www.cs.ubc.ca/~rikblok/research/presented/blok02b/index.html\rAbstract Presentation given at the Dec. 2, 2002 SOWD Lab Meeting. A demonstration of how the simulation tool R2DToo can be used to solve real problems.\nDownload",
    "description": "SOWD (Schluter, Otto, Whitton, Whitlock, Doebeli)) Lab Meeting, UBC",
    "tags": [],
    "title": "Rock, paper and scissors in space (2002)",
    "uri": "/~rikblok/research/presented/blok02b/index.html"
  },
  {
    "breadcrumb": "Research ramblings¬†\u003e¬†Presented",
    "content": "PIMS-MITACS Math Finance Seminar, UBC Blok\r(2002)\rBlok, \rH.\r \r(2002).\r \rStatistical properties of financial timeseries.\r Retrieved from \rhttps://www.cs.ubc.ca/~rikblok/research/presented/blok02/index.html\rAbstract A brief introduction to L√©vy flight and fractional Brownian motion from the experimentalist‚Äôs perspective. Simple tools to analyze these timeseries, the Zipf plot and dispersional analysis, are presented. As a demonstration, these tools are applied to intraday foreign exchange data to determine the L√©vy and Hurst exponents.\nDownload",
    "description": "PIMS-MITACS Math Finance Seminar, UBC",
    "tags": [],
    "title": "Statistical properties of financial timeseries (2002)",
    "uri": "/~rikblok/research/presented/blok02/index.html"
  },
  {
    "breadcrumb": "Computational capers¬†\u003e¬†Orphanware",
    "content": "",
    "description": "Ok, you want to let other people run Internet Explorer on your computer but you want to let them have their own favorites, home page, etc. Microsoft‚Äôs solution? Save what you‚Äôre doing‚Ä¶log off current user‚Ä¶wait‚Ä¶log on as other user‚Ä¶wait‚Ä¶run IE‚Ä¶Done! My solution? RunIEAs ‚Ä¶Done!",
    "tags": [],
    "title": "RunIEAs (2001 - 2002)",
    "uri": "/~rikblok/compute/orphanware/runieas/index.html"
  },
  {
    "breadcrumb": "Mathematical musings",
    "content": "My wife and I live in a twenty eight unit condominium which shares the cost of natural gas. Each unit has its own gas fireplace which we find is sufficient to heat our unit all year long, without resorting to electric baseboard heaters. This makes for an interesting problem in game theory: at what price level can we expect the residents to switch from heating with gas to heating with electricity?\nThe problem is only interesting when the cost of heating with gas is on the same order as electric heat. If one source is much cheaper than the other then it is the rational choice. As I write this the cost of gas is roughly (if I did the math right!) 3/4 the cost of electricity (measured in dollars per unit of energy). This neglects some issues such as efficiency of turning the energy into heat, etc. but at least it gives us a ballpark figure. Clearly, the problem is relevant.\nI‚Äôm going to demonstrate two solutions to the problem. The first ignores game theory and gives a trivial, intuitive result. The second, using game theory, gives a more likely‚Äìand drastically worse‚Äìresult.\nSolution 1: Self-consistency First, some definitions:\n$T$ total heating cost over some fixed period (eg. one year), $N$ number of units in condo (eg. $N=28$), $E$ total units of energy used to heat home, $f$ ratio of gas price rate to electricity rate (eg. $f=3/4$), $r_e$ cost per unit energy for electricity, $r_g$ cost per unit energy for gas ($r_g=f r_e$), and $g$ fraction of heat generated by gas, for a single resident (between zero and one). Ok, to state it mathematically, we want to find the fraction $g$ which minimizes the total cost $T$ each resident spends. For this first solution, we assume each resident is going to do the same thing because they all want to minimize $T$.\nSo each resident‚Äôs cost for electric heat is $(1-g) E r_e$ and the total cost of gas for the entire building is $N g E r_g$, which is split uniformly between the $N$ condos. So the total cost to each condo is\n$$ T = (1-g) E r_e + g E r_g = E r_e [1+(f-1)g]. $$So what would each resident choose for $g$ in order to minimize $T$? Simple: if $f\u003c1$ then choose $g=1$ and if $f\u003e1$ then choose $g=0$. This just means the rational way to heat your home is with whichever source is cheaper. That seems obvious doesn‚Äôt it?\nSolution 2: Game theoretic If you agree with the first solution this one might surprise you. Again, we need a few definitions. Instead of everybody applying the same behaviour $g$, lets consider what I should do as a resident versus what everybody else is doing:\n$g_\\text{me}$ the fraction $g$ for me, as a resident, or $g_\\text{other}$ the fraction $g$ averaged over all other residents. Now there are three costs: my electricity, $(1-g_\\text{me}) E r_e$, my gas, $g_\\text{me} E r_g$, and everybody else‚Äôs gas, $(N-1) g_\\text{other} E r_g$. As before, these last two terms are shared by all $N$ residents so my total cost is\n$$ \\begin{array}{rl} T \u0026 = (1-g_\\text{me}) E r_e + [g_\\text{me} E r_g + (N-1) g_\\text{other} E r_g]/N \\\\ \u0026 = E r_e [1+(N-1) g_\\text{other} f / N + (f/N - 1) g_\\text{me}]. \\end{array} $$Notice that I only have control over my own actions, $g_\\text{me}$. I can‚Äôt hope to influence other people‚Äôs behaviour so $g_\\text{other}$ is effectively constant, independent of what I do. So, to minimize T all I can do is try to minimize the very last term $(f/N - 1) g_\\text{me}$. This is achieved with $g_\\text{me}=1$ when $f\u003cN$ and $g_\\text{me}=0$ when $f\u003eN$.\nTragedy of the commons Compare these two solutions: the first says I should use gas only if it is cheaper than electricity, but the second says I should keep using it until it is $N$ times more expensive than electricity! ($N=28$ in my building.)\nIf that‚Äôs the optimal behaviour for me, then the same should hold for every resident in the building. So, when $1\u003cf\u003cN$ we are all going to be paying more for heating than we need to! Strange but true. This dilemma is known as the tragedy of the commons. It happens because nobody can improve their situation by changing their behaviour unless everyone else changes, too.\nFortunately, there are ways to get around this kind of dilemma. What you have to do is change the rules of the game. For example, if the price of gas got too high we could have an emergency strata meeting to vote on the option of shutting off the gas to the entire building. (Other, less totalitarian solutions are probably also available‚Ä¶)\n‚Äî Rik Blok, 2002",
    "description": "My wife and I live in a twenty eight unit condominium which shares the cost of natural gas.  At what price level can we expect the residents to switch from heating with gas to heating with electricity?",
    "tags": [],
    "title": "Shared Gas: A 'Tragedy' of the Commons (2002)",
    "uri": "/~rikblok/math/shared_gas/index.html"
  },
  {
    "breadcrumb": "Scientific scribblings",
    "content": "I often have people ask me what I do for a living. Because my research projects are so varied I like to give a different answer each time. Nevertheless, the question has forced me to evaluate my role as a scientist. This page is an attempt to explain what I believe science is all about and where my work fits in‚Ä¶\nBackground Science is the process of making testable claims (scientists call them theories or hypotheses) about our surroundings and testing them. When a claim fails a test we are forced to re-evaluate either it or the assumptions it relies on. On the other hand, the more tests a claim passes the more it is accepted by the scientific community. (Or at least it should be, but sometimes other factors can affect how quickly a claim is accepted, such as culture, religion or politics.)\nBy natural extension, then, the ultimate scientific achievement would be to propose a claim (theory) which can explain everything! Given that, one might reasonably ask ‚ÄúWhy aren‚Äôt all scientists looking for a Theory of Everything?‚Äù\nOnion In fact, some physicists are trying to find the Theory of Everything. But besides that we have many other scientific fields, such as chemistry, biology, psychology, etc. Why is that? Each field covers only a small domain of knowledge. It tends to begin with some axiomatic principles and explore those to form theories to explain more complicated phenomena. For example some physicists study how sub-atomic particles interact to form atoms. Further simple examples follow:\nField Axioms Theories Physics Sub-atomic particles Atoms Chemistry Atoms Complex molecules (eg. DNA) Microbiology DNA Cells Physiology Cells Individuals Ecology Individuals Populations The important point is that each scientific field has a limited domain of expertise; it can explain only a portion of reality. It is not (currently) possible, for example, to explain why people smile from a knowledge of quarks and gluons alone.\nNotice the relationship between the axioms and theories in the above table. The concepts developed in one field often become the fundamental principles upon which another field rests. I have found it convenient to think of the relationships between scientific fields as separate layers of knowledge surrounding a central core. One layer forms the foundation for another. Hence, the onion model of science.\n‚Äã\rFigure 1\rFigure 1: Science can be categorized into layers where the principles constructed in one layer become the foundation for the layer above.\nEach layer of the onion represents a field of science which is tightly connected, and the lines indicate the limits of the field. Of course, this is an idealization: there are many fields which overlap each other, blurring the separation between layers. (For instance, cell membranes are studied by physicists, chemists and biologists.) However, the onion is meant to emphasize the strong interconnectedness within fields and neglect the (relatively) few links between fields.\nThe reader may ask why is it possible to separate science into layers? Why don‚Äôt the layers just blend together into a cohesive whole? The answer has to do with how science is typically done.\nReductionism If you try to take a cat apart to see how it works, the first thing you have on your hands is a nonworking cat. ‚Äî Douglas Adams, 2002\nThe separation of science into layers is not due to incomplete knowledge in the core but rather due to the historical methodology of science.\nTypically, a system is studied by taking it apart and seeing how its individual components work, a method called reductionism. It‚Äôs a very natural and intuitive approach to learning and it usually works. But sometimes, even when you know all there is to know about all the individual bits, you still can‚Äôt figure out how the system functions as a whole. Consider a mechanical watch: it consists primarily of simple components, such as cogs and springs, and yet few people would be able to explain how it works.\nThe difficulty is that, to understand it, you have to think about how all the bits are working together at the same time. The bits are said to be working in parallel. Nature, of course, is massively parallel so we can‚Äôt expect a reductionist approach to work every time.\nI am not trying to belittle reductionism, it is a very useful technique and has had many astounding successes. Without it no progress in science could have been possible whatsoever. My point is that, as good as reductionism is, it cannot explain everything. Even if a Theory of Everything is discovered which perfectly explains every question that could be asked at the core of the onion, it does not follow that we will know everything that science can ask. There will still be a limit to its explanatory power. A complete understanding of physics will not impact biology, for example. But if the separation of science into distinct layers (or fields) is not due to incomplete understanding then what is it due to?\nComplexity As alluded to with the analogy of the watch, the problem is the sheer numbers of interacting components in one layer make it impossible to compute results in a higher layer of the onion. Thus, a Theory of Everything will not spell the end of science, it will just fill in the rules at the very core of the onion. By itself it will contribute nothing to the understanding of the higher layers.\nTo understand nature as a whole it is necessary to construct new theories and tools to explain large systems of interacting units. This is the science of Complexity. Complexity is a relatively new approach to science which complements reductionism. Reductionism tries to explain how each of the bits work and complexity tries to explain how they all work with each other. Together, these two approaches hold the promise of full and complete understanding of the natural world.\nAs complexity science matures it is hoped that it will give us a way to break the barriers separating the layers of the onion (fields of science). As such complexity science is interdisciplinary, it is not tied to any particular field of study. In fact, it can be found in fields as diverse as condensed matter physics and population ecology.\n‚Äî Rik Blok, 2002",
    "description": "I often have people ask me what I do for a living. Because my research projects are so varied I like to give a different answer each time. Nevertheless, the question has forced me to evaluate my role as a scientist. This page is an attempt to explain what I believe science is all about and where my work fits in‚Ä¶",
    "tags": [],
    "title": "The onion of Science (2002)",
    "uri": "/~rikblok/science/onion_of_science/index.html"
  },
  {
    "breadcrumb": "Research ramblings¬†\u003e¬†Presented",
    "content": "Presentation for Doebeli lab meeting Blok\r(2001)\rBlok, \rH.\r \r(2001).\r \rCan memes drive genes?.\r Retrieved from \rhttps://www.cs.ubc.ca/~rikblok/research/presented/blok01/index.html\rAbstract Assuming culture is transmitted horizontally (via imitation) a model was constructed to determine the conditions under which culture can dominate genetic evolution (‚Äúget off the leash‚Äù according to Blackmore (\rCitation: 2000 Blackmore, \rS. \r(2000).\r \rThe meme machine.\r \rOxford University Press.\r)\r). Two requirements were found: (1) culture must compete with genes (required only for the effect to be empirically testable); and (2) Interactions between individuals must be confined to small groups or neighbourhoods. The model was tested via analysis and simulation.\nIn this talk I will present the model, analysis, and simulation results. Feedback is appreciated.\nDownload",
    "description": "Presentation for Doebeli lab meeting, UBC",
    "tags": [],
    "title": "Can memes drive genes? (2001)",
    "uri": "/~rikblok/research/presented/blok01/index.html"
  },
  {
    "breadcrumb": "Computational capers¬†\u003e¬†Orphanware",
    "content": "",
    "description": "ExportChart Excel Add-In. Save your Excel charts to Gif files for use in web pages or graphic programs. Requires Microsoft Excel 97 or 2000.",
    "tags": [],
    "title": "ExportChart (1999 - 2001)",
    "uri": "/~rikblok/compute/orphanware/exportchart/index.html"
  },
  {
    "breadcrumb": "Computational capers¬†\u003e¬†Orphanware",
    "content": "",
    "description": "View and edit TeX equations before compiling your source. View your equation as you type in (almost) real time. Copies modified text to the clipboard for quick use in your favorite text editor.",
    "tags": [],
    "title": "TeX Equation Previewer (1999 - 2000)",
    "uri": "/~rikblok/compute/orphanware/eqnpreview/index.html"
  },
  {
    "breadcrumb": "Research ramblings¬†\u003e¬†Presented",
    "content": "Final PhD oral defense, UBC Blok\r(2000)\rBlok, \rH.\r \r(2000).\r \rOn the nature of the stock market: Simulations and experiments (Departmental defense).\r Retrieved from \rhttps://www.cs.ubc.ca/~rikblok/research/presented/blok00/index.html\rDownload",
    "description": "Final PhD oral defense, UBC",
    "tags": [],
    "title": "On the nature of the stock market: Simulations and experiments (2000)",
    "uri": "/~rikblok/research/presented/blok00c/index.html"
  },
  {
    "breadcrumb": "Research ramblings¬†\u003e¬†Published",
    "content": "PhD Thesis, UBC Blok\r(2000)\rBlok, \rH.\r \r(2000).\r \rOn the nature of the stock market: Simulations and experiments\r. \rUniversity of British Columbia\r Retrieved from \rhttp://hdl.handle.net/2429/11108\rAbstract Over the last few years there has been a surge of activity within the physics community in the emerging field of Econophysics - the study of economic systems from a physicist‚Äôs perspective. Physicists tend to take a different view than economists and other social scientists, being interested in such topics as phase transitions and fluctuations.\nIn this dissertation two simple models of stock exchange are developed and simulated numerically. The first is characterized by centralized trading with a market maker. Fluctuations are driven by a stochastic component in the agents‚Äô forecasts. As the scale of the fluctuations is varied a critical phase transition is discovered. Unfortunately, this model is unable to generate realistic market dynamics.\nThe second model discards the requirement of centralized trading. In this case the stochastic driving force is Gaussian-distributed ‚Äúnews events‚Äù which are public knowledge. Under variation of the control parameter the model exhibits two phase transitions: both a first- and a second-order (critical).\nThe decentralized model is able to capture many of the interesting properties observed in empirical markets such as fat tails in the distribution of returns, a brief memory in the return series, and long-range correlations in volatility. Significantly, these properties only emerge when the parameters are tuned such that the model spans the critical point. This suggests that real markets may operate at or near a critical point, but is unable to explain why this should be. This remains an interesting open question worth further investigation.\nOne of the main points of the thesis is that these empirical phenomena are not present in the stochastic driving force, but emerge endogenously from interactions between agents. Further, they emerge despite the simplicity of the modeled agents; suggesting complex market dynamics do not arise from the complexity of individual investors but simply from interactions between (even simple) investors.\nAlthough the emphasis of this thesis is on the extent to which multi-agent models can produce complex dynamics, some attempt is also made to relate this work with empirical data. Firstly, the trading strategy applied by the agents in the second model is demonstrated to be adequate, if not optimal, and to have some surprising consequences.\nSecondly, the claim put forth by Sornette et al. (\rCitation: 1996 Sornette, \rD., \rJohansen, \rA. \u0026 Bouchaud, \rJ.\r \r(1996).\r Stock Market Crashes, Precursors and Replicas.\rJournal de Physique I, 6(1). 9.\rhttps://doi.org/10.1051/jp1:1996135\r)\rthat large financial crashes may be heralded by accelerating precursory oscillations is also tested. It is shown that there is weak evidence for the existence of log-periodic precursors but the signal is probably too indistinct to allow for reliable predictions.\nDownload Individual sections\nFront matter Chapter 1: Introduction Chapter 2: Centralized Stock Exchange Model Chapter 3: Decentralized Stock Exchange Model Chapter 4: Analysis and results: Phase space Chapter 5: Analysis and results: Empirical results Chapter 6: Experiments with a hypothetical portfolio Chapter 7: Concluding remarks Bibliography Appendix A: Discounted least-squares curve fitting Appendix B: Sampling discrete processes Appendix C: Long-range memory: The Hurst exponent",
    "description": "PhD Thesis, UBC\nIn this dissertation, two simple models of stock exchange are developed and simulated numerically. The decentralized model captures key empirical market properties, including fat-tailed returns, short-term memory in returns, and long-range volatility correlations. Significantly, these features emerge only when parameters are tuned to span the critical point, suggesting markets may self-organize near criticality‚Ä¶",
    "tags": [],
    "title": "On the nature of the stock market: Simulations and experiments (2000)",
    "uri": "/~rikblok/research/published/blok00b/index.html"
  },
  {
    "breadcrumb": "Academic anecdotes¬†\u003e¬†Old courses",
    "content": "",
    "description": "Elements of Physics (Winter 2000)\nThermometry, thermal properties of matter, heat, oscillations, waves, sound, wave optics; geometrical optics, elementary electricity and magnetism, simple DC and AC circuits.",
    "tags": [],
    "title": "UBC PHYS 153 (2000)",
    "uri": "/~rikblok/teaching/past/phys153/index.html"
  },
  {
    "breadcrumb": "Research ramblings¬†\u003e¬†Published",
    "content": "Synchronous versus asynchronous updating in the ‚Äúgame of Life‚Äù Blok \u0026 Bergersen\r(1999)\rBlok, \rH. \u0026 Bergersen, \rB.\r \r(1999).\r Synchronous versus asynchronous updating in the ‚Äúgame of Life‚Äù.\rPhysical Review E, 59(4). 3876‚Äì3879.\rhttps://doi.org/10.1103/PhysRevE.59.3876\rAbstract The rules for the ‚Äúgame of Life‚Äù are modified to allow for only a random fraction of sites to be updated in each time step. Under variation of this fraction from the parallel updating limit down to the Poisson limit, a critical phase transition is observed that explains why the game of Life appears to obey self-organized criticality. The critical exponents are calculated and the static exponents appear to belong to the directed percolation universality class in 2+1 dimensions. The dynamic exponents, however, are nonuniversal, as seen in other systems with multiple absorbing states.\nDownload",
    "description": "The rules for the ‚Äúgame of Life‚Äù are modified to allow for only a random fraction of sites to be updated in each time step. Under variation of this fraction from the parallel updating limit down to the Poisson limit, a critical phase transition is observed that explains why the game of Life appears to obey self-organized criticality‚Ä¶",
    "tags": [],
    "title": "Synchronous versus asynchronous updating in the \"game of Life\" (1999)",
    "uri": "/~rikblok/research/published/blok99/index.html"
  },
  {
    "breadcrumb": "Research ramblings¬†\u003e¬†Presented",
    "content": "Presentation for PHYS 510, UBC Blok\r(1998)\rBlok, \rH.\r \r(1998).\r \rModelling Intentionality: The Gambler.\r Retrieved from \rhttps://www.cs.ubc.ca/~rikblok/research/presented/blok98/index.html\rDownload",
    "description": "Presentation for PHYS 510, UBC",
    "tags": [],
    "title": "Modelling intentionality: The gambler (1998)",
    "uri": "/~rikblok/research/presented/blok98/index.html"
  },
  {
    "breadcrumb": "Research ramblings¬†\u003e¬†Presented",
    "content": "Presentation for Peter Wall Inst. Adv. Science, Crisis Points Group, UBC Blok\r(1998)\rBlok, \rH.\r \r(1998).\r \rExtra! Extra! Critical Update on Life.\r Retrieved from \rhttps://www.cs.ubc.ca/~rikblok/research/presented/blok98b/index.html\rDownload",
    "description": "Presentation for Peter Wall Inst. Adv. Science, Crisis Points Group, UBC",
    "tags": [],
    "title": "Extra! Extra! Critical update on 'Life' (1998)",
    "uri": "/~rikblok/research/presented/blok98b/index.html"
  },
  {
    "breadcrumb": "Research ramblings¬†\u003e¬†Unpublished notes",
    "content": "Discounted Least Squares Curve Fitting Blok\r(1997)\rBlok, \rH.(1997, 7/20). Retrieved from \rhttps://www.cs.ubc.ca/~rikblok/research/notes/discounted_least_squares/index.html\rVersion 1 ‚Äî Rik Blok, 1997-07-20\n1. Introduction I recently wrote some code to make simple forecasts in a time series (a steadily accumulating set of \\((x,y)\\) data points). For its simplicity, I chose a least-squares fit to a straight line. The underlying behaviour of the system was continuously changing so it was unreasonable to expect the same parameters to be valid for all the data. As new data came in, I expected old data to become irrelevant, and I handled this by only fitting over the last \\(N\\) data points. Unfortunately, it became evident that this arbitrary parameter \\(N\\) I had chosen was very important to the fit, often producing pathological results: as \\(N\\) new data points were accumulated after an outlier (a strongly atypical \\(y\\)-value), it would suddenly be dropped from consideration and the forecast would undergo a discontinuous ‚Äújump‚Äù. I began to wonder if there was a way of steadily discounting the relevance of past data in a smoother and more natural way‚Ä¶\n(Note: much of the text written here is a blatant copy from Press et al. (\rCitation: 1992 Press, \rW., \rTeukolsky, \rS., \rVetterling, \rW. \u0026 Flannery, \rB. \r(1992).\r \rNumerical Recipes in C: The Art of Scientific Computing (Second).\r \rCambridge University Press. Retrieved from \rhttp://www.nr.com/\r)\r. They said it so well, I could not word it any better myself. In Chapter 16 they derive the least-squares technique I described above.)\n2. Solution We use the index \\(i\\) to label our data points where \\(i=0\\) indicates the most recently acquired data and \\(i=1,2,3,\\ldots\\) indicate successively older data. Each data point consists of a triplet \\((x,y,\\sigma)\\) where \\(x\\) is the independent variable (eg. time), \\(y\\) is the dependent variable, and \\(\\sigma\\) is the associated measurement error in \\(y\\).\nAs new data arrives \\((x_0,y_0,\\sigma_0)\\) we shift the indices of prior data to make room, and scale up the errors by some factor \\(\\gamma\\in (0,1)\\):\n\\[ (x_{i+1},y_{i+1},\\sigma_{i+1})\\leftarrow (x_i, y_i,\\sigma_i/\\gamma). \\]If we define \\(\\sigma_i^*\\) as the original value of \\(\\sigma_0\\) then after applying \\(i\\) of the above operations\n\\[ \\sigma_i = \\sigma_i^*/\\gamma^i \\] (2.1) so, since \\(\\gamma\u003c1\\), the historical deviations grow exponentially as new information is acquired.\nWe wish to fit data to a model which is a linear combination of any \\(M\\) specified functions of \\(x\\). For example, the functions could be \\(1,x,x^2,\\ldots,x^{M-1}\\), in which case their general linear combination,\n\\[ y(x) = a_1 + a_2 x + \\cdots + a_M x^{M-1} \\]is a polynomial of degree \\(M-1\\). The general form of this kind of model is\n\\[ y(x) = \\sum_{j=1}^M a_j X_j(x) \\] (2.2) where \\(X_1(x),\\ldots,X_M(x)\\) are arbitrary fixed functions of \\(x\\), called the basis functions. Note that the functions \\(X_j(x)\\) can be wildly nonlinear functions of \\(x\\). In this discussion ‚Äúlinear‚Äù refers only to the model‚Äôs dependence on its parameters \\(a_j\\).\nFor these linear models we define a merit function\n\\[ \\chi^2 = \\sum_{i=0}^N \\left[ \\frac{y_i - \\sum_j a_j X_j(x_i)}{\\sigma_i} \\right]^2. \\] (2.3) We will pick as best parameters those that minimize \\(\\chi^2\\). There are several different techniques for finding this minimum. We will focus on one: the singular value decomposition of the normal equations. To introduce it we need some notation.\nLet \\({\\bf A}\\) be a matrix whose \\(N\\times M\\) components are constructed from the \\(M\\) basis functions evaluated at the \\(N\\) abscissas \\(x_i\\), and from the \\(N\\) measurement errors \\(\\sigma_i\\), by the prescription\n\\[ A_{ij} = \\frac{X_j(x_i)}{\\sigma_i}. \\] (2.4) The matrix \\({\\bf A}\\) is called the design matrix of the fitting problem. Notice that in general \\(\\bf A\\) has more rows than columns, \\(N\\geq M\\), since there must be more data points than model parameters to be solved for.\nAlso define a vector \\(\\bf b\\) of length \\(N\\) by\n\\[ b_i = \\frac{y_i}{\\sigma_i} \\]and denote the \\(M\\) vector whose components are the parameters to be fitted, \\(a_1,\\ldots,a_M\\), by \\(\\bf a\\).\nIf we take the derivative of Eq. (2.3) with respect to all \\(M\\) parameters \\(a_j\\), we obtain \\(M\\) equations that must hold at the chi-square minimum,\n\\[ 0 = \\frac{1}{\\sigma_i^2} \\left[ y_i - \\sum_j a_j X_j(x_i) \\right] X_k(x_i)\\;\\; k=1,\\ldots,M. \\] (2.5) Interchanging the order of summations, we can write Eq. (2.5) as the matrix equation\n\\[ \\sum_j \\alpha_{kj} a_j = \\beta_k \\] (2.6) where\n\\[ \\alpha_{kj} = \\sum_i \\frac{X_j(x_i) X_k(x_i)}{\\sigma_i^2} \\text{ or equivalently } [\\alpha] = {\\bf A}^T\\cdot {\\bf A} \\] (2.7) an \\(M\\times M\\) matrix, and\n\\[ \\beta_k = \\sum_i \\frac{y_i X_k(x_i)}{\\sigma_i^2} \\text{ or equivalently } [\\beta] = {\\bf A}^T\\cdot {\\bf b} \\] (2.8) a vector of length \\(M\\).\nEq. (2.5) or (2.6) are called the normal equations of the least-squares problem. They can be solved for the vector parameters \\(\\bf a\\) by singular value decomposition (SVD). SVD solves fixes many difficulties in the normal equations, including susceptibility to round-off errors. SVD can be significantly slower than other methods; however, its great advantage, that it (theoretically) cannot fail, more than makes up for the speed disadvantage. A good review of SVD techniques can be found in Press et al. (\rCitation: 1992 Press, \rW., \rTeukolsky, \rS., \rVetterling, \rW. \u0026 Flannery, \rB. \r(1992).\r \rNumerical Recipes in C: The Art of Scientific Computing (Second).\r \rCambridge University Press. Retrieved from \rhttp://www.nr.com/\r)\rSection 2.6. In matrix form, the normal equations can be written as\n\\[ [\\alpha]\\cdot {\\bf a}=[\\beta]. \\] (2.9) 3. Covariance matrix Let us define\n\\[ [C] = [\\alpha]^{-1}. \\] (3.1) Then\n\\[ {\\bf a}=[C]\\cdot [\\beta] \\text{ or } a_j = \\sum_k C_{jk} \\beta_k \\]which allows us to determine \\(\\bf a\\)‚Äôs dependence on the \\(y_i\\) values. From Eq. (2.7) we see that \\([C]\\) is independent of \\(y_i\\) so\n\\[ a_j = \\sum_j C_{jk} \\sum_i A_{ik} \\frac{y_i}{\\sigma_i} \\] (3.2) and\n\\[ \\frac{\\partial a_j}{\\partial y_i} = \\sum_k C_{jk} \\frac{A_{ik}}{\\sigma_i}. \\]The covariance between two parameters \\(a_j\\) and \\(a_k\\) is defined as\n\\[ \\begin{array}{rcl} \\text{Covar}[a_j,a_k] \u0026 \\equiv \u0026 \\sum_i \\sigma_i^2 \\frac{\\partial a_j}{\\partial y_i} \\frac{\\partial a_k}{\\partial y_i} \\\\ \u0026 = \u0026 \\sum_i \\sigma_i^2 \\sum_{lm} C_{jl} \\frac{A_{il}}{\\sigma_i} \\frac{A_{im}}{\\sigma_i} \\\\ \u0026 = \u0026 \\sum_{lm} C_{jl} C_{km} \\alpha_{ml} \\end{array} \\] (3.3) but since \\([C]=[\\alpha]^{-1}\\) so\n\\[ \\sum_m C_{km} \\alpha_{ml} = \\delta_{kl} \\text{ or } [C][\\alpha]={\\bf 1} \\]where \\(\\delta_{kl}\\) is the Kronecker delta function. Hence Eq. (3.3) reduces to\n\\[ \\text{Covar}[a_j,a_k] = C_{jk} \\] (3.4) and we find that \\([C]\\) is the covariance matrix. The variance of a single parameter \\(a_j\\) is simply defined as\n\\[ \\text{Var}[a_j]=\\text{Covar}[a_j,a_j]=C_{jj}. \\] (3.5) 4. Storage and updating So far we have made no mention of \\(N\\), the number of data points to be fit. As we will see an advantage of the discounted least squares method is that \\(N\\) becomes irrelevant. As data points are accumulated the oldest data becomes decreasingly relevant and eventually contribute negligibly to the fitting procedure. Hence we can theoretically apply this data to an infinite data set. But can this be practically implemented? The answer is‚Ä¶Yes!\nNotice that as we acquire new data \\((x_0,y_0,\\sigma_0)\\) according to Eq. (2.7) and (2.8) the matrix \\([\\alpha]\\) and vector \\([\\beta]\\) update as\n\\[ \\alpha_{kj} \\leftarrow A_{0j} A_{0k} + \\gamma^2 \\alpha_{kj} = \\frac{X_j(x_0) X_k(x_0)}{\\sigma_0^2} + \\gamma^2 \\alpha_{kj} \\] (4.1) and\n\\[ \\beta_j \\leftarrow A_{0j} b_0 + \\gamma^2 \\beta_j = \\frac{X_j(x_0) y_0}{\\sigma_0^2} + \\gamma^2 \\beta_j \\] (4.2) so it becomes clear that we need not even store the history of data points, but should rather store just \\([\\alpha]\\) and \\([\\beta]\\) and update them as new data is accumulated.\nA useful measure we have neglected to calculate so far is \\(\\chi^2\\),the chi-square statistic itself. In matrix notation Eq. (2.3) can be written\n\\[ \\begin{array}{rcl} \\chi^2 \u0026 = \u0026 ({\\bf a}^T \\cdot {\\bf A}^T - {\\bf b}^T) \\cdot ({\\bf A} \\cdot {\\bf a}-{\\bf b}) \\\\ \u0026 = \u0026 {\\bf a}^T \\cdot {\\bf A}^T \\cdot {\\bf A} \\cdot {\\bf a} - {\\bf b}^T \\cdot {\\bf A} \\cdot {\\bf a} - {\\bf a}^T \\cdot {\\bf A}^T \\cdot {\\bf b} + {\\bf b}^T \\cdot {\\bf b} \\\\ \u0026 = \u0026 {\\bf a}^T \\cdot ([\\alpha] \\cdot {\\bf a} - [\\beta]) - [\\beta]^T \\cdot {\\bf a} + {\\bf b}^T \\cdot {\\bf b} \\\\ \u0026 = \u0026 {\\bf b}^T \\cdot {\\bf b} - [\\beta]^T \\cdot {\\bf a} \\end{array} \\]which appears to still depend on the data history in the first term. Let us define this term as a new variable \\(\\delta\\),\n\\[ \\delta \\equiv {\\bf b}^T \\cdot {\\bf b} = \\sum_i b_i^2. \\]Then, similarly to Eq. (4.1) and (4.2) \\(\\delta\\) can be updated as more information is accumulated\n\\[ \\delta \\leftarrow b_0^2 + \\gamma^2 \\delta = \\frac{y_0^2}{\\sigma_0^2} + \\gamma^2 \\delta. \\] (4.3) ‚Äã\rFigure 4.1\rFigure 4.1: Discounted least-squares fitting has a computational storage advantage over traditional least-squares when \\(N\u003eM^2+M+4\\) where \\(N\\) is the number of data points and \\(M\\) is the number of parameters to be fitted.\nSo, to store all relevant history information we need only remember \\([\\alpha]\\), \\([\\beta]\\), and \\(\\delta\\) as well as the latest data triplet \\((x_0,y_0,\\sigma_0)\\) for a total of \\(M^2+M+4\\) numbers, regardless of how many data points have been acquired. Figure 4.1 shows that for many practical problems discounted least-squares fitting requires less storage than other methods. Although it has not been tested, we expect a similar condition to hold for processing time because the number of calculations depend only on \\(M\\) instead of \\(M\\) and \\(N\\) as in traditional least-squares methods.\nAs the reader can justify, all of these values should be initialized (prior to any data) with null values: \\([\\alpha]={\\bf 0}\\), \\([\\beta]={\\bf 0}\\), and \\(\\delta=0\\).\n5. Memory, effective number of data points For traditional least-squares fitting it is well known that if the measurement errors of \\(y_i\\) are distributed normally then the method is a maximum likelihood estimation and the expectation value (average) of Eq. (2.3) evaluates to\n\\[ \\left\\langle \\chi^2 \\right\\rangle = N-M. \\]This arises because \\((y_i - y(x_i))/\\sigma_i\\) is distributed normally with mean 0 and variance 1, so the sum of \\(N\\) variances should equate to \\(N\\). The subtraction of \\(M\\) is necessary because \\(M\\) parameters can be adjusted to actually reduce the variances further. For instance, with \\(N=M=1\\) we can adjust the single parameter such that the curve passes precisely through the point \\((x_0,y_0)\\), with zero variance. Similarly, for our method\n\\[ \\begin{array}{rcl} \\left\\langle \\chi^2 \\right\\rangle \u0026 = \u0026 \\sum_{i=0}^\\infty \\gamma^{2 i} \\left\\langle \\left[ \\frac{y_i-y(x_i)}{\\sigma_i^*}\\right]^2 \\right\\rangle - M \\\\ \u0026 = \u0026 \\sum_{i=0}^\\infty \\gamma^{2 i} - M \\\\ \u0026 = \u0026 \\frac{1}{1-\\gamma^2} - M \\end{array} \\] (5.1) which strongly suggests an effective number of data points\n\\[ N_{eff} \\equiv \\frac{1}{1-\\gamma^2}. \\] (5.2) 5.1. Memory We now undertake a thought experiment to understand how \\(N_{eff}\\) comes into play. Consider a single parameter fit \\(X(x_i)=1\\) or \\(y(x_i)=a\\) to a long history of values \\(y_i=1\\) (regardless of \\(x_i\\)). Updating according to Eq. (4.1), (4.2), and (4.3) gives\n\\[ \\begin{array}{rcr} \\alpha \u0026 \\leftarrow \u0026 1 + \\gamma^2 \\alpha \\\\ \\beta \u0026 \\leftarrow \u0026 y + \\gamma^2 \\beta \\\\ \\delta \u0026 \\leftarrow \u0026 y^2 + \\gamma^2 \\delta \\end{array} \\]so after a long history of \\(y=1\\),\n\\[ \\begin{array}{rl} \\alpha \u0026 = 1 + \\gamma^2 \\left( 1 + \\gamma^2(\\cdots)\\right) = 1 + \\gamma^2 + \\gamma^4 + \\cdots \\\\ \u0026 = \\frac{1}{1-\\gamma^2} = \\beta = \\delta \\end{array} \\]which has a solution, in one dimension, of\n\\[ a = \\frac{\\beta}{\\alpha} \\]or \\(y(x)=a=1\\).\nNow consider a sudden shift in the data stream to \\(y_i=0\\) (like a step function). How will this change our curve fit? The value of \\(\\alpha\\) remains unchanged but \\(\\beta\\) and \\(a\\) change as follows:\n\\(y\\) \\(\\beta\\) \\(a\\) \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) \\(1\\) \\(\\alpha\\) \\(1\\) \\(0\\) \\(\\gamma^2 \\alpha\\) \\(\\gamma^2\\) \\(0\\) \\(\\gamma^4 \\alpha\\) \\(\\gamma^4\\) \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) Notice that \\(a\\) decays exponentially to the new equilibrium \\(a=0\\). The time constant \\(\\tau\\) for the system (time for \\(a\\) to decay to \\(1/e\\)) is\n\\[ \\begin{array}{l} \\left( \\gamma^2 \\right)^\\tau = e^{-1} \\\\ \\Rightarrow \\tau = \\frac{-1}{2 \\ln \\gamma} \\end{array} \\]which is, as Figure 5.1 shows, almost identical to \\(N_{eff}\\) for all \\(\\gamma\\).\n‚Äã\rFigure 5.1\rFigure 5.1: The difference between \\(N_{eff}\\) and \\(\\tau\\) is strictly less than one. The main difference between the two is that \\(\\sigma_{N_{eff}} \\rightarrow \\infty \\) as \\(N_{eff}\\rightarrow 1\\) (as it should) while \\(\\sigma_\\tau = \\sqrt{e} \\sigma_\\tau^*\\) for all \\(\\tau\\). They converge as \\(N_{eff}\\rightarrow \\infty\\).\nThus, \\(N_{eff}\\) is indeed a practical measure of the effective number of data points in a fit. The fit is dominated by the most recent data \\(i\\leq N_{eff}\\), and \\(N_{eff}\\) acts as the memory of the fitting procedure.\n6. Unknown measurement errors On occasion measurement uncertainties are unknown and least-squares fitting can be used to recover an estimate of these uncertainties. Be forewarned that this technique assumes normally distributed y data with identical variances. If this is not the case, the results become meaningless. It also precludes the use of a ‚Äúgoodness-of-fit‚Äù estimator (such as the incomplete gamma function, see Press et al. (\rCitation: 1992 Press, \rW., \rTeukolsky, \rS., \rVetterling, \rW. \u0026 Flannery, \rB. \r(1992).\r \rNumerical Recipes in C: The Art of Scientific Computing (Second).\r \rCambridge University Press. Retrieved from \rhttp://www.nr.com/\r)\rSection 6.2) because it assumes a good fit.\nWe begin by assuming \\(\\sigma_i^*=1\\) for all data points and proceeding with our calculations of \\(\\bf a\\) and \\(\\chi^2\\). If all (unknown) variances are equal \\(\\sigma^*=\\sigma_i^*\\) then Eq. (5.1) actually becomes\n\\[ \\left\\langle \\chi^2 \\right\\rangle = (N_{eff} - M) \\sigma^{*2} \\]so the actual data variance should be\n\\[ \\sigma^{*2} = \\frac{\\chi^2}{N_{eff}-M}. \\] (6.1) We can update our parameter error estimates by recognizing that, from Eq. (3.2) and Eq. (2.4), the covariance matrix is proportional to the variance in the data, so\n\\[ C_{jk} \\leftarrow \\frac{\\chi^2}{N_{eff}-M} C_{jk}. \\] (6.2) 7. Forecasting Forecasting via curve fitting is a dangerous proposition because it requires extrapolating into a region beyond the scope of the data, where different rules may apply, and hence, different parameter values. Nevertheless, it often used simply for its convenience. We assume the latest parameter estimations apply at the forecasted point \\(x\\) and simply use Eq. (2.2) to predict \\(y(x)\\).\nThe uncertainty in the prediction can be estimated from the covariance matrix. The definition of variance for any distribution is the expectation value of the squared difference from the mean:\n\\[ \\text{Var}[z] \\equiv \\left\\langle \\left( z - \\langle z \\rangle \\right)^2 \\right\\rangle \\]and the covariance between two variables is defined as\n\\[ \\text{Covar}[z_1,z_2] \\equiv \\left\\langle \\left( z_1 - \\langle z_1 \\rangle \\right) \\left( z_2 - \\langle z_2 \\rangle \\right) \\right\\rangle \\]so Eq. (2.2) has a variance\n\\[ \\begin{array}{rcl} \\text{Var}[y(x)] \u0026 = \u0026 \\text{Var}\\left[ \\sum_j a_j X_j(x) \\right] \\\\ \u0026 = \u0026 \\left\\langle \\left( \\sum_j a_j X_j(x) - \\sum_j \\langle a_j \\rangle X_j(x) \\right) ^2 \\right\\rangle \\\\ \u0026 = \u0026 \\sum_{jk} X_j(x) \\left\\langle \\left( a_j - \\langle a_j \\rangle \\right) \\left( a_k - \\langle a_k \\rangle \\right) \\right\\rangle X_k(x) \\\\ \u0026 = \u0026 \\sum_{jk} X_j(x) \\text{Covar}[a_j,a_k] X_k(x) \\\\ \u0026 = \u0026 X_j(x) C_{jk} X_k(x) \\end{array} \\]where \\([C]\\) is the covariance matrix discussed in Section 3 with possible updating, in the absence of measurement errors, according to Eq. (6.2).\nThe above gives the uncertainty in \\(y(x)\\), but in our derivation we have assumed the observed \\(y\\)-values were distributed normally around the curve where \\(y(x)\\) represents the mean of the distribution. Similarly for our prediction, \\(y(x)\\) is the prediction of the mean with its own uncertainty‚Äî-on top of which there is the measurement uncertainty of data around the mean. If the expected measurement uncertainty is given by \\(\\sigma'\\) then the predicted observation \\(y' \\sim N(y(x),\\sigma')\\) or, with the substitution\n\\[ z' = y' - y(x) \\]we assume \\(z' \\sim N(0,\\sigma')\\) regardless of the prediction \\(y(x)\\). In other words, \\(z'\\) and \\(y(x)\\) are mutually independent.\n\\[ \\begin{array}{rcl} \\text{Var}[y'] \u0026 = \u0026 \\text{Var}[y(x) + z'] \\\\ \u0026 = \u0026 \\left\\langle \\left( y(x) - \\langle y(x) \\rangle + z' - \\langle z' \\rangle \\right)^2 \\right\\rangle \\\\ \u0026 = \u0026 \\left\\langle \\left( y(x) - \\langle y(x) \\rangle \\right)^2 + \\left( z' - \\langle z' \\rangle \\right)^2 + 2 \\left( y(x) - \\langle y(x) \\rangle \\right) \\left( z' - \\langle z' \\rangle \\right) \\right\\rangle \\\\ \u0026 = \u0026 \\left\\langle \\left( y(x) - \\langle y(x) \\rangle \\right)^2 \\right\\rangle + \\left\\langle \\left( z' - \\langle z' \\rangle \\right)^2 \\right\\rangle + 2 \\left\\langle \\left( y(x) - \\langle y(x) \\rangle \\right) \\left( z' - \\langle z' \\rangle \\right) \\right\\rangle \\\\ \u0026 = \u0026 \\text{Var}[y(x)] + \\text{Var}[z']. \\end{array} \\]The last step of dropping the covariance term is allowed because when two distributions are independent\n\\[ \\left\\langle \\left( z_1 - \\langle z_1 \\rangle \\right) \\left( z_2 - \\langle z_2 \\rangle \\right) \\right\\rangle = \\left\\langle z_1 - \\langle z_1 \\rangle \\right\\rangle \\left\\langle z_2 - \\langle z_2 \\rangle \\right\\rangle = 0 \\]so our final results for the forecast \\(y'\\) at \\(x\\) are\n\\[ \\begin{array}{rcl} \\langle y' \\rangle \u0026 = \u0026 y(x) = \\sum_j a_j X_j(x) \\\\ \\text{Var}[y'] \u0026 = \u0026 \\sum_{jk} X_j(x) C_{jk} X_k(x) + \\sigma'^2. \\end{array} \\] (7.1) If \\(\\sigma'\\) is unknown it should be set to the same scale as historical measurement errors. If they are unknown, \\(\\sigma'\\) should be estimated from Eq. (6.1).\n8. Implementation A sample implementation of the above method, using a polynomial fitting function is included in the DOS program dpolyfit.exe((Download {{:random_research:rik_s_notes:discounted_least_squares:dls.zip|dls.zip}} source code and executable, released to the public domain)). It is designed to make continuously updated parameter fits from data in the input stream, and output these parameters, or forecasts derived therefrom, to the output stream. It takes as a command-line parameter an initialization file containing preset parameters for the input format, fitting procedure, and output display. Common usages of this program are:\n‚Äã\rListing 8.1\rdpolyfit.exe inifile.ini \u003cin.dat \u003eout.dat dpolyfit.exe inifile.ini \u003cin.dat \u003e\u003eout.dat\rListing 8.1: Sample command-line parameters for program, where inifile.ini, in.dat, and out.dat are replaced with desired configuration, input and output files, respectively. The second version appends output to out.dat rather than overwriting it.\nThe behaviour of the program is controlled by the initialization file which contains the following options:\n‚Äã\rListing 8.2\r[Input] Errors=No\t; input s values? [Fit] Memory=14\t; effective # data points, Neff in Eq. 5.2 Parameters=7\t; # of parameters a to fit, M in Eq. 2.2 [Output] Input=Yes\t; print input (x,y,s) triplet to output? Parameters=No\t; print parameters a and errors to output? Forecast=Yes\t; print forecasted y to output? Forecast Distance=0\t; forecast y at x=x0+\"Forecast Distance\" [Abort]\t; end program when all of the following are true: x=0 y=0 sig=0\t; only compare s if \"[Input] Errors=Yes\"\rListing 8.2: Sample initialization file inifile.ini.\nIf ‚Äú[Input] Errors=Yes‚Äù then the program expects three numbers per data point \\((x_0,y_0,\\sigma_0)\\), each separated by white spaces (eg. ‚Äú1.0 1.2 0.4‚Äù). Otherwise, only two are expected \\((x_0,y_0)\\).\nThe option ‚Äú[Fit] Memory=...‚Äù contains \\(N_{eff}\\) as in Eq. (5.2). Generally, this must be strictly \\(\u003e0\\), but if a negative number is entered it is interpreted as \\(N_{eff}=\\infty\\), producing a traditional fit over all data points with no rescaling of the measurement errors.\nIf ‚Äú[Output] Input=Yes‚Äù then the input values \\((x_0,y_0,\\sigma_0)\\) are reproduced as the first three columns of the output file. Even if \\(\\sigma_0\\) is unspecified, a best estimate is output, based on Eq. (6.1).\nIf ‚Äú[Output] Parameters=Yes‚Äù then the next \\(2 M\\) columns of output are the parameters \\(\\bf a\\) and their respective uncertainties, eg. ‚Äú\\(a_1 \\delta a_1 \\ldots a_M \\delta a_M\\)‚Äù.\nIf ‚Äú[Output] Forecast=Yes‚Äù then the program generates another two columns of output. It calculates the forecast of \\(y\\) at \\(x=x_0+\\)\"[Output] Forecast Distance\" from Eq. (7.1) and prints out the forecasted \\(y\\) and its uncertainty.\nThe program ends when the input \\((x_0,y_0,\\sigma_0)\\) or \\((x_0,y_0)\\) matches the values in ‚Äú[Abort] x=... y=... sig=...‚Äù or ‚Äú[Abort] x=... y=...‚Äù, respectively.\nThe design of this program might cause some confusion: even though the input data file is a complete set of data, the program only analyzes each data point successively, and all output is based on just this point and prior data. For example, forecasts are based only on past data, so by the end of the output file, all data points are considered but in the beginning results are based only on a single data point. The technique derived herein is better suited to time series with slowly accumulating data, rather than a complete data set on startup.\n9. Summary As in traditional least-squares methods, by differentiating the \\(\\chi^2\\) merit function (Eq. (2.3)) of a linear model (Eq. (2.2)) we were able find a set of linear equations (Eq. (2.9)) which allowed us to solve for the optimal parameters which minimize \\(\\chi^2\\). By scaling up the error tolerance of old data as new data is acquired (Eq. (2.1)) we were able to compact the information such that only an \\(M \\times M\\) matrix \\([\\alpha]\\) (Eq. (4.1)), an \\(M\\times 1\\) vector \\([\\beta]\\) (Eq. (4.2)), and a scalar \\(\\delta\\) (Eq. (4.3)) need be stored to retain the full history of accumulated data. We found that the inverse of \\([\\alpha]\\) (Eq. (3.1)) held the covariance matrix of the fitted parameters (Eq. (3.4) and (3.5)). We were able to compute a memory for this technique (Eq. (5.2)) which is comparable to the number of data points used in traditional least-squares fitting. By assuming a good fit we were able to estimate the measurement uncertainties if they were unknown, and apply this to reconstruct reasonable deviations in the fitted parameters (Eq. (6.2)). Finally, by extrapolating with the latest parameter estimates (assuming they were valid in the forecasted domain), we were able to make forecasts and estimate their uncertainties (Eq. (7.1)).\nAs my list of references will attest, I have done virtually no research to see whether the discounted least-squares method has already been discovered (as is undoubtedly the case) and what name it goes by. In deriving this, I did not care if I ‚Äúreinvented the wheel‚Äù because my goal was to introduce myself to some of the statistical techniques, particularly those used in the derivation of uncertainties.\n10. References Blok\r(1997)\rBlok, \rH.(1997, 7/20). Retrieved from \rhttps://www.cs.ubc.ca/~rikblok/research/notes/discounted_least_squares/index.html\rPress, \rTeukolsky, \rVetterling \u0026 Flannery\r(1992)\rPress, \rW., \rTeukolsky, \rS., \rVetterling, \rW. \u0026 Flannery, \rB. \r(1992).\r \rNumerical Recipes in C: The Art of Scientific Computing (Second).\r \rCambridge University Press. Retrieved from \rhttp://www.nr.com/",
    "description": "I recently wrote some code to make simple forecasts in a time series. I began to wonder if there was a way of steadily discounting the relevance of past data in a smoother and more natural way‚Ä¶",
    "tags": [],
    "title": "Discounted Least Squares (1997)",
    "uri": "/~rikblok/research/notes/discounted_least_squares/index.html"
  },
  {
    "breadcrumb": "Research ramblings¬†\u003e¬†Published",
    "content": "Blok \u0026 Bergersen\r(1997)\rBlok, \rH. \u0026 Bergersen, \rB.\r \r(1997).\r Effect of boundary conditions on scaling in the ‚Äúgame of Life‚Äù.\rPhysical Review E, 55(5). 6249‚Äì6252.\rhttps://doi.org/10.1103/PhysRevE.55.6249\rAbstract The debate as to whether the ‚Äúgame of Life‚Äù is self-organized critical remains unresolved. We present evidence that boundary conditions play an important role in the scaling behaviour, resulting in apparently contradictory results. We develop an analytic form for the scaling function and demonstrate that periodic boundaries force saturation, while open boundaries exhibit no such transitions on similar scales. We also consider the removal of boundaries altogether.\nDownload",
    "description": "The debate as to whether the ‚Äúgame of Life‚Äù is self-organized critical remains unresolved. We present evidence that boundary conditions play an important role in the scaling behaviour, resulting in apparently contradictory results‚Ä¶",
    "tags": [],
    "title": "Effect of boundary conditions on scaling in the \"game of Life\" (1997)",
    "uri": "/~rikblok/research/published/blok97/index.html"
  },
  {
    "breadcrumb": "Mathematical musings",
    "content": "Pythagorean theorem\rIn a right triangle the square of the hypotenuse is equal to the sum of the squares of the sides containing the right angle.\nI‚Äôve been puzzling over a proof for this for years, and it finally dawned on me. (Eureka!) It‚Äôs all in how you draw it‚Ä¶\nProof #1 Given the triangle formed by $a$, $b$ (choosing $b\\geq a$) and $c$, we can construct a square with total area $c^2$. As shown, we can fit four triangles, each with area $a b/2$, into the large square, leaving an inner square with area $(b-a)^2$. Thus, the total area of the large square is\n$$ \\begin{array}{rl} c^2 \u0026 = 4 (a b/2) + (b-a)^2 \\\\ \u0026 = 2 a b + a^2 + b^2 - 2 a b \\\\ \u0026 = a^2 + b^2 . \\end{array} $$Hence, the Pythagorean theorem.\nProof #2 I found another proof, which Jim Loy told me is due to Legendre. It relies on recognizing that you can subdivide a triangle forming two sub-triangles similar to each other and the original. (I won‚Äôt prove this.) Then, from the figure above, and from the properties of similar triangles\n$$ \\frac{a}{e} = \\frac{c}{a} \\text{ thus } a^2 = c e $$and\n$$ \\frac{b}{f} = \\frac{c}{b} \\text{ thus } b^2 = c f. $$Adding the two results together gives\n$$ \\begin{array}{rl} a^2 + b^2 \u0026 = c e + c f \\\\ \u0026 = c (e+f) \\\\ \u0026 = c^2 . \\end{array} $$Hence, the Pythagorean theorem.\n‚Äî Rik Blok, 1997",
    "description": "I‚Äôve been puzzling over a proof for this for years, and it finally dawned on me. (Eureka!) It‚Äôs all in how you draw it‚Ä¶",
    "tags": [],
    "title": "Proof of the Pythagoran theorem (1997)",
    "uri": "/~rikblok/math/pythagoras/index.html"
  },
  {
    "breadcrumb": "Research ramblings",
    "content": "My peer-reviewed and published articles.\nMultimodal pattern formation in phenotype distributions of sexual populations (2007)During bouts of evolutionary diversification the emerging species cluster around different locations in phenotype space. How such multimodal patterns in phenotype space can emerge from a single ancestral species is a fundamental question in biology. Here, we demonstrate that phenotype distributions can split into multiple modes under the force of frequency-dependent competition‚Ä¶\nA tale of two cycles - distinguishing quasi-cycles and limit cycles in finite predator-prey populations (2007)Periodic predator-prey dynamics in constant environments are usually taken as indicative of deterministic limit cycles. It is known, however, that demographic stochasticity in finite populations can also give rise to regular population cycles. Here we show how to distinguish between quasi-cycles and noisy limit cycles based on observing changing population sizes in predator-prey populations. We demonstrate that by using our methods even short and imperfect time series allow quasi-cycles and limit cycles to be distinguished reliably‚Ä¶\nScale-free extinction dynamics in spatially structured host‚Äìparasitoid systems (2006)Much of the work on extinction events has focused on external perturbations of ecosystems, such as climatic change, or anthropogenic factors. Extinction, however, can also be driven by endogenous factors, such as the ecological interactions between species in an ecosystem. Here we show that endogenously driven extinction events can have a scale-free distribution in simple spatially structured host-parasitoid systems. Based on these results, we conjecture that scale-free extinction processes and critical phase transitions of the type we have found may be a characteristic feature of many spatially structured, multi-species ecosystems in nature‚Ä¶\nOn the nature of the stock market: Simulations and experiments (2000)PhD Thesis, UBC\nIn this dissertation, two simple models of stock exchange are developed and simulated numerically. The decentralized model captures key empirical market properties, including fat-tailed returns, short-term memory in returns, and long-range volatility correlations. Significantly, these features emerge only when parameters are tuned to span the critical point, suggesting markets may self-organize near criticality‚Ä¶\nSynchronous versus asynchronous updating in the \"game of Life\" (1999)The rules for the ‚Äúgame of Life‚Äù are modified to allow for only a random fraction of sites to be updated in each time step. Under variation of this fraction from the parallel updating limit down to the Poisson limit, a critical phase transition is observed that explains why the game of Life appears to obey self-organized criticality‚Ä¶\nEffect of boundary conditions on scaling in the \"game of Life\" (1997)The debate as to whether the ‚Äúgame of Life‚Äù is self-organized critical remains unresolved. We present evidence that boundary conditions play an important role in the scaling behaviour, resulting in apparently contradictory results‚Ä¶",
    "description": "My peer-reviewed and published articles",
    "tags": [],
    "title": "Published",
    "uri": "/~rikblok/research/published/index.html"
  },
  {
    "breadcrumb": "",
    "content": "Contact me below if you‚Äôd like to talk to me outside of class. Also, here‚Äôs some course material for current and past courses I have been involved in.\nContact RikWant to book an appointment or reach me? Check out my office hours and contact information here.\nWorkloadView my historical workload, automatically generated from the emails waiting in my inbox.\nRecent coursesHere are some recent courses I‚Äôve taught.\nUBC CPSC 110Computation, Programs, and Programming\nFundamental program and computation structures. Introductory programming skills. Computation as a tool for information processing, simulation and modelling, and interacting with the world.\nUBC CPSC 107Systematic Program Design\nFundamental computation and program structures. Continuing systematic program design from CPSC 103.\nUBC ISCI 320Research Development Project\nRetreat to develop skills in writing scientific research proposals. Emphasis on formulating and testing hypotheses to explain observations.\nOld coursesHere are some courses I‚Äôve taught in the past.\nUBC ISCI 344 (2016)Game Theory in Economics and Evolution (Fall 2016))\nExploration of human and animal interactions: integrating evolutionary and economic perspectives to investigate individual and social behaviour.\nUBC ISCI 422 (2009)Models in Science (Fall 2009)\nMeaning, nature, use, strengths and limitations of models as investigative tools in all scientific disciplines. Detailed investigation of selected model systems from different scientific disciplines.\nUBC PHYS 102 (2003)Electricity, Light and Radiation (Summer 2003)\nIntroduction to optics, electricity and magnetism, electric circuits, radioactivity, including biological applications.\nUBC PHYS 153 (2000)Elements of Physics (Winter 2000)\nThermometry, thermal properties of matter, heat, oscillations, waves, sound, wave optics; geometrical optics, elementary electricity and magnetism, simple DC and AC circuits.",
    "description": "My contact information and material from some of my courses.  Look here if you want to book an appointment.",
    "tags": [],
    "title": "Academic anecdotes",
    "uri": "/~rikblok/teaching/index.html"
  },
  {
    "breadcrumb": "Academic anecdotes",
    "content": "Want to book an appointment or reach me? Check out my office hours and contact information here.\nOffice hours Choose an available time slot to book an online Zoom appointment:\nE-mail rik.blok@ubc.ca Go ahead, fire off an email if you have a question or want to meet outside of my regular office hours (above). It may take me a while to get back to you, depending on my workload.\nPhone 604-736-6343 Feel free to phone me at home anytime. Leave a message if I‚Äôm not around.\nSnail mail Rik Blok, Sessional Lecturer Computer Science, UBC 201 - 2366 Main Mall Vancouver, BC, Canada V6T 1Z4 I don‚Äôt check my mailbox regularly so please let me know if you‚Äôve mailed me something.",
    "description": "Want to book an appointment or reach me?  Check out my office hours and contact information here.",
    "tags": [],
    "title": "Contact Rik",
    "uri": "/~rikblok/teaching/contact/index.html"
  },
  {
    "breadcrumb": "Research ramblings",
    "content": "Work I‚Äôve presented for feedback at seminars, lab meetings, and guest lectures.\nSelf-affine timeseries analysis (2003)Guest lecture for PHYS 510: Stochastic Processes in Physics, UBC\nRock, paper and scissors in space (2002)SOWD (Schluter, Otto, Whitton, Whitlock, Doebeli)) Lab Meeting, UBC\nStatistical properties of financial timeseries (2002)PIMS-MITACS Math Finance Seminar, UBC\nCan memes drive genes? (2001)Presentation for Doebeli lab meeting, UBC\nOn the nature of the stock market: Simulations and experiments (2000)Final PhD oral defense, UBC\nModelling intentionality: The gambler (1998)Presentation for PHYS 510, UBC\nExtra! Extra! Critical update on 'Life' (1998)Presentation for Peter Wall Inst. Adv. Science, Crisis Points Group, UBC",
    "description": "Work I‚Äôve presented for feedback at seminars, lab meetings, and guest lectures",
    "tags": [],
    "title": "Presented",
    "uri": "/~rikblok/research/presented/index.html"
  },
  {
    "breadcrumb": "",
    "content": "I spend a lot of time around computers, both at work and play. Yes, I‚Äôm a card-carrying geek üòâ Here‚Äôs what I‚Äôve picked up over the years.\nTrends in Computing (2011)Years ago I heard it said that computers were doubling in performance every year or two; that is, two years from now you could buy a computer twice as powerful/fast as today for the same price or less. I was curious to see if this was true so I started tracking the prices of individual components on a monthly basis.\nOrphanwareThis page contains software I am no longer developing or maintaining. Enter at your own risk üòâ\nToolbar (1999 - 2003)Toolbar (alias Rik‚Äôs Toolbar) provides a way to add a customized floating toolbar to any application. When a button is pressed a pre-defined sequence of keystrokes is sent to the desired window.\nR2DToo (2001 - 2003)Rik‚Äôs 2D simulation Tool lets you build and run your own cellular automata or other spatial network simulations. R2DToo is designed for scientists, to help with constructing, running, and collecting data from simulations with features such as live time series plots of interesting statistics and automation to let the user run experiments repeatedly without requiring user interaction.\nRunIEAs (2001 - 2002)Ok, you want to let other people run Internet Explorer on your computer but you want to let them have their own favorites, home page, etc. Microsoft‚Äôs solution? Save what you‚Äôre doing‚Ä¶log off current user‚Ä¶wait‚Ä¶log on as other user‚Ä¶wait‚Ä¶run IE‚Ä¶Done! My solution? RunIEAs ‚Ä¶Done!\nExportChart (1999 - 2001)ExportChart Excel Add-In. Save your Excel charts to Gif files for use in web pages or graphic programs. Requires Microsoft Excel 97 or 2000.\nTeX Equation Previewer (1999 - 2000)View and edit TeX equations before compiling your source. View your equation as you type in (almost) real time. Copies modified text to the clipboard for quick use in your favorite text editor.",
    "description": "I spend a lot of time around computers, both at work and play. Yes, I‚Äôm a card-carrying geek üòâ  Here‚Äôs what I‚Äôve picked up over the years.",
    "tags": [],
    "title": "Computational capers",
    "uri": "/~rikblok/compute/index.html"
  },
  {
    "breadcrumb": "Academic anecdotes",
    "content": "You reached out to me and now you‚Äôre wondering, ‚ÄúThat ahle! Why hasn‚Äôt Rik got back to me?‚Äù If I‚Äôm busy I just may not have had a chance yet. So check out my current workload for yourself. Automatically generated from the number of emails waiting in my inbox.\n‚Äã\r2 weeks\r1 month\r4 months\r1 year\r3 years\r10 years\rall time\rChart shows daily maximum workload.\nChart shows daily maximum workload.\nChart shows daily maximum workload.\nChart shows weekly maximum workload.\nChart shows weekly maximum workload.\nChart shows 3-month maximum workload.\nChart shows 3-month maximum workload.\nUnder light workloads expect a response within a few days. I should be able to get back to you within a week under moderate workloads. But when my workload is heavy it could take a few weeks.",
    "description": "View my historical workload, automatically generated from the emails waiting in my inbox.",
    "tags": [],
    "title": "Workload",
    "uri": "/~rikblok/teaching/workload/index.html"
  },
  {
    "breadcrumb": "Computational capers",
    "content": "This page contains software I am no longer developing or maintaining. Enter at your own risk üòâ\nToolbar (1999 - 2003)Toolbar (alias Rik‚Äôs Toolbar) provides a way to add a customized floating toolbar to any application. When a button is pressed a pre-defined sequence of keystrokes is sent to the desired window.\nR2DToo (2001 - 2003)Rik‚Äôs 2D simulation Tool lets you build and run your own cellular automata or other spatial network simulations. R2DToo is designed for scientists, to help with constructing, running, and collecting data from simulations with features such as live time series plots of interesting statistics and automation to let the user run experiments repeatedly without requiring user interaction.\nRunIEAs (2001 - 2002)Ok, you want to let other people run Internet Explorer on your computer but you want to let them have their own favorites, home page, etc. Microsoft‚Äôs solution? Save what you‚Äôre doing‚Ä¶log off current user‚Ä¶wait‚Ä¶log on as other user‚Ä¶wait‚Ä¶run IE‚Ä¶Done! My solution? RunIEAs ‚Ä¶Done!\nExportChart (1999 - 2001)ExportChart Excel Add-In. Save your Excel charts to Gif files for use in web pages or graphic programs. Requires Microsoft Excel 97 or 2000.\nTeX Equation Previewer (1999 - 2000)View and edit TeX equations before compiling your source. View your equation as you type in (almost) real time. Copies modified text to the clipboard for quick use in your favorite text editor.",
    "description": "This page contains software I am no longer developing or maintaining.  Enter at your own risk üòâ",
    "tags": [],
    "title": "Orphanware",
    "uri": "/~rikblok/compute/orphanware/index.html"
  },
  {
    "breadcrumb": "Research ramblings",
    "content": "Here are some research-oriented technical notes I‚Äôve written. They‚Äôre not peer-reviewed or published.\nReplicator Kinetics (2013)Here I explore several possible systems of reactions that yield evolutionary dynamics consistent with the replicator equation. They are also useful for studying finite, structured populations.\nParallel Poisson (2004)I explore how to efficiently implement Poisson processes in event-driven, multi-agent simulations.\nDiscounted Least Squares (1997)I recently wrote some code to make simple forecasts in a time series. I began to wonder if there was a way of steadily discounting the relevance of past data in a smoother and more natural way‚Ä¶",
    "description": "Here are some research-oriented technical notes I‚Äôve written. They‚Äôre not peer-reviewed or published.",
    "tags": [],
    "title": "Unpublished notes",
    "uri": "/~rikblok/research/notes/index.html"
  },
  {
    "breadcrumb": "",
    "content": "Some interesting (to me!) mathematical puzzles and problems I‚Äôve come across.\nEuler's constant (2014)I found a sequence that converges to Euler‚Äôs constant faster than Bernoulli‚Äôs formula.\nShared gas (2002)My wife and I live in a twenty eight unit condominium which shares the cost of natural gas. At what price level can we expect the residents to switch from heating with gas to heating with electricity?\nThe Pythagorean theorem (1997)I‚Äôve been puzzling over a proof for this for years, and it finally dawned on me. (Eureka!) It‚Äôs all in how you draw it‚Ä¶",
    "description": "Some interesting (to me!) mathematical puzzles and problems I‚Äôve come across.",
    "tags": [],
    "title": "Mathematical musings",
    "uri": "/~rikblok/math/index.html"
  },
  {
    "breadcrumb": "Academic anecdotes",
    "content": "Here are some recent courses I‚Äôve taught.\nUBC CPSC 110Computation, Programs, and Programming\nFundamental program and computation structures. Introductory programming skills. Computation as a tool for information processing, simulation and modelling, and interacting with the world.\nUBC CPSC 107Systematic Program Design\nFundamental computation and program structures. Continuing systematic program design from CPSC 103.\nUBC ISCI 320Research Development Project\nRetreat to develop skills in writing scientific research proposals. Emphasis on formulating and testing hypotheses to explain observations.",
    "description": "Here are some recent courses I‚Äôve taught.",
    "tags": [],
    "title": "Recent courses",
    "uri": "/~rikblok/teaching/current/index.html"
  },
  {
    "breadcrumb": "",
    "content": "I‚Äôm a theoretical statistical physicist by training and a complexologist by nature. The common thread throughout my research is the search for common features of complex, irreducible systems.\nTraditionally, science approaches a problem by breaking it into parts and solving each part separately. In some cases, even when the individual pieces are well understood, the interactions between them will lead to surprising outcomes. Many important and diverse systems exhibit this irreducibility: earthquakes, ecosystems, stock markets, weather, computer networks, the immune system, the brain, forest fires, et cetera. Traditional scientific methods are ill-equipped to cope with these complex systems so my approach is to use novel tools such as nonequilibrium statistical physics theory and computer simulations to further our understanding.\nSee also my Google Scholar profile or my Zotero library.\nPublishedMy peer-reviewed and published articles\nMultimodal pattern formation in phenotype distributions of sexual populations (2007)During bouts of evolutionary diversification the emerging species cluster around different locations in phenotype space. How such multimodal patterns in phenotype space can emerge from a single ancestral species is a fundamental question in biology. Here, we demonstrate that phenotype distributions can split into multiple modes under the force of frequency-dependent competition‚Ä¶\nA tale of two cycles - distinguishing quasi-cycles and limit cycles in finite predator-prey populations (2007)Periodic predator-prey dynamics in constant environments are usually taken as indicative of deterministic limit cycles. It is known, however, that demographic stochasticity in finite populations can also give rise to regular population cycles. Here we show how to distinguish between quasi-cycles and noisy limit cycles based on observing changing population sizes in predator-prey populations. We demonstrate that by using our methods even short and imperfect time series allow quasi-cycles and limit cycles to be distinguished reliably‚Ä¶\nScale-free extinction dynamics in spatially structured host‚Äìparasitoid systems (2006)Much of the work on extinction events has focused on external perturbations of ecosystems, such as climatic change, or anthropogenic factors. Extinction, however, can also be driven by endogenous factors, such as the ecological interactions between species in an ecosystem. Here we show that endogenously driven extinction events can have a scale-free distribution in simple spatially structured host-parasitoid systems. Based on these results, we conjecture that scale-free extinction processes and critical phase transitions of the type we have found may be a characteristic feature of many spatially structured, multi-species ecosystems in nature‚Ä¶\nOn the nature of the stock market: Simulations and experiments (2000)PhD Thesis, UBC\nIn this dissertation, two simple models of stock exchange are developed and simulated numerically. The decentralized model captures key empirical market properties, including fat-tailed returns, short-term memory in returns, and long-range volatility correlations. Significantly, these features emerge only when parameters are tuned to span the critical point, suggesting markets may self-organize near criticality‚Ä¶\nSynchronous versus asynchronous updating in the \"game of Life\" (1999)The rules for the ‚Äúgame of Life‚Äù are modified to allow for only a random fraction of sites to be updated in each time step. Under variation of this fraction from the parallel updating limit down to the Poisson limit, a critical phase transition is observed that explains why the game of Life appears to obey self-organized criticality‚Ä¶\nEffect of boundary conditions on scaling in the \"game of Life\" (1997)The debate as to whether the ‚Äúgame of Life‚Äù is self-organized critical remains unresolved. We present evidence that boundary conditions play an important role in the scaling behaviour, resulting in apparently contradictory results‚Ä¶\nPresentedWork I‚Äôve presented for feedback at seminars, lab meetings, and guest lectures\nSelf-affine timeseries analysis (2003)Guest lecture for PHYS 510: Stochastic Processes in Physics, UBC\nRock, paper and scissors in space (2002)SOWD (Schluter, Otto, Whitton, Whitlock, Doebeli)) Lab Meeting, UBC\nStatistical properties of financial timeseries (2002)PIMS-MITACS Math Finance Seminar, UBC\nCan memes drive genes? (2001)Presentation for Doebeli lab meeting, UBC\nOn the nature of the stock market: Simulations and experiments (2000)Final PhD oral defense, UBC\nModelling intentionality: The gambler (1998)Presentation for PHYS 510, UBC\nExtra! Extra! Critical update on 'Life' (1998)Presentation for Peter Wall Inst. Adv. Science, Crisis Points Group, UBC\nUnpublished notesHere are some research-oriented technical notes I‚Äôve written. They‚Äôre not peer-reviewed or published.\nReplicator Kinetics (2013)Here I explore several possible systems of reactions that yield evolutionary dynamics consistent with the replicator equation. They are also useful for studying finite, structured populations.\nParallel Poisson (2004)I explore how to efficiently implement Poisson processes in event-driven, multi-agent simulations.\nDiscounted Least Squares (1997)I recently wrote some code to make simple forecasts in a time series. I began to wonder if there was a way of steadily discounting the relevance of past data in a smoother and more natural way‚Ä¶",
    "description": "I‚Äôm a theoretical statistical physicist by training and a complexologist by nature. The common thread throughout my research is the search for common features of complex, irreducible systems.",
    "tags": [],
    "title": "Research ramblings",
    "uri": "/~rikblok/research/index.html"
  },
  {
    "breadcrumb": "Academic anecdotes",
    "content": "Here are some courses I‚Äôve taught in the past. These pages are not maintained and may contain broken links.\nUBC ISCI 344 (2016)Game Theory in Economics and Evolution (Fall 2016))\nExploration of human and animal interactions: integrating evolutionary and economic perspectives to investigate individual and social behaviour.\nUBC ISCI 422 (2009)Models in Science (Fall 2009)\nMeaning, nature, use, strengths and limitations of models as investigative tools in all scientific disciplines. Detailed investigation of selected model systems from different scientific disciplines.\nUBC PHYS 102 (2003)Electricity, Light and Radiation (Summer 2003)\nIntroduction to optics, electricity and magnetism, electric circuits, radioactivity, including biological applications.\nUBC PHYS 153 (2000)Elements of Physics (Winter 2000)\nThermometry, thermal properties of matter, heat, oscillations, waves, sound, wave optics; geometrical optics, elementary electricity and magnetism, simple DC and AC circuits.",
    "description": "Here are some courses I‚Äôve taught in the past.",
    "tags": [],
    "title": "Old courses",
    "uri": "/~rikblok/teaching/past/index.html"
  },
  {
    "breadcrumb": "",
    "content": "Science is both my work and my play. That doesn‚Äôt mean I‚Äôm particularly bright or hard-working, just that I‚Äôm curious. Because that‚Äôs the main ingredient for doing good science. (A healthy dose of skepticism helps, too.)\nModelsI‚Äôm interested in the patterns that can emerge when many (often simple) elements interact. It is often required to build models of these kinds of systems to study their behaviour.\nEscape from Goblin-town! (2025)This simulation is inspired by the Goblin-town chase scene in the film The Hobbit: An Unexpected Journey (2012).\nConway's Game of Life (2020)This NetLogo model implements Conway‚Äôs Game of Life, a cellular automaton John Horton Conway designed to be difficult to anticipate the dynamics of starting patterns. This implementation incorporates some ideas I focused on in my research: finite-size effects and asynchronous updating.\nAxelrod's tournament (2018)In the early 1980s Robert Axelrod invited colleagues to submit strategies to a series of round-robin tournaments to see which strategies would do well playing an iterated Prisoner‚Äôs Dilemma. This NetLogo model allows you to try Axelrod‚Äôs tournaments yourself by creating some strategies and testing them in an iterated Prisoner‚Äôs Dilemma.\nAquaworld Radiation Balance (2018)This simple radiation balance model shows the greenhouse effect that an atmosphere can have in warming a planet. By trapping some of the radiation emitted by the planet the atmosphere can cause the surface to become warmer than it otherwise would be.\nA Trojan horse approach to medical intervention strategies (2017)I recently read an interesting review paper that explores the possibility of fighting a bacterial infection with Darwinian medicine through the introduction of a ‚Äúcheater‚Äù strain of bacteria into a wild population. I extended the analytic model in the paper to an agent-based model with explicit spatial structure.\nFlame (2017)I got thinking about how fires work today. Why do flames curl into whorls and some tongues lick up so high? I built this model to see how hard it was to reproduce the phenomenon. This is the result. I don‚Äôt think it captures much of the underlying mechanism but it looks pretty hot üôÇ\nMandelbrot Set (2017)Explore the Mandelbrot set and some related fractals.\nSince I was born (2022)The world‚Äôs spinning fast. Sometimes I forget about how much science and technology have progressed in my lifetime. Here are some advances to help remind me.\nThe curious skeptic (2008)Here‚Äôs what drives me as a teacher.\nThe onion of Science (2002)I often have people ask me what I do for a living. Because my research projects are so varied I like to give a different answer each time. Nevertheless, the question has forced me to evaluate my role as a scientist. This page is an attempt to explain what I believe science is all about and where my work fits in‚Ä¶",
    "description": "Science is both my work and my play. That doesn‚Äôt mean I‚Äôm particularly bright or hard-working, just that I‚Äôm curious. Because that‚Äôs the main ingredient for doing good science. (A healthy dose of skepticism helps, too.)",
    "tags": [],
    "title": "Scientific scribblings",
    "uri": "/~rikblok/science/index.html"
  },
  {
    "breadcrumb": "Academic anecdotes¬†\u003e¬†Recent courses",
    "content": "",
    "description": "Computation, Programs, and Programming\nFundamental program and computation structures. Introductory programming skills. Computation as a tool for information processing, simulation and modelling, and interacting with the world.",
    "tags": [],
    "title": "UBC CPSC 110",
    "uri": "/~rikblok/teaching/current/cpsc110/index.html"
  },
  {
    "breadcrumb": "Academic anecdotes¬†\u003e¬†Recent courses",
    "content": "",
    "description": "Systematic Program Design\nFundamental computation and program structures. Continuing systematic program design from CPSC 103.",
    "tags": [],
    "title": "UBC CPSC 107",
    "uri": "/~rikblok/teaching/current/cpsc107/index.html"
  },
  {
    "breadcrumb": "Academic anecdotes¬†\u003e¬†Recent courses",
    "content": "",
    "description": "Research Development Project\nRetreat to develop skills in writing scientific research proposals. Emphasis on formulating and testing hypotheses to explain observations.",
    "tags": [],
    "title": "UBC ISCI 320",
    "uri": "/~rikblok/teaching/current/isci320/index.html"
  },
  {
    "breadcrumb": "",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Categories",
    "uri": "/~rikblok/categories/index.html"
  },
  {
    "breadcrumb": "",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tags",
    "uri": "/~rikblok/tags/index.html"
  }
]
